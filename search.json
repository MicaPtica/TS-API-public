[
  {
    "objectID": "Main concepts/ppg_concept.html#quick-access",
    "href": "Main concepts/ppg_concept.html#quick-access",
    "title": "PPG",
    "section": "Quick access",
    "text": "Quick access\n\nPPG Subsystem\nExamples\nUsecase\nPPG Data structures",
    "crumbs": [
      "Main concepts",
      "PPG"
    ]
  },
  {
    "objectID": "Main concepts/ppg_concept.html#what-is-ppg",
    "href": "Main concepts/ppg_concept.html#what-is-ppg",
    "title": "PPG",
    "section": "What is PPG?",
    "text": "What is PPG?\nPhotoplethysmography (PPG) is a non-invasive optical technique used to measure blood volume changes in the microvascular bed of tissue. It is widely used in medical and fitness devices to monitor heart rate, blood oxygen levels, and other physiological parameters. PPG sensors work by emitting light into the skin and measuring the amount of light absorbed or reflected by blood vessels.\nPPG is a cornerstone technology in wearable devices, enabling real-time monitoring of cardiovascular health. Its applications range from fitness tracking to clinical monitoring, making it a versatile tool in health monitoring systems.",
    "crumbs": [
      "Main concepts",
      "PPG"
    ]
  },
  {
    "objectID": "Main concepts/ppg_concept.html#ppg-in-teslasuit",
    "href": "Main concepts/ppg_concept.html#ppg-in-teslasuit",
    "title": "PPG",
    "section": "PPG in Teslasuit",
    "text": "PPG in Teslasuit\nThe Teslasuit integrates PPG technology as part of its biometry subsystem, enabling advanced physiological monitoring capabilities. The PPG subsystem in the Teslasuit is designed to provide real-time data on heart rate, heart rate variability (HRV), and raw PPG signals. This data can be used for various applications, including fitness tracking and stress monitoring\nThe Teslasuit’s PPG functionality is accessible through the TsPPG class, which provides methods for streaming raw data, retrieving processed data, and performing calibration. The PPG subsystem is tightly integrated with the Teslasuit API, allowing developers to seamlessly incorporate PPG data into their applications.",
    "crumbs": [
      "Main concepts",
      "PPG"
    ]
  },
  {
    "objectID": "Main concepts/ppg_concept.html#key-features-of-the-teslasuit-ppg-subsystem",
    "href": "Main concepts/ppg_concept.html#key-features-of-the-teslasuit-ppg-subsystem",
    "title": "PPG",
    "section": "Key Features of the Teslasuit PPG Subsystem",
    "text": "Key Features of the Teslasuit PPG Subsystem\n\nRaw Data Streaming: The Teslasuit PPG subsystem allows developers to stream raw PPG data in real time. This data can be used for custom signal processing and analysis.\nHeart Rate Variability (HRV): The subsystem provides HRV data, which is a key indicator of autonomic nervous system activity and overall cardiovascular health.\nProcessed Data: In addition to raw data, the subsystem offers processed PPG data, including heart rate and validity check of retrieved data.\nCalibration: The PPG subsystem includes a calibration feature to ensure accurate measurements.",
    "crumbs": [
      "Main concepts",
      "PPG"
    ]
  },
  {
    "objectID": "Main concepts/ppg_concept.html#how-the-teslasuit-api-implements-ppg",
    "href": "Main concepts/ppg_concept.html#how-the-teslasuit-api-implements-ppg",
    "title": "PPG",
    "section": "How the Teslasuit API Implements PPG",
    "text": "How the Teslasuit API Implements PPG\nThe Teslasuit API provides a structured approach to accessing and utilizing PPG data. Below are the key steps involved:\n\nInitialization: The Teslasuit API must be initialized before accessing the PPG subsystem. This ensures that the API is ready to communicate with the Teslasuit device.\nDevice Connection: A Teslasuit device must be connected to access its PPG subsystem. The API provides methods to wait for and retrieve connected devices.\nSubsystem Access: The PPG subsystem is accessed through the ppg property of the connected device. This property returns an instance of the TsPpg class.\nData Retrieval: The TsPpg class provides methods to retrieve raw and processed PPG data, as well as HRV metrics.",
    "crumbs": [
      "Main concepts",
      "PPG"
    ]
  },
  {
    "objectID": "Main concepts/ppg_concept.html#description-of-ppg-data",
    "href": "Main concepts/ppg_concept.html#description-of-ppg-data",
    "title": "PPG",
    "section": "Description of PPG data",
    "text": "Description of PPG data\nBelow is a detailed description of the PPG data and data structures used in the Teslasuit API for the PPG subsystem.\n\nHRV\n\nWhat is Heart Rate Variability (HRV)?\nHeart Rate Variability (HRV) is a measure of the variation in time between consecutive heartbeats. These time intervals, typically measured in milliseconds, reflect how the autonomic nervous system regulates the heart. HRV is widely recognized as a non-invasive marker of physiological resilience, stress response, and overall autonomic balance.\n\n\nWhy HRV Matters\nHRV provides insights into the balance between the sympathetic (“fight or flight”) and parasympathetic (“rest and digest”) branches of the autonomic nervous system. Higher HRV generally indicates better adaptability, recovery capacity, and health, while lower HRV can signal stress, fatigue, or underlying health issues.\n\n\nHRV in Teslasuit\nTeslasuit provides HRV analysis using various statistical and mathematical methods, including time-domain, frequency-domain, and non-linear approaches. These metrics provide different perspectives on how the body is responding and adapting over time. As calculation of different HRV parameters requires multiple R-R intervals, base for HRV calculations, Teslasuit has to make sufficient amount of measurements. Therefore the time buffer was implemented which makes impossible to get HRV data right after turning on the PPG sensor.\n\n\nHRV parameters and explanation\n\nMean R-R: The average time interval between consecutive heartbeats, measured in milliseconds. It reflects the average heart period and is inversely related to heart rate.\nStandard Deviation of NN Intervals (SDNN): A measure of overall heart rate variability, calculated as the standard deviation of all normal-to-normal RR intervals. It reflects both sympathetic and parasympathetic activity and is influenced by total recording duration.\nStandard Deviation of Successive Differences (SDSD): The standard deviation of the differences between successive RR intervals. It reflects short-term variations in heart rate and is primarily influenced by parasympathetic activity.\nRoot Mean Square of Successive Differences (RMSSD): A time-domain index of short-term heart rate variability. It is calculated as the square root of the mean squared differences between adjacent RR intervals and serves as a reliable indicator of parasympathetic (vagal) activity.\nSD1: A non-linear HRV metric representing short-term variability, derived from the width of the Poincaré plot (a scatter plot of RR intervals against the next RR interval). It is mathematically related to RMSSD.\nSD2: A measure of both short- and long-term variability, reflecting the length of the Poincaré plot ellipse. It captures the overall magnitude of variability and complements SD1.\nHigh-to-Low Frequency Ratio (HLF): The ratio between high-frequency and low-frequency spectral power in frequency-domain analysis. It provides an index of autonomic balance, with higher values indicating parasympathetic dominance and lower values suggesting sympathetic predominance.\n\n\n\n\nHeart Rate\n\nWhat is Heart Rate?\nHeart rate refers to the number of times the heart beats per minute (bpm). It is a direct indicator of cardiac activity and is influenced by a wide range of physiological and environmental factors, including physical exertion, emotional state, body temperature, and cardiovascular health. Heart rate is one of the most fundamental vital signs used in health and performance monitoring.\n\n\nWhy Heart Rate Matters\nHeart rate reflects the immediate state of the cardiovascular system and the body’s response to internal and external stimuli. An elevated heart rate may indicate physical effort, stress, or cardiovascular strain, while a lower heart rate at rest is often associated with good cardiovascular fitness and efficient autonomic function. Tracking heart rate over time allows for monitoring of exercise intensity, recovery, fatigue, and overall wellness.\n\n\nHeart Rate in Teslasuit\nTeslasuit measures heart rate using a photoplethysmography (PPG) sensor, which detects changes in vessels blood volume with each heartbeat. This allows for continuous, non-invasive monitoring of heart rate in both active and resting states. Heart rate data is updated in real-time and can be used independently or in combination with HRV metrics to assess physical performance, recovery, and autonomic nervous system activity.\n\n\nHeart Rate parameter and explanation\n\nHeart Rate (HR): The number of heartbeats per minute. It is calculated for every interval between successive heartbeats (R-R intervals) and reflects current cardiovascular activity. Heart rate increases with physical exertion or stress and decreases during rest or relaxation.\nis_valid: During periods of movement, signal artifacts may cause temporary disruptions or inaccuracies in heart rate measurements. To address this, we developed an extrapolation algorithm that maintains data continuity by estimating heart rate values when direct measurement is unreliable. As a result, each data point is accompanied by a validity flag indicating whether the value is based on a reliable measurement or an extrapolated estimate.",
    "crumbs": [
      "Main concepts",
      "PPG"
    ]
  },
  {
    "objectID": "Main concepts/ppg_concept.html#applications-of-ppg-in-teslasuit",
    "href": "Main concepts/ppg_concept.html#applications-of-ppg-in-teslasuit",
    "title": "PPG",
    "section": "Applications of PPG in Teslasuit",
    "text": "Applications of PPG in Teslasuit\nThe PPG subsystem in the Teslasuit has a wide range of applications, including:\n\nFitness and Wellness: Monitor heart rate and HRV to track fitness levels and recovery.\nStress Monitoring: Use HRV data to assess stress levels and provide biofeedback.\nRehabilitation: Integrate PPG data into rehabilitation programs to monitor cardiovascular responses.\nGaming and VR: Enhance immersive experiences by incorporating real-time physiological data into gameplay or virtual environments.",
    "crumbs": [
      "Main concepts",
      "PPG"
    ]
  },
  {
    "objectID": "Main concepts/ppg_concept.html#dependencies-in-data-structures-and-accessing-data",
    "href": "Main concepts/ppg_concept.html#dependencies-in-data-structures-and-accessing-data",
    "title": "PPG",
    "section": "Dependencies in Data Structures and Accessing Data",
    "text": "Dependencies in Data Structures and Accessing Data\nThe Teslasuit PPG subsystem relies on a hierarchy of data structures to manage and process PPG data. Below is a detailed description of the dependencies between these structures and a block scheme illustrating how data is accessed.\n\nData Structure Dependencies\n\nTsPpgRawNodeData:\n\nRepresents raw PPG data for a single sensor node.\nContains attributes like ir_data, red_data, blue_data, green_data, and timestamp.\n\nTsPpgRawData:\n\nRepresents raw PPG data from multiple sensor nodes.\nContains a list of TsPpgRawNodeData objects.\n\nTsPpgNodeData:\n\nRepresents processed PPG data for a single sensor node.\nContains attributes like heart_rate, is_heart_rate_valid, and timestamp.\n\nTsPpgData:\n\nRepresents processed PPG data from multiple sensor nodes.\nContains a list of TsPpgNodeData objects.\n\nTsHrv:\n\nRepresents HRV metrics derived from processed PPG data.\nContains attributes like mean_rr, sdnn, rmssd, and others.\n\n\n\n\nBlock Scheme for Accessing Data\nBelow is a simplified block scheme illustrating the flow of data from raw sensor readings to processed metrics:\n\n\n\n\n\nflowchart TD\n    A([PPG class]) --&gt; B[[TsHrv]]\n    A --&gt; C[[TsPpgRawData]]\n    C --&gt; D[[TsPpgRawNodeData]]\n    D --&gt; E((ir_data))\n    D --&gt; F((red_data))\n    D --&gt; G((blue_data))\n    D --&gt; H((green_data))\n    D --&gt; I((timestamp))\n    A --&gt; Q[[TsPpgData]]\n    Q --&gt; R[[TsPpgNodeData]]\n    R --&gt; S((heart_rate))\n    R --&gt; T((is_valid))\n    \n    B --&gt; J((mean_rr))\n    B --&gt; K((sdnn))\n    B --&gt; L((sdsd))\n    B --&gt; M((sd1))\n    B --&gt; N((sd2))\n    B --&gt; O((rmssd))\n    B --&gt; P((hlf))\n\n    class B,J,K,L,M,N,O,P hrv;\n    class C,D,E,F,G,H,I,Q,R,S,T ppg;",
    "crumbs": [
      "Main concepts",
      "PPG"
    ]
  },
  {
    "objectID": "Main concepts/ppg_concept.html#example-code",
    "href": "Main concepts/ppg_concept.html#example-code",
    "title": "PPG",
    "section": "Example Code",
    "text": "Example Code\nFor detailed examples of how to use the PPG subsystem in the Teslasuit API, refer to the PPG Examples page. These examples demonstrate how to initialize the API, connect to a device, and retrieve PPG data.",
    "crumbs": [
      "Main concepts",
      "PPG"
    ]
  },
  {
    "objectID": "Main concepts/ppg_concept.html#conclusion",
    "href": "Main concepts/ppg_concept.html#conclusion",
    "title": "PPG",
    "section": "Conclusion",
    "text": "Conclusion\nThe PPG subsystem in the Teslasuit represents a powerful tool for real-time physiological monitoring. By leveraging the Teslasuit API, developers can integrate PPG data into a wide range of applications, from fitness tracking to immersive VR experiences.",
    "crumbs": [
      "Main concepts",
      "PPG"
    ]
  },
  {
    "objectID": "Main concepts/mocap_concept.html#quick-access",
    "href": "Main concepts/mocap_concept.html#quick-access",
    "title": "Mocap",
    "section": "Quick access",
    "text": "Quick access\n\nMocap Subsystem\nExamples\nUsecase\nMocap Data structures",
    "crumbs": [
      "Main concepts",
      "Mocap"
    ]
  },
  {
    "objectID": "Main concepts/mocap_concept.html#what-is-mocap",
    "href": "Main concepts/mocap_concept.html#what-is-mocap",
    "title": "Mocap",
    "section": "What is Mocap?",
    "text": "What is Mocap?\nMotion capture (Mocap) is a technology used to record the movement of objects or people. It is widely used in fields such as animation, gaming, sports, and biomechanics to analyze and replicate motion. Mocap systems track the position and orientation of key points on a subject and translate them into digital data.\nMotion capture (Mocap) is a foundational technology in wearable devices, allowing for real-time monitoring of body movements. It serves a wide array of purposes, from entertainment to healthcare, making it a highly adaptable tool for motion analysis and simulation.",
    "crumbs": [
      "Main concepts",
      "Mocap"
    ]
  },
  {
    "objectID": "Main concepts/mocap_concept.html#mocap-in-teslasuit",
    "href": "Main concepts/mocap_concept.html#mocap-in-teslasuit",
    "title": "Mocap",
    "section": "Mocap in Teslasuit",
    "text": "Mocap in Teslasuit\nTeslasuit integrates Mocap technology as part of its motion capture subsystem, enabling advanced motion tracking capabilities. The Mocap subsystem in the Teslasuit is designed to provide real-time data on skeletal positions, orientations, and biomechanical angles. This data can be used for various applications, including animation, rehabilitation, and sports performance analysis.\nSystem relies on 14 strategically placed inertial measurement unit (IMU) sensors embedded throughout the suit. These sensors ensure high-resolution tracking of body movements, delivering precise and consistent motion data across all major joints and body segments.\nThe Teslasuit’s Mocap functionality is accessible through the TsMocap class, which provides methods for streaming raw data, retrieving skeleton data, and performing calibration. The Mocap subsystem is tightly integrated with the Teslasuit API, allowing developers to seamlessly incorporate motion data into their applications.\nMocap sensors are located as shown on the picture below:\n\n\n\nMocap sensor scheme",
    "crumbs": [
      "Main concepts",
      "Mocap"
    ]
  },
  {
    "objectID": "Main concepts/mocap_concept.html#key-features-of-the-teslasuit-mocap-subsystem",
    "href": "Main concepts/mocap_concept.html#key-features-of-the-teslasuit-mocap-subsystem",
    "title": "Mocap",
    "section": "Key features of the Teslasuit Mocap subsystem",
    "text": "Key features of the Teslasuit Mocap subsystem\n\nRaw Data Streaming: The Teslasuit Mocap subsystem allows developers to stream raw motion data in real time. This data can be used for custom analysis and visualization.\nSkeleton Data: The subsystem provides detailed skeletal data, including bone positions and orientations, enabling precise motion tracking.\nBiomechanical Angles: The subsystem offers biomechanical angle data, which is useful for analyzing joint movements and posture.\nCalibration: The Mocap subsystem includes a calibration feature to ensure accurate motion tracking.",
    "crumbs": [
      "Main concepts",
      "Mocap"
    ]
  },
  {
    "objectID": "Main concepts/mocap_concept.html#how-the-teslasuit-api-implements-mocap",
    "href": "Main concepts/mocap_concept.html#how-the-teslasuit-api-implements-mocap",
    "title": "Mocap",
    "section": "How the Teslasuit API implements Mocap",
    "text": "How the Teslasuit API implements Mocap\nThe Teslasuit API provides a structured approach to accessing and utilizing Mocap data. Below are the key steps involved:\n\nInitialization: The Teslasuit API must be initialized before accessing the Mocap subsystem. This ensures that the API is ready to communicate with the Teslasuit device.\nDevice Connection: A Teslasuit device must be connected to access its Mocap subsystem. The API provides methods to wait for and retrieve connected devices.\nSubsystem Access: The Mocap subsystem is accessed through the mocap property of the connected device. This property returns an instance of the TsMocap class.\nData Retrieval: The TsMocap class provides methods to retrieve raw sensor data, skeleton data, and biomechanical angles.",
    "crumbs": [
      "Main concepts",
      "Mocap"
    ]
  },
  {
    "objectID": "Main concepts/mocap_concept.html#description-of-mocap-data",
    "href": "Main concepts/mocap_concept.html#description-of-mocap-data",
    "title": "Mocap",
    "section": "Description of Mocap data",
    "text": "Description of Mocap data\nBelow is a detailed description of the Mocap data and data structures used in the Teslasuit API for the Mocap subsystem.\n\nRaw data\n\nWhat is raw data?\nRaw data in the context of the Teslasuit Mocap subsystem refers to the unprocessed sensor readings collected directly from the suit’s inertial measurement units (IMUs). Each IMU sensor provides measurements such as gyroscope (angular velocity), accelerometer (linear acceleration), magnetometer (magnetic field), and sometimes additional sensor fusion outputs (e.g., orientation quaternions).\nRaw data is essential for low-level analysis, sensor fusion, and custom motion processing. It allows developers to access the fundamental measurements before any higher-level interpretation, such as skeleton reconstruction or biomechanical angle calculation.\n\n\nRaw data parameters and explanation\n\nGyroscope (gyro): Measures the rate of rotation (angular velocity) around the X, Y, and Z axes (in radians per second).\nAccelerometer (accel): Measures linear acceleration along the X, Y, and Z axes (in meters per second squared).\nMagnetometer (magn): Measures the magnetic field along the X, Y, and Z axes (in microteslas).\nOrientation Quaternions (q6, q9): Represent the estimated orientation of the sensor in 3D space, based on 6-axis or 9-axis sensor fusion.\nLinear Acceleration (linear_accel): Acceleration with gravity removed, useful for motion analysis (in meters per second squared).\nTimestamp (timestamp): The time at which the sensor reading was captured.\n\n\nWhat is a quaternion?\nA quaternion is a mathematical representation used to describe rotations in 3D space. It consists of four components: one real part (w) and three imaginary parts (x, y, z). Quaternions are widely used in computer graphics, robotics, and motion capture because they avoid issues like gimbal lock and provide smooth interpolation for rotations.\n\n\n\nWhy raw data matters\nAccess to raw data enables advanced users to implement custom filtering, sensor fusion algorithms, or diagnostics. It is particularly useful for research, debugging, and applications requiring precise control over motion data processing.\n\n\n\nSkeleton data\n\nWhat is skeleton data?\nThe “Skeleton” refers to a skeletal model—a digital representation of the human body composed of interconnected bones or segments—that mirrors the subject’s posture and motion in real time. Skeleton data represents the positions and orientations of bones in a 3D space. It is used to track the movement of a subject’s body and is a fundamental component of motion capture systems.\n\n\nWhy skeleton data matters\nSkeleton data provides insights into body posture, joint movements, and overall motion patterns. It is widely used in animation, sports analysis, and rehabilitation to study and replicate human motion.\n\n\nSkeleton data in Teslasuit\nThe Teslasuit provides detailed skeleton data using its integrated motion capture sensors. This data includes the position and rotation of each bone in the body, enabling precise motion tracking and analysis.\n\n\nSkeleton data parameters and explanation\n\nPosition: The 3D coordinates (x, y, z) of a bone in space.\nRotation: The orientation of a bone represented as a quaternion (w, x, y, z).\n\n\n\n\nBiomechanical angles\n\nWhat are biomechanical angles?\nBiomechanical angles represent the relative angles between bones at joints. These angles are used to analyze joint movements and body mechanics.\n\n\nWhy biomechanical angles matter\nBiomechanical angles provide valuable information about joint flexibility, posture, and movement efficiency. They are essential for applications in sports performance, rehabilitation, and ergonomics.\n\n\nBiomechanical angles in Teslasuit\nTeslasuit calculates biomechanical angles using its motion capture data. These angles are available for key joints in the body and can be used to analyze motion patterns and detect abnormalities.\n\n\nBiomechanical angle parameters and explanation\n\nJoint Angle: The angles between two connected bones at a joint. Angles are typically measured in degrees or radians and represent the relative orientation of the bones.\n\nFlexion/Extension: These angles describe the bending (flexion) or straightening (extension) of a joint. For example, the knee joint’s flexion angle increases as the leg bends.\nAbduction/Adduction: These angles describe the movement of a limb away from (abduction) or toward (adduction) the body’s midline. For example, raising an arm sideways involves abduction of the shoulder joint.\nInternal/External Rotation: These angles describe the rotation of a bone around its longitudinal axis. For example, rotating the forearm inward or outward involves internal or external rotation of the shoulder joint.\nPlane of Movement: The biomechanical angles are often categorized based on the anatomical planes of movement:\n\nSagittal Plane: Flexion and extension.\nFrontal Plane: Abduction and adduction.\nTransverse Plane: Internal and external rotation.",
    "crumbs": [
      "Main concepts",
      "Mocap"
    ]
  },
  {
    "objectID": "Main concepts/mocap_concept.html#applications-of-mocap-in-teslasuit",
    "href": "Main concepts/mocap_concept.html#applications-of-mocap-in-teslasuit",
    "title": "Mocap",
    "section": "Applications of Mocap in Teslasuit",
    "text": "Applications of Mocap in Teslasuit\nThe Mocap subsystem in the Teslasuit has a wide range of applications, including:\n\nAnimation and Gaming: Capture realistic human movements for use in animation and virtual environments.\nSports Performance: Analyze motion patterns to improve athletic performance and reduce injury risk.\nRehabilitation: Monitor body movements during rehabilitation exercises to track progress and ensure proper technique.\nVirtual Reality: Enhance immersive experiences by incorporating real-time motion data into VR applications.",
    "crumbs": [
      "Main concepts",
      "Mocap"
    ]
  },
  {
    "objectID": "Main concepts/mocap_concept.html#dependencies-in-data-structures-and-accessing-data",
    "href": "Main concepts/mocap_concept.html#dependencies-in-data-structures-and-accessing-data",
    "title": "Mocap",
    "section": "Dependencies in data structures and accessing data",
    "text": "Dependencies in data structures and accessing data\nThe Teslasuit Mocap subsystem relies on a hierarchy of data structures to manage and process motion data. Below is a detailed description of the dependencies between these structures and a block scheme illustrating how data is accessed.\n\nData structure dependencies\n\nTsMocapBone:\n\nRepresents the position and rotation of a single bone.\nContains attributes like position and rotation.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo get position and rotation for specified bone, we need:\n\nChoose bone we need\n\n\n\nTsBone2dIndex structure all possible options are shown. Specify one you need.\n\n\nCall function correctly\n\n\n\nIn order to get position and rotation correctly, we can proceed with next code example:\n\n   biomech_data = mocap.get_skeleton_data_on_ready()\n   print(\"Position and rotation \", biomech_data[TsBone2dIndex.LeftUpperArmLeftUpperArm].position, biomech_data[TsBone2dIndex.LeftUpperArmLeftUpperArm].rotation)\n\n\n\nTsMocapSensor:\n\nRepresents raw IMU sensor data for a single bone.\nContains attributes like gyro, accel, timestamp and others.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo get raw data for specified bone, we need:\n\nChoose bone we need\n\n\n\nTsBone2dIndex structure all possible options are shown. Specify one you need.\n\n\nCall function correctly\n\n\n\nIn order to get raw data correctly, we can proceed with next code example:\n\n   biomech_data = mocap.mocap.get_raw_data_on_ready()\n   print(\"Bone data:\", data[TsBone2dIndex.RightUpperArm])\n\n\n\nTsBiomechanicalIndex:\n\nRepresents biomechanical angles for specific joints.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo get specified angle, we need:\n\nChoose angle we need\n\n\n\nIn the TsBiomechanicalIndex structure all possible options are shown. Specify one you need.\n\n\nCall function correctly\n\n\n\nIn order to get angles correctly, we can proceed with next code example:\n\n   biomech_data = mocap.get_biomechanical_angles_on_ready()\n   print(\"Biomech Pelvis Tilt: \", biomech_data[TsBiomechanicalIndex.PelvisTilt])\n\n\n\n\n\n\nBlock scheme for accessing data\nBelow is a simplified block scheme illustrating the flow of data from raw sensor readings to processed metrics:\n\n\n\n\n\nflowchart TD\n    A([Mocap class]) --&gt; B[[TsMocapBone]]\n    A --&gt; C[[TsMocapSensor]]\n    B --&gt; N[[position]]\n    B --&gt; O[[rotation]]\n    C --&gt; D[[gyro]]\n    C --&gt; E[[accel]]\n    C --&gt; F[[timestamp]]\n    C --&gt; I[[q6]]\n    C --&gt; K[[q9]]\n    C --&gt; L[[magn]]\n    C --&gt; M[[linear_accel]]\n    A --&gt; G[[TsBiomechanicalIndex]]\n    G --&gt; H((angle_value))\n\n    class B,C,D,E,F,G,H mocap;",
    "crumbs": [
      "Main concepts",
      "Mocap"
    ]
  },
  {
    "objectID": "Main concepts/mocap_concept.html#example-code",
    "href": "Main concepts/mocap_concept.html#example-code",
    "title": "Mocap",
    "section": "Example code",
    "text": "Example code\nFor detailed examples of how to use the Mocap subsystem in the Teslasuit API, refer to the Mocap Examples page. These examples demonstrate how to initialize the API, connect to a device, and retrieve Mocap data.",
    "crumbs": [
      "Main concepts",
      "Mocap"
    ]
  },
  {
    "objectID": "Main concepts/mocap_concept.html#conclusion",
    "href": "Main concepts/mocap_concept.html#conclusion",
    "title": "Mocap",
    "section": "Conclusion",
    "text": "Conclusion\nThe Mocap subsystem in the Teslasuit represents a powerful tool for real-time motion tracking. By leveraging the Teslasuit API, developers can integrate Mocap data into a wide range of applications, from animation to rehabilitation.",
    "crumbs": [
      "Main concepts",
      "Mocap"
    ]
  },
  {
    "objectID": "Main concepts/haptic_concept.html#quick-access",
    "href": "Main concepts/haptic_concept.html#quick-access",
    "title": "Haptic",
    "section": "Quick access",
    "text": "Quick access\n\nHaptic Subsystem\nExamples\nHaptic Data structures",
    "crumbs": [
      "Main concepts",
      "Haptic"
    ]
  },
  {
    "objectID": "Main concepts/haptic_concept.html#what-is-haptic-feedback",
    "href": "Main concepts/haptic_concept.html#what-is-haptic-feedback",
    "title": "Haptic",
    "section": "What is haptic feedback?",
    "text": "What is haptic feedback?\nHaptic feedback refers to the use of tactile sensations to communicate information to the user through touch. In wearable technology, haptic feedback is typically delivered via electrical stimulation, vibration, or temperature changes, allowing users to feel virtual objects, receive notifications, or experience immersive effects in virtual environments.\nHaptic technology is widely used in gaming, VR/AR, rehabilitation, and training applications to enhance realism and interactivity. By stimulating the skin and muscles, haptic feedback can simulate textures, impacts, or environmental cues, providing a richer and more engaging user experience.",
    "crumbs": [
      "Main concepts",
      "Haptic"
    ]
  },
  {
    "objectID": "Main concepts/haptic_concept.html#haptic-in-teslasuit",
    "href": "Main concepts/haptic_concept.html#haptic-in-teslasuit",
    "title": "Haptic",
    "section": "Haptic in Teslasuit",
    "text": "Haptic in Teslasuit\nThe Teslasuit integrates advanced haptic feedback technology, enabling precise and programmable tactile sensations across the body. The haptic subsystem in the Teslasuit allows developers to create, manage, and play haptic effects, including instant touches and looped playables, using a flexible API.\nThe Teslasuit’s haptic functionality is accessible through the TsHapticPlayer class, which provides methods for creating haptic effects, controlling playback, and customizing parameters such as amplitude, period, and pulse width. The haptic subsystem is tightly integrated with the Teslasuit API, allowing seamless incorporation of tactile feedback into applications.\nHaptic feedback electrodes are located as shown on the picture below:\n\n\n\nHaptic electrode scheme",
    "crumbs": [
      "Main concepts",
      "Haptic"
    ]
  },
  {
    "objectID": "Main concepts/haptic_concept.html#key-features-of-the-teslasuit-haptic-subsystem",
    "href": "Main concepts/haptic_concept.html#key-features-of-the-teslasuit-haptic-subsystem",
    "title": "Haptic",
    "section": "Key features of the Teslasuit haptic subsystem",
    "text": "Key features of the Teslasuit haptic subsystem\n\nProgrammable Haptic Effects: Developers can create custom haptic effects by specifying parameters such as amplitude, period, and pulse width, or by using pre-defined haptic assets.\nInstant Touches and Playables: The subsystem supports both instant haptic touches (short, parameterized effects) and playables (longer, asset-based effects that can be looped or sequenced).\nChannel Mapping: Haptic feedback can be targeted to specific body areas or channels, enabling localized sensations and complex patterns.\nReal-Time Control: The API allows real-time control over haptic playback, including pausing, muting, and adjusting multipliers for global effect scaling.",
    "crumbs": [
      "Main concepts",
      "Haptic"
    ]
  },
  {
    "objectID": "Main concepts/haptic_concept.html#how-the-teslasuit-api-implements-haptic-feedback",
    "href": "Main concepts/haptic_concept.html#how-the-teslasuit-api-implements-haptic-feedback",
    "title": "Haptic",
    "section": "How the Teslasuit API implements haptic feedback",
    "text": "How the Teslasuit API implements haptic feedback\nThe Teslasuit API provides a structured approach to accessing and utilizing haptic feedback. Below are the key steps involved:\n\nInitialization: The Teslasuit API must be initialized before accessing the haptic subsystem.\nDevice Connection: A Teslasuit device must be connected to access its haptic subsystem.\nSubsystem Access: The haptic subsystem is accessed through the haptic property of the connected device, returning an instance of the TsHapticPlayer class.\nEffect Creation and Playback: The TsHapticPlayer class provides methods to create haptic effects, play or stop them, and adjust parameters in real time.",
    "crumbs": [
      "Main concepts",
      "Haptic"
    ]
  },
  {
    "objectID": "Main concepts/haptic_concept.html#description-of-haptic-data",
    "href": "Main concepts/haptic_concept.html#description-of-haptic-data",
    "title": "Haptic",
    "section": "Description of haptic data",
    "text": "Description of haptic data\nBelow is a detailed description of the haptic data and data structures used in the Teslasuit API for the haptic subsystem.\n\nHaptic parameters\n\nWhat are haptic parameters?\nHaptic parameters define the characteristics of a haptic effect, such as how strong it feels, how long it lasts, and what pattern it follows. The main parameters include:\n\nPeriod: The duration of one cycle of the haptic signal, typically in milliseconds. It is inversely proportional to frequency, meaning a shorter period corresponds to a higher frequency.\nAmplitude: The strength or intensity of the haptic effect.\nPulse Width: The duration of each pulse within a period, affecting the sharpness of the sensation.\n\n\n\nWhy haptic parameters matter\nBy adjusting these parameters, developers can create a wide range of tactile sensations, from gentle vibrations to sharp pulses or even temperature changes. This flexibility allows for realistic simulation of touch, impact, or environmental effects.\n\n\nHaptic parameters in Teslasuit\nTeslasuit exposes haptic parameters through the TsHapticParam structure. Parameters can be grouped and passed to the haptic player to define instant touches or modify playables.\nMain haptic parameters are:\n\nAmplitude: Controls the strength or intensity of the haptic effect. Higher amplitude results in a stronger sensation. Amplitude is a value in percent, where 1% is the minimal value in Control Center calibration and 100% is maximal.\nPeriod: Specifies the duration of a single cycle of the haptic signal, measured in milliseconds. The period is inversely proportional to frequency and can be calculated using the formula: period (ms) = 1 / frequency (Hz) * 1000. The supported frequency range is from 1 Hz to 150 Hz.\nPulse Width: Specifies the duration of each pulse within a period, influencing the sharpness or smoothness of the sensation.\nDuration: Touch-specific parameter to set a precise duration (in milliseconds) for an instant haptic touch. This allows developers to control how long the sensation lasts, independent of the underlying signal period or amplitude.\n\nThese parameters can be combined and adjusted to create a wide variety of tactile effects tailored to specific application needs.\n\n\n\nHaptic playables\n\nAsset: A pre-designed haptic pattern created using the Haptic Editor, typically stored in the .ts_asset format.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo create playble from the file with format .ts_asset you need:\n\nLoad asset\n\nLoad asset from path using load_asset_from_path function from Asset manager.\n\nCreate playable\n\npass the object from step 1 to create playable function from Haptic subsystem:\n\n\n\n\n\n\nTouch: An instant, parameterized haptic effect designed for short, targeted stimulation.\nPlayable: Any haptic effect, either an asset or a touch, that is prepared and ready for playback.\n\n\n\n\n\n\nflowchart TD\n    A([Touch]) --&gt; B[[Playable]]\n    C([Asset]) --&gt; B\n \n\n\n\n\n\n\n\n\nHaptic multipliers\n\nMaster multiplier\nMaster multiplier changes aﬀect all playable items. There can be numerous multipliers, each corresponding to a specific haptic parameter type (such as amplitude, period, or pulse width). This allows you to globally adjust the intensity or characteristics of all haptic effects at once by modifying the relevant multiplier. For example, increasing the amplitude multiplier will make all haptic sensations stronger, while adjusting the period multiplier can change the frequency of all effects system-wide.\n\n\nPlayable multiplier\nPlayable multiplier affects a specific playable item, allowing fine-tuned control over its haptic parameters independently of the global (master) settings. There can be multiple multipliers, each corresponding to a different haptic parameter type (such as amplitude, period, or pulse width) for a given playable. This enables developers to dynamically adjust the intensity or characteristics of individual haptic effects during playback without altering the overall system behavior.\n\n\nTouch multiplier\nTouch multipliers allow you to adjust the intensity or characteristics of individual instant touches. By applying a multiplier to a touch, you can control parameters such as amplitude, period, or pulse width for that specific effect, without affecting other touches or playables. This enables precise, real-time customization of haptic sensations for each instant touch event.",
    "crumbs": [
      "Main concepts",
      "Haptic"
    ]
  },
  {
    "objectID": "Main concepts/haptic_concept.html#applications-of-haptic-feedback-in-teslasuit",
    "href": "Main concepts/haptic_concept.html#applications-of-haptic-feedback-in-teslasuit",
    "title": "Haptic",
    "section": "Applications of haptic feedback in Teslasuit",
    "text": "Applications of haptic feedback in Teslasuit\nThe haptic subsystem in the Teslasuit has a wide range of applications, including:\n\nImmersive VR/AR: Simulate touch, impact, or environmental effects for enhanced immersion.\nTraining and Simulation: Provide realistic feedback for muscle memory and skill acquisition.\nRehabilitation: Deliver targeted stimulation for therapy and recovery.\nGaming: Enhance gameplay with tactile cues and effects.",
    "crumbs": [
      "Main concepts",
      "Haptic"
    ]
  },
  {
    "objectID": "Main concepts/haptic_concept.html#scheme-of-correspondence-of-nodes-and-channels-for-haptic",
    "href": "Main concepts/haptic_concept.html#scheme-of-correspondence-of-nodes-and-channels-for-haptic",
    "title": "Haptic",
    "section": "Scheme of correspondence of nodes and channels for haptic",
    "text": "Scheme of correspondence of nodes and channels for haptic\nThe Teslasuit haptic subsystem organises stimulation points using a hierarchy of nodes and channels:\n\nNode: Unit which controls channels throughout the body region (e.g right arm).\nChannel: Group of electrodes connected to one channel in the node.\n\n\nMapping haptic effects to channels\nHaptic effects can be mapped to specific channels or groups of channels within the Teslasuit. This allows developers to target tactile sensations to precise areas of the body, enhancing realism and control. Channel mapping can be defined either within a haptic asset or when creating haptic effects programmatically, ensuring the effect is delivered to the intended location.\n\nNote: When working with predefined haptic assets (such as .ts_asset files), channel mapping is fixed within the asset and cannot be changed programmatically. If you prefer to define haptic touches in your code, rather than use haptic assets, please use the scheme below to target channels correctly. This approach helps avoid unexpected sensations and ensures that stimulation is applied only to the desired channels.\n\n\nCorrespondence scheme\n\n\n\nHaptic mapping scheme\n\n\nThis structure enables developers to deliver localised or distributed haptic effects by specifying the appropriate area or channel in their code.\n\n\n\n\n\n\n\n\n\nBody area\nBone index\nChannel on mapping scheme\nBone channel ID\n\n\n\n\nLeft Upper arm front\n12\n1,2,3\n0, 1, 2\n\n\nRight Upper arm front\n14\n1,2,3\n0, 1, 2\n\n\nLeft Upper arm back\n13\n9, 10, 11,12\n0, 1, 2, 3\n\n\nRight Upper arm back\n15\n9, 10, 11,12\n0, 1, 2, 3\n\n\nLeft lower arm front\n16\n4, 5, 6, 7, 8\n0, 1, 2, 3, 4\n\n\nRight lower arm front\n18\n4, 5, 6, 7, 8\n0, 1, 2, 3, 4\n\n\nLeft lower arm back\n17\n13, 14, 15, 16\n0, 1, 2, 3\n\n\nRight lower arm back\n19\n13, 14, 15, 16\n0, 1, 2, 3\n\n\nAbdomen\n8\n1, 2, 3, 4, 5, 6, 7, 8\n0, 1, 2, 3, 4, 5, 6, 7\n\n\nBack\n11\n9, 10, 11, 12, 13, 14, 15, 16\n0, 1, 2, 3, 4, 5, 6, 7\n\n\nLeft Upper leg front\n0\n3, 4, 5, 6, 7\n0, 1, 2, 3, 4\n\n\nRight Upper leg front\n2\n3, 4, 5, 6, 7\n0, 1, 2, 3, 4\n\n\nLeft Upper leg back\n1\n1, 2, 9, 10, 11, 12, 13\n0, 1, 2, 3, 4, 5, 6\n\n\nRight Upper leg back\n3\n1, 2, 9, 10, 11, 12, 13\n0, 1, 2, 3, 4, 5, 6\n\n\nLeft Lower leg front\n4\n8\n0\n\n\nRight Lower leg front\n6\n8\n0\n\n\nLeft Lower leg back\n5\n14, 15, 16\n0, 1, 2\n\n\nRight Lower leg back\n7\n14, 15, 16\n0, 1, 2\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nTo select the correct haptic channel in your code, follow these steps:\n\nRefer to the mapping scheme\n\nLocate the desired channel number on the mapping scheme above.\n\nConsult the table\n\nUse the table to find the corresponding bone index for the target body area and the bone channel ID for the channel.\n\nUse the correct Python code\n\nSee the example below for selecting channel 14 on the left arm:\n\n\n   # Initialize device \n   # ...\n   # Retrieve the haptic channel layout. Do this once and reuse the layout object.\n   layout = mapper.get_haptic_electric_channel_layout(device.get_mapping())\n   # Retrieve the bones structure. Also do this once and reuse.\n   bones = mapper.get_layout_bones(layout)\n   # According to the mapping scheme, channel 14 on the left lower arm (back) \n   # corresponds to bone index 17 and bone channel ID 1.\n   channel = mapper.get_bone_contents(bones[17][1])",
    "crumbs": [
      "Main concepts",
      "Haptic"
    ]
  },
  {
    "objectID": "Main concepts/haptic_concept.html#dependencies-in-data-structures-and-accessing-data",
    "href": "Main concepts/haptic_concept.html#dependencies-in-data-structures-and-accessing-data",
    "title": "Haptic",
    "section": "Dependencies in data structures and accessing data",
    "text": "Dependencies in data structures and accessing data\nThe Teslasuit haptic subsystem relies on a hierarchy of data structures to manage and process haptic effects. Below is a description of the dependencies between these structures and a block scheme illustrating how data is accessed.\n\nData structure dependencies\n\nTsHapticParam:\n\nRepresents a single haptic parameter (type and value).\n\nTsHapticParamMultiplier:\n\nRepresents a multiplier for a haptic parameter.\n\nTsHapticParamType:\n\nManages haptic playables, touches, and playback state.\n\n\n\n\nBlock scheme for accessing data\nBelow is a simplified block scheme illustrating the flow of data from parameter creation to playback:\n\n\n\n\n\nflowchart TD\n    A([TsHapticPlayer]) --&gt; B[[TsHapticParam]]\n    A --&gt; C[[TsHapticParamMultiplier]]\n    B --&gt; D((type))\n    B --&gt; E((value))\n    C --&gt; F((type))\n    C --&gt; G((value))",
    "crumbs": [
      "Main concepts",
      "Haptic"
    ]
  },
  {
    "objectID": "Main concepts/haptic_concept.html#example-code",
    "href": "Main concepts/haptic_concept.html#example-code",
    "title": "Haptic",
    "section": "Example code",
    "text": "Example code\nFor detailed examples of how to use the haptic subsystem in the Teslasuit API, refer to the Haptic Examples page. These examples demonstrate how to initialize the API, connect to a device, and play haptic effects.",
    "crumbs": [
      "Main concepts",
      "Haptic"
    ]
  },
  {
    "objectID": "Main concepts/haptic_concept.html#conclusion",
    "href": "Main concepts/haptic_concept.html#conclusion",
    "title": "Haptic",
    "section": "Conclusion",
    "text": "Conclusion\nThe haptic subsystem in the Teslasuit provides a powerful and flexible platform for delivering tactile feedback. By leveraging the Teslasuit API, developers can create immersive, interactive, and responsive experiences across a wide range of applications.",
    "crumbs": [
      "Main concepts",
      "Haptic"
    ]
  },
  {
    "objectID": "Main concepts/index.html",
    "href": "Main concepts/index.html",
    "title": "Overview",
    "section": "",
    "text": "TESLASUIT is a smart full-body suit designed as an advanced interface between the user and digital environments. The suit combines motion capture, haptic feedback, and biometric sensing to create a seamless and immersive connection with virtual worlds.\n\n\n\nMotion Capture (Mocap):\nTESLASUIT features 14 mocap sensors distributed across the jacket and trousers, including magnetometers, gyroscopes, and accelerometers. These sensors track the user’s movements in real time, enabling accurate avatar representation and interaction in VR and AR applications.\nHaptic Feedback:\nThe suit delivers precise tactile sensations using 80 haptic channels of shaped electrodes mapped to anatomically suitable locations. These electrodes stimulate skin and muscle nerves with electrical impulses, simulating touch and interaction with digital objects.\nBiometric Monitoring:\nTESLASUIT integrates a PPG (photoplethysmography) sensor on the right shoulder to monitor heart activity, enabling real-time tracking of heart rate and heart rate variability.\n\n\n\n\nTESLASUIT consists of two garments: the jacket and trousers. Each garment contains its own set of sensors and electrodes, managed by distributed nodes. The jacket houses the main control unit, which processes data from all nodes and coordinates the suit’s functions.\n\n\n\nThe suit is powered by a dedicated power bank located in a special pocket on the back of the jacket. Connectivity between the jacket and trousers, as well as to the power bank, is provided by USB Type-C cables. The modular design allows for flexible use, including",
    "crumbs": [
      "Main concepts",
      "Overview"
    ]
  },
  {
    "objectID": "Main concepts/index.html#integrated-systems",
    "href": "Main concepts/index.html#integrated-systems",
    "title": "Overview",
    "section": "",
    "text": "Motion Capture (Mocap):\nTESLASUIT features 14 mocap sensors distributed across the jacket and trousers, including magnetometers, gyroscopes, and accelerometers. These sensors track the user’s movements in real time, enabling accurate avatar representation and interaction in VR and AR applications.\nHaptic Feedback:\nThe suit delivers precise tactile sensations using 80 haptic channels of shaped electrodes mapped to anatomically suitable locations. These electrodes stimulate skin and muscle nerves with electrical impulses, simulating touch and interaction with digital objects.\nBiometric Monitoring:\nTESLASUIT integrates a PPG (photoplethysmography) sensor on the right shoulder to monitor heart activity, enabling real-time tracking of heart rate and heart rate variability.",
    "crumbs": [
      "Main concepts",
      "Overview"
    ]
  },
  {
    "objectID": "Main concepts/index.html#hardware-architecture",
    "href": "Main concepts/index.html#hardware-architecture",
    "title": "Overview",
    "section": "",
    "text": "TESLASUIT consists of two garments: the jacket and trousers. Each garment contains its own set of sensors and electrodes, managed by distributed nodes. The jacket houses the main control unit, which processes data from all nodes and coordinates the suit’s functions.",
    "crumbs": [
      "Main concepts",
      "Overview"
    ]
  },
  {
    "objectID": "Main concepts/index.html#connectivity-and-power",
    "href": "Main concepts/index.html#connectivity-and-power",
    "title": "Overview",
    "section": "",
    "text": "The suit is powered by a dedicated power bank located in a special pocket on the back of the jacket. Connectivity between the jacket and trousers, as well as to the power bank, is provided by USB Type-C cables. The modular design allows for flexible use, including",
    "crumbs": [
      "Main concepts",
      "Overview"
    ]
  },
  {
    "objectID": "examples/bia_example.html#quick-access",
    "href": "examples/bia_example.html#quick-access",
    "title": "BIA example (experimental)",
    "section": "Quick access",
    "text": "Quick access\n\nMain concept\nBIA Subsystem\nBIA data structures",
    "crumbs": [
      "Examples",
      "BIA example (experimental)"
    ]
  },
  {
    "objectID": "examples/bia_example.html#intro",
    "href": "examples/bia_example.html#intro",
    "title": "BIA example (experimental)",
    "section": "Intro",
    "text": "Intro\nThis web page provides a comprehensive guide on how to retrieve data from the BIA (Bioelectrical Impedance Analysis) subsystem of a Teslasuit device. The page is structured to help developers understand the process of initializing the Teslasuit API, connecting to a device, configuring the BIA subsystem, and streaming data.",
    "crumbs": [
      "Examples",
      "BIA example (experimental)"
    ]
  },
  {
    "objectID": "examples/bia_example.html#code-for-bia-data-streaming",
    "href": "examples/bia_example.html#code-for-bia-data-streaming",
    "title": "BIA example (experimental)",
    "section": "Code for BIA data streaming",
    "text": "Code for BIA data streaming\n1from teslasuit_sdk import ts_api\n\ndef main():\n2    print(\"Initializing Teslasuit API...\")\n    api = ts_api.TsApi()\n\n3    print(\"Waiting for a Teslasuit device to connect...\")\n    device = api.get_device_manager().get_or_wait_last_device_attached()\n\n4    print(\"Accessing the BIA subsystem...\")\n    bia = device.bia\n\n5    print(\"Setting up streaming configuration...\")\n    channels_indexes = [1, 3, 7, 9, 12]\n    bia.set_streaming_config(channels_indexes, 24000, 1, 1000)\n\n6    print(\"Starting BIA data streaming...\")\n    bia.start_streaming()\n\n    try:\n        while True:\n7            data = bia.get_data_on_ready()\n8            print(\"Number of channels:\", data.number_of_channels)\n            for channel in data.channels:\n9                print(\"Channel index:\", channel.channel_index)\n                for freq in channel.frequencies:\n10                    print(\"Frequency:\", freq.frequency)\n11                    print(\"Real part:\", freq.complex_number.real_value)\n12                    print(\"Imaginary part:\", freq.complex_number.im_value)\n    except KeyboardInterrupt:\n13        print(\"Stopping BIA streaming...\")\n        bia.stop_streaming()\n\n# Entry point for the script\nif __name__ == \"__main__\":\n14    main()\n\n1\n\nImport the main Teslasuit API module.\n\n2\n\nCreate an instance of the Teslasuit API.\n\n3\n\nWait for a Teslasuit device to be connected and get it.\n\n4\n\nAccess the BIA subsystem from the device.\n\n5\n\nConfigure the BIA subsystem for streaming.\n\n6\n\nStart streaming BIA data from the suit.\n\n7\n\nWait for BIA data to become available.\n\n8\n\nPrint the number of channels in the BIA data.\n\n9\n\nIterate through each channel and print its index.\n\n10\n\nPrint the frequency of each data point.\n\n11\n\nPrint the real part of the complex number for each frequency.\n\n12\n\nPrint the imaginary part of the complex number for each frequency.\n\n13\n\nStop streaming when interrupted.\n\n14\n\nStart the program using the main function.",
    "crumbs": [
      "Examples",
      "BIA example (experimental)"
    ]
  },
  {
    "objectID": "examples/bia_example.html#expected-output",
    "href": "examples/bia_example.html#expected-output",
    "title": "BIA example (experimental)",
    "section": "Expected output",
    "text": "Expected output\n1Initializing Teslasuit API...\n2Waiting for a Teslasuit device to connect...\n3Accessing the BIA subsystem...\n4Setting up streaming configuration...\n5Starting BIA data streaming...\n6Number of channels: 5\n7Channel index: 1\n8Frequency: 24000\n9Real part: 123\n10Imaginary part: 456\n...\n\n1\n\nThe API is initialized via api = ts_api.TsApi().\n\n2\n\nThe program waits for a Teslasuit device to connect using api.get_device_manager().get_or_wait_last_device_attached().\n\n3\n\nThe BIA subsystem of the connected device is accessed via device.bia.\n\n4\n\nStreaming configuration is set using bia.set_streaming_config().\n\n5\n\nBIA data streaming is initiated with bia.start_streaming().\n\n6\n\nThe program prints the number of channels in the BIA data.\n\n7\n\nThe channel index is printed for each channel.\n\n8\n\nThe frequency value is printed for each data point.\n\n9\n\nThe real part of the complex number is printed.\n\n10\n\nThe imaginary part of the complex number is printed.",
    "crumbs": [
      "Examples",
      "BIA example (experimental)"
    ]
  },
  {
    "objectID": "examples/current_feedback_example.html#quick-access",
    "href": "examples/current_feedback_example.html#quick-access",
    "title": "Current feedback example (experimental)",
    "section": "Quick access",
    "text": "Quick access\n\nMain concept\nCurrent feedback Subsystem\nCurrent feedback data structures",
    "crumbs": [
      "Examples",
      "Current feedback example (experimental)"
    ]
  },
  {
    "objectID": "examples/current_feedback_example.html#intro",
    "href": "examples/current_feedback_example.html#intro",
    "title": "Current feedback example (experimental)",
    "section": "Intro",
    "text": "Intro\nThis web page provides a comprehensive guide on how to retrieve current feedback data from a Teslasuit device. The page is structured to help developers understand the process of initializing the Teslasuit API, connecting to a device, accessing the Current Feedback subsystem, and streaming data from nodes and channels.",
    "crumbs": [
      "Examples",
      "Current feedback example (experimental)"
    ]
  },
  {
    "objectID": "examples/current_feedback_example.html#code-for-current-feedback-data",
    "href": "examples/current_feedback_example.html#code-for-current-feedback-data",
    "title": "Current feedback example (experimental)",
    "section": "Code for Current Feedback Data",
    "text": "Code for Current Feedback Data\n1from teslasuit_sdk import ts_api\n2import teslasuit_sdk.subsystems.ts_current_feedback\n\ndef main():\n3    print(\"Initializing Teslasuit API...\")\n    api = ts_api.TsApi()\n\n4    print(\"Waiting for a Teslasuit device to connect...\")\n    device = api.get_device_manager().get_or_wait_last_device_attached()\n\n5    print(\"Accessing the Current Feedback subsystem...\")\n    current_feedback = device.current_feedback\n\n6    print(\"Starting current feedback data streaming...\")\n    current_feedback.start_streaming()\n\n    print(\"Waiting for Current Feedback data...\")\n    nodes_data = {}\n    while True:\n7        data = current_feedback.get_data_on_ready()\n        for node in data.nodes:\n            for channel in node.channels_data:\n                nodes_data.setdefault(node.node_index, {})[channel.channel_index] = channel.value\n8                print(f\"Node {node.node_index}, Channel {channel.channel_index}: {channel.value}\")\n        if len(nodes_data.keys()) == 5:  # Adjust based on device configuration\n            break\n\n    print(\"Final Nodes Data:\", nodes_data)\n\n# Entry point for the script\nif __name__ == \"__main__\":\n9    main()\n\n1\n\nImport the main Teslasuit API module.\n\n2\n\nImport the Current Feedback subsystem from the SDK.\n\n3\n\nCreate an instance of the Teslasuit API.\n\n4\n\nWait for a Teslasuit device to be connected and get it.\n\n5\n\nAccess the Current Feedback subsystem from the device.\n\n6\n\nStart streaming current feedback data from the suit.\n\n7\n\nWait for current feedback data to become available.\n\n8\n\nPrint the node and channel data values.\n\n9\n\nStart the program using the main function.",
    "crumbs": [
      "Examples",
      "Current feedback example (experimental)"
    ]
  },
  {
    "objectID": "examples/current_feedback_example.html#expected-output",
    "href": "examples/current_feedback_example.html#expected-output",
    "title": "Current feedback example (experimental)",
    "section": "Expected output",
    "text": "Expected output\n1Initializing Teslasuit API...\n2Waiting for a Teslasuit device to connect...\n3Accessing the Current Feedback subsystem...\n4Starting current feedback data streaming...\n5Waiting for Current Feedback data...\n6Node 0, Channel 0: 123\nNode 0, Channel 1: 456\n...\n7Final Nodes Data: {0: {0: 123, 1: 456}, ...}\n\n1\n\nAPI is initialized via api = ts_api.TsApi().\n\n2\n\nThe program waits for a Teslasuit device to connect using api.get_device_manager().get_or_wait_last_device_attached().\n\n3\n\nThe Current Feedback subsystem of the connected device is accessed via device.current_feedback.\n\n4\n\nCurrent feedback data streaming is initiated with current_feedback.start_streaming().\n\n5\n\nThe program enters a loop to wait for current feedback data using current_feedback.get_data_on_ready().\n\n6\n\nNode and channel data values are printed as they become available.\n\n7\n\nThe final nodes data is displayed after streaming is complete.",
    "crumbs": [
      "Examples",
      "Current feedback example (experimental)"
    ]
  },
  {
    "objectID": "examples/force_feedback_example.html#quick-access",
    "href": "examples/force_feedback_example.html#quick-access",
    "title": "Force Feedback example",
    "section": "Quick access",
    "text": "Quick access\n\nMain concept\nForce Feedback Subsystem\nForce Feedback data structures",
    "crumbs": [
      "Examples",
      "Force Feedback example"
    ]
  },
  {
    "objectID": "examples/force_feedback_example.html#intro",
    "href": "examples/force_feedback_example.html#intro",
    "title": "Force Feedback example",
    "section": "Intro",
    "text": "Intro\nThis web page provides a comprehensive guide on how to use the Force Feedback feature of the Teslasuit device. The page is structured to help developers understand the process of initializing the Teslasuit API, connecting to a device, configuring force feedback parameters, and enabling/disabling force feedback.",
    "crumbs": [
      "Examples",
      "Force Feedback example"
    ]
  },
  {
    "objectID": "examples/force_feedback_example.html#code-for-force-feedback",
    "href": "examples/force_feedback_example.html#code-for-force-feedback",
    "title": "Force Feedback example",
    "section": "Code for Force Feedback",
    "text": "Code for Force Feedback\n\nimport time\n1from teslasuit_sdk import ts_api\n2from teslasuit_sdk.ts_mapper import TsBone2dIndex\n3from teslasuit_sdk.subsystems.ts_magnetic_encoder import (\n    TsForceFeedbackLockDirection, TsForceFeedbackConfig)\n\ndef main():\n    try:\n4        print(\"Initialize API\")\n        api = ts_api.TsApi()\n\n5        print(\"Waiting for a Teslasuit device to connect...\")\n        device = api.get_device_manager().get_or_wait_last_device_attached()\n\n6        print(\"Accessing the Magnetic Encoder subsystem...\")\n        encoder = device.magnetic_encoder\n\n7        print(\"Set force feedback angle\")\n        ff_config = [TsForceFeedbackConfig()]\n        ff_config[0].bone_index = TsBone2dIndex.RightThumbProximal.value\n        ff_config[0].angle = 45\n        ff_config[0].hardness_percent = 100\n        ff_config[0].lock_direction = TsForceFeedbackLockDirection.Both.value\n8        encoder.ts_force_feedback_enable(ff_config)\n\n9        time.sleep(10)\n10        print(\"Release force feedback\")\n        encoder.ts_force_feedback_disable([TsBone2dIndex.RightThumbProximal.value])\n11        print(\"Finished\")\n\n12    except (KeyboardInterrupt, SystemExit):\n        print('\\n! Received keyboard interrupt, quitting glove forcefeedback\\n')\n\n13main()\n\n1\n\nImport the main Teslasuit API module.\n\n2\n\nImport the bone index mapper for specifying bones.\n\n3\n\nImport the force feedback configuration and lock direction classes.\n\n4\n\nInitialize the Teslasuit API.\n\n5\n\nWait for a Teslasuit device to connect.\n\n6\n\nAccess the Magnetic Encoder subsystem of the connected device.\n\n7\n\nConfigure force feedback parameters, including bone index, angle, hardness, and lock direction.\n\n8\n\nEnable force feedback using the configured parameters.\n\n9\n\nWait for 10 seconds to observe the force feedback effect.\n\n10\n\nDisable force feedback for the specified bone index.\n\n11\n\nPrint a message indicating the process is finished.\n\n12\n\nHandle keyboard interrupts gracefully.\n\n13\n\nStart the program using the main function.",
    "crumbs": [
      "Examples",
      "Force Feedback example"
    ]
  },
  {
    "objectID": "examples/force_feedback_example.html#expected-output",
    "href": "examples/force_feedback_example.html#expected-output",
    "title": "Force Feedback example",
    "section": "Expected output",
    "text": "Expected output\n\n1Initialize API\n2Waiting for a Teslasuit device to connect...\n3Accessing the Magnetic Encoder subsystem...\n4Set force feedback angle\n5Release force feedback\n6Finished\n\n1\n\nThe API is initialized via api = ts_api.TsApi().\n\n2\n\nThe program waits for a Teslasuit device to connect using api.get_device_manager().get_or_wait_last_device_attached().\n\n3\n\nThe Magnetic Encoder subsystem of the connected device is accessed via device.magnetic_encoder.\n\n4\n\nForce feedback parameters are configured and enabled using encoder.ts_force_feedback_enable(ff_config).\n\n5\n\nForce feedback is disabled using encoder.ts_force_feedback_disable().\n\n6\n\nThe program prints a completion message.",
    "crumbs": [
      "Examples",
      "Force Feedback example"
    ]
  },
  {
    "objectID": "examples/index.html",
    "href": "examples/index.html",
    "title": "Overview",
    "section": "",
    "text": "On this page, you can find categorized examples of API usage for the Teslasuit SDK. Each example demonstrates how to interact with a specific subsystem or feature of the Teslasuit.",
    "crumbs": [
      "Examples",
      "Overview"
    ]
  },
  {
    "objectID": "examples/index.html#intro",
    "href": "examples/index.html#intro",
    "title": "Overview",
    "section": "",
    "text": "On this page, you can find categorized examples of API usage for the Teslasuit SDK. Each example demonstrates how to interact with a specific subsystem or feature of the Teslasuit.",
    "crumbs": [
      "Examples",
      "Overview"
    ]
  },
  {
    "objectID": "examples/index.html#examples",
    "href": "examples/index.html#examples",
    "title": "Overview",
    "section": "Examples",
    "text": "Examples\n\nSensor Data\n\nPPG: Retrieve heart rate and HRV data.\nEMG (experimental): Stream muscle activity data.\nBIA (experimental): Analyze body composition using impedance data.\n\n\n\nMotion Capture\n\nMocap: Stream biomechanical angles and IMU data.\n\n\n\nFeedback Systems\n\nForce Feedback (Teslaglove): Configure and control force feedback.\nHaptic: Create and play haptic feedback.\n\n\n\nCurrent Monitoring\n\nCurrent Feedback (experimental): Stream current feedback data from nodes and channels.",
    "crumbs": [
      "Examples",
      "Overview"
    ]
  },
  {
    "objectID": "api_docs.html",
    "href": "api_docs.html",
    "title": "api_docs",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "api_docs.html#quarto",
    "href": "api_docs.html#quarto",
    "title": "api_docs",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "Getting_started.html",
    "href": "Getting_started.html",
    "title": "Getting started",
    "section": "",
    "text": "Welcome to the Teslasuit API! This guide will help you take your first steps with the Teslasuit API — from setting up your environment to running your first haptic interaction.\nMake sure your Teslasuit is connected to your PC or laptop before continuing.",
    "crumbs": [
      "Home",
      "Getting started"
    ]
  },
  {
    "objectID": "Getting_started.html#welcome",
    "href": "Getting_started.html#welcome",
    "title": "Getting started",
    "section": "",
    "text": "Welcome to the Teslasuit API! This guide will help you take your first steps with the Teslasuit API — from setting up your environment to running your first haptic interaction.\nMake sure your Teslasuit is connected to your PC or laptop before continuing.",
    "crumbs": [
      "Home",
      "Getting started"
    ]
  },
  {
    "objectID": "Getting_started.html#requirements",
    "href": "Getting_started.html#requirements",
    "title": "Getting started",
    "section": "Requirements",
    "text": "Requirements\nTo get started, make sure the following requirements are met:\n\nTeslasuit device connected and recognized by the system\nTeslasuit Control Center installed (for suit calibration)\nTeslasuit SDK added to your PATH. To add Teslasuit SDK to your PATH, please read Environment setup",
    "crumbs": [
      "Home",
      "Getting started"
    ]
  },
  {
    "objectID": "Getting_started.html#environment-setup",
    "href": "Getting_started.html#environment-setup",
    "title": "Getting started",
    "section": "Environment Setup",
    "text": "Environment Setup\nBefore writing any code, make sure the Teslasuit SDK is available in your Python environment.\nIf you’re developing locally and the SDK is not in your PATH, you can use the following snippet to add it dynamically:\ntry:\n    import teslasuit_sdk\nexcept ImportError:\n    import os\n    import sys\n    sdk_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\n    sys.path.insert(0, sdk_path)\n    import teslasuit_sdk\n    print(f'Successfully added \\'{sdk_path}\\' into sys.path')",
    "crumbs": [
      "Home",
      "Getting started"
    ]
  },
  {
    "objectID": "Getting_started.html#first-steps",
    "href": "Getting_started.html#first-steps",
    "title": "Getting started",
    "section": "First steps",
    "text": "First steps\n\nConnect the Suit\nAfter connecting your Teslasuit to your PC or laptop, you’re ready to explore its capabilities using Python.\nTo begin, you need to:\n\nAttach the device\nInitialize the API and Device\nCreate a haptic playable\n\n ⚠️ Safety First! Please calibrate your suit in Control Center in order to avoid unpleasant or painful experience\n\n\nRun Your First Touch\nBelow is a complete example that demonstrates how to send a basic haptic touch to the right upper arm of the suit:\nimport time\nfrom teslasuit_sdk import ts_api\nimport teslasuit_sdk.subsystems.ts_haptic\nfrom teslasuit_sdk.ts_mapper import TsBone2dIndex\n\nTOUCH_DURATION_MS = 1000\n\ndef main():\n    print(\"Initialize API\")\n    api = ts_api.TsApi()\n    device = api.get_device_manager().get_or_wait_last_device_attached()\n    player = device.haptic\n    mapper = api.mapper\n\n    print(\"Setup channels to play and touch parameters\")\n    layout = mapper.get_haptic_electric_channel_layout(device.get_mapping())\n    bones = mapper.get_layout_bones(layout)\n    channels = mapper.get_bone_contents(bones[TsBone2dIndex.RightUpperArm.value])\n    params = player.create_touch_parameters(100, 40, 150)\n\n    print(\"Create touch and play\")\n    playable_id = player.create_touch(params, channels, TOUCH_DURATION_MS)\n    player.play_playable(playable_id)\n\n    print(\"Wait until playback finished...\")\n    time.sleep(TOUCH_DURATION_MS / 1000)\n    print(\"Finished\")\n\n\nif __name__ == '__main__':\n    main()",
    "crumbs": [
      "Home",
      "Getting started"
    ]
  },
  {
    "objectID": "Getting_started.html#test-your-setup",
    "href": "Getting_started.html#test-your-setup",
    "title": "Getting started",
    "section": "Test Your Setup",
    "text": "Test Your Setup\nIf the suit is connected and the SDK is installed correctly, running the script above should produce a short haptic effect on the right upper arm of the suit.\nIf nothing happens:\n\nEnsure the device is calibrated in the Control Center\nCheck the connection\nConfirm that Python can import the teslasuit_sdk module",
    "crumbs": [
      "Home",
      "Getting started"
    ]
  },
  {
    "objectID": "Getting_started.html#explore-more",
    "href": "Getting_started.html#explore-more",
    "title": "Getting started",
    "section": "Explore more",
    "text": "Explore more\nReady to dive deeper?\n\nLearn about Teslasuit systems in the Main concepts section.\nExplore the Core and Subsystems API in the API Reference.\nWalk through various Examples to get started with specific suit features.\nGet inspired by real-world applications in the Use cases section",
    "crumbs": [
      "Home",
      "Getting started"
    ]
  },
  {
    "objectID": "API Reference/subsystems/emg.html#quick-access",
    "href": "API Reference/subsystems/emg.html#quick-access",
    "title": "EMG (experimental)",
    "section": "Quick access",
    "text": "Quick access\n\nMain concept\nExamples\nEMG data structures",
    "crumbs": [
      "API Reference",
      "Subsystems",
      "EMG (experimental)"
    ]
  },
  {
    "objectID": "API Reference/subsystems/emg.html#intro",
    "href": "API Reference/subsystems/emg.html#intro",
    "title": "EMG (experimental)",
    "section": "Intro",
    "text": "Intro\nThe EMG subsystem provides functionality to access and process Electromyography (EMG) data from Teslasuit devices.\n\nNote:\nSince TsEmg is a member of the device class, it cannot be used independently without an active Teslasuit device.",
    "crumbs": [
      "API Reference",
      "Subsystems",
      "EMG (experimental)"
    ]
  },
  {
    "objectID": "API Reference/subsystems/emg.html#class-tsemg",
    "href": "API Reference/subsystems/emg.html#class-tsemg",
    "title": "EMG (experimental)",
    "section": "Class TsEmg",
    "text": "Class TsEmg\nProvides an interface for interacting with the Teslasuit EMG subsystem.\nThis class allows for streaming EMG data, setting filter options, and retrieving raw EMG data.\n\nClass methods:\n\nset_options(self, lower_bandwidth, upper_bandwidth, sample_frequency, sample_size)\nSet options for EMG streaming, such as filter parameters.\nArgs:\n\nlower_bandwidth (int): Filter’s lower bandwidth.\n\nupper_bandwidth (int): Filter’s upper bandwidth.\n\nsample_frequency (int): Sampling frequency.\n\nsample_size (int): Sample size.\n\n\nstart_streaming(self)\nStart EMG streaming for a provided device handle.\nThis method subscribes to the data update callbacks and starts the streaming process.\n\nstop_streaming(self)\nStop EMG streaming for a provided device handle.\nThis method unsubscribes from the data update callbacks and stops the streaming process.\n\nget_data_on_ready(self)\nWait until EMG data is ready and retrieve it.\nThis method blocks until data is available or streaming is stopped.\nReturns:\n\nTsEmgData: The latest EMG data object containing information about nodes, channels, and timestamps.",
    "crumbs": [
      "API Reference",
      "Subsystems",
      "EMG (experimental)"
    ]
  },
  {
    "objectID": "API Reference/subsystems/emg.html#access-to-the-data",
    "href": "API Reference/subsystems/emg.html#access-to-the-data",
    "title": "EMG (experimental)",
    "section": "Access to the data",
    "text": "Access to the data\nThese code snippets and charts are just an example of how is the data flow looks like. to know more, please visit data structures page.\n\nAccess to EMG channel data\nTsEmg.get_data_on_ready().nodes[0].channels[0].samples[0]\n\n\n\n\n\nflowchart TD\nA[TsEmgData] --&gt; B[TsEmgNodeData]\nB --&gt; C[TsEmgChannelData]\nC --&gt; D[samples]\n\n\n\n\n\n\n\n\nAccess to EMG options\nTsEmg.get_data_on_ready().options.lower_bandwidth\n\n\n\n\n\nflowchart TD\nA[TsEmgOptions] --&gt; B[lower_bandwidth]\nA --&gt; C[upper_bandwidth]\nA --&gt; D[sampling_frequency]\nA --&gt; E[sample_size]",
    "crumbs": [
      "API Reference",
      "Subsystems",
      "EMG (experimental)"
    ]
  },
  {
    "objectID": "API Reference/subsystems/index.html",
    "href": "API Reference/subsystems/index.html",
    "title": "Overview",
    "section": "",
    "text": "In this section, you can find documentation for the API subsystems responsible for communication with various Teslasuit and Teslaglove functionalities.",
    "crumbs": [
      "API Reference",
      "Subsystems",
      "Overview"
    ]
  },
  {
    "objectID": "API Reference/subsystems/index.html#intro",
    "href": "API Reference/subsystems/index.html#intro",
    "title": "Overview",
    "section": "",
    "text": "In this section, you can find documentation for the API subsystems responsible for communication with various Teslasuit and Teslaglove functionalities.",
    "crumbs": [
      "API Reference",
      "Subsystems",
      "Overview"
    ]
  },
  {
    "objectID": "API Reference/subsystems/index.html#prerequisites",
    "href": "API Reference/subsystems/index.html#prerequisites",
    "title": "Overview",
    "section": "Prerequisites",
    "text": "Prerequisites\nBefore you have access to any subsystem, ensure the following steps are completed:\n\nTeslasuit API Initialization The Teslasuit API must be initialized before accessing any of its features.\nConnected Teslasuit Device A Teslasuit device must be connected. If no device is available, the system will wait until one is attached.\n\n💡 Note: The availability of the system depends on the type and version of your product.",
    "crumbs": [
      "API Reference",
      "Subsystems",
      "Overview"
    ]
  },
  {
    "objectID": "API Reference/subsystems/index.html#subsystems",
    "href": "API Reference/subsystems/index.html#subsystems",
    "title": "Overview",
    "section": "Subsystems",
    "text": "Subsystems\n\nHaptic: Enables control of haptic feedback, including instant touches and looped playables.\nMocap: Streams motion capture data, including raw sensor data, skeleton data, and biomechanical angles.\nPPG: Provides access to PPG sensor data, including raw data, HRV, and heart rate.\nForce feedback (Teslaglove): Manages servomotor control for haptic feedback and movement restriction.\nEMG (experimental): Provides access to EMG data for muscle activity analysis.\nCurrent feedback(experimental): Streams and processes current feedback data from Teslasuit devices.\nBIA (experimental): Handles BIA data streaming and configuration.",
    "crumbs": [
      "API Reference",
      "Subsystems",
      "Overview"
    ]
  },
  {
    "objectID": "API Reference/subsystems/haptic.html#quick-access",
    "href": "API Reference/subsystems/haptic.html#quick-access",
    "title": "Haptic",
    "section": "Quick access",
    "text": "Quick access\n\nMain concept\nExamples\nHaptic data structures",
    "crumbs": [
      "API Reference",
      "Subsystems",
      "Haptic"
    ]
  },
  {
    "objectID": "API Reference/subsystems/haptic.html#intro",
    "href": "API Reference/subsystems/haptic.html#intro",
    "title": "Haptic",
    "section": "Intro",
    "text": "Intro\nThe Haptic subsystem provides functionality to control haptic feedback on the Teslasuit. It allows developers to create, manage, and play haptic effects, including instant touches and looped playables.\n\nNote:\nSince TsHapticPlayer is a member of the device class, it cannot be used independently without an active Teslasuit device.",
    "crumbs": [
      "API Reference",
      "Subsystems",
      "Haptic"
    ]
  },
  {
    "objectID": "API Reference/subsystems/haptic.html#class-tshapticplayer",
    "href": "API Reference/subsystems/haptic.html#class-tshapticplayer",
    "title": "Haptic",
    "section": "Class TsHapticPlayer",
    "text": "Class TsHapticPlayer\nHandles haptic feedback management, including creating and controlling haptic playables and instant touches.\n\nClass methods:\n\nis_player_running(self)\nChecks if the haptic player is currently running.\nReturns:\n- bool: True if the player is running.\n\nstop_player(self)\nStops the haptic player for the connected device.\n\nis_player_paused(self)\nChecks if the haptic player is in a paused state.\nReturns:\n- bool: True if the player is paused.\n\nset_player_paused(self, is_paused)\nPauses or resumes the haptic player.\nArgs:\n- is_paused (bool): True to pause, False to resume.\n\nis_player_muted(self)\nChecks if the haptic player is muted.\nReturns:\n- bool: True if the player is muted.\n\nset_player_muted(self, is_muted)\nMutes or unmutes the haptic player.\nArgs:\n- is_muted (bool): True to mute, False to unmute.\n\nget_player_time(self)\nRetrieves the time elapsed since the haptic player started.\nReturns:\n- int: Time in milliseconds.\n\nget_number_of_master_multipliers(self)\nGets the number of master multipliers for the haptic player.\nReturns:\n- int: Number of multipliers.\n\nget_master_multipliers(self)\nGets the list of master multipliers for the haptic player.\nReturns:\n- list: List of TsHapticParamMultiplier.\n\nset_master_multipliers(self, multipliers)\nSets the master multipliers for the haptic player.\nArgs:\n- multipliers (list): List of TsHapticParamMultiplier.\n\nget_master_multiplier(self, type)\nGets a specific master multiplier by type.\nArgs:\n- type (TsHapticParamType): Type of the parameter.\nReturns:\n- TsHapticParamMultiplier\n\nset_master_multiplier(self, multiplier)\nSets a specific master multiplier.\nArgs:\n- multiplier (TsHapticParamMultiplier)\n\ncreate_playable(self, asset, is_looped)\nCreates a playable from a haptic asset.\nArgs:\n- asset: The haptic asset.\n- is_looped (bool): Whether the playable should loop.\nReturns:\n- int: The ID of the created playable.\n\nis_playable_exists(self, playable_id)\nChecks if a haptic playable exists.\nArgs:\n- playable_id (int): The ID of the playable.\nReturns:\n- bool: True if the playable exists.\n\nplay_playable(self, playable_id)\nPlays a haptic playable by its ID.\nArgs:\n- playable_id (int): The ID of the playable.\n\nplay_touch(self, params, channels, duration)\nPlays an instant haptic touch with the specified parameters.\nArgs:\n- params (list): List of TsHapticParam objects.\n- channels (list): List of channel IDs.\n- duration (int): Duration in milliseconds.\n\ncreate_touch(self, params, channels, duration)\nCreates a haptic touch with the specified parameters.\nArgs:\n- params (list): List of TsHapticParam objects.\n- channels (list): List of channel IDs.\n- duration (int): Duration in milliseconds.\nReturns:\n- int: The ID of the created touch (playable).\n\nis_playable_playing(self, playable_id)\nChecks if a haptic playable is currently playing.\nArgs:\n- playable_id (int): The ID of the playable.\nReturns:\n- bool: True if the playable is playing.\n\nstop_playable(self, playable_id)\nStops a haptic playable by its ID.\nArgs:\n- playable_id (int): The ID of the playable.\n\nremove_playable(self, playable_id)\nRemoves a haptic playable from the player.\nArgs:\n- playable_id (int): The ID of the playable.\n\nget_playable_paused(self, playable_id)\nChecks if a haptic playable is paused.\nArgs:\n- playable_id (int): The ID of the playable.\nReturns:\n- bool: True if the playable is paused.\n\nset_playable_paused(self, playable_id, is_paused)\nPauses or resumes a haptic playable.\nArgs:\n- playable_id (int): The ID of the playable.\n- is_paused (bool): True to pause, False to resume.\n\nget_playable_muted(self, playable_id)\nChecks if a haptic playable is muted.\nArgs:\n- playable_id (int): The ID of the playable.\nReturns:\n- bool: True if the playable is muted.\n\nset_playable_muted(self, playable_id, is_muted)\nMutes or unmutes a haptic playable.\nArgs:\n- playable_id (int): The ID of the playable.\n- is_muted (bool): True to mute, False to unmute.\n\nget_playable_looped(self, playable_id)\nChecks if a haptic playable is looped.\nArgs:\n- playable_id (int): The ID of the playable.\nReturns:\n- bool: True if the playable is looped.\n\nset_playable_looped(self, playable_id, is_looped)\nSets a haptic playable to loop or not.\nArgs:\n- playable_id (int): The ID of the playable.\n- is_looped (bool): True to loop, False otherwise.\n\nget_number_of_playable_multipliers(self, playable_id)\nGets the number of multipliers for a playable.\nArgs:\n- playable_id (int): The ID of the playable.\nReturns:\n- int: Number of multipliers.\n\nget_playable_multipliers(self, playable_id)\nGets the multipliers for a playable.\nArgs:\n- playable_id (int): The ID of the playable.\nReturns:\n- list: List of TsHapticParamMultiplier.\n\nset_playable_multipliers(self, playable_id, multipliers)\nSets the multipliers for a playable.\nArgs:\n- playable_id (int): The ID of the playable.\n- multipliers (list): List of TsHapticParamMultiplier.\n\nget_playable_local_time(self, playable_id)\nGets the local playback time of a playable.\nArgs:\n- playable_id (int): The ID of the playable.\nReturns:\n- int: Local time in milliseconds.\n\nset_playable_local_time(self, playable_id, local_time)\nSets the local playback time of a playable.\nArgs:\n- playable_id (int): The ID of the playable.\n- local_time (int): Local time in milliseconds.\n\nget_playable_duration(self, playable_id)\nGets the duration of a playable.\nArgs:\n- playable_id (int): The ID of the playable.\nReturns:\n- int: Duration in milliseconds.\n\nclear_all_playables(self)\nRemoves all haptic playables from the haptic player.\n\nadd_channel_to_dynamic_playable(self, channel_id, playable_id)\nAdds a channel to a dynamic haptic playable.\nArgs:\n- channel_id: Channel ID.\n- playable_id (int): The ID of the playable.\n\nremove_channel_from_dynamic_playable(self, channel_id, playable_id)\nRemoves a channel from a dynamic haptic playable.\nArgs:\n- channel_id: Channel ID.\n- playable_id (int): The ID of the playable.\n\nset_material_channel_impact(self, channel_id, impact, playable_id)\nSets the channel impact for a haptic material.\nArgs:\n- channel_id: Channel ID.\n- impact (float): Impact value.\n- playable_id (int): The ID of the playable.\n\ncreate_touch_parameters(self, period_ms, amplitude, pulse_width)\nCreates parameters for an instant haptic touch.\nArgs:\n- period_ms (float): Period in milliseconds.\n- amplitude (float): Amplitude value.\n- pulse_width (float): Pulse width value.\nReturns:\n- list: List of TsHapticParam objects.\n\ncreate_touch_multipliers(self, period_ms_m, amplitude_m, pulse_width_m)\nCreates multipliers for an instant haptic touch.\nArgs:\n- period_ms_m (float): Period multiplier.\n- amplitude_m (float): Amplitude multiplier.\n- pulse_width_m (float): Pulse width multiplier.\nReturns:\n- list: List of TsHapticParamMultiplier objects.",
    "crumbs": [
      "API Reference",
      "Subsystems",
      "Haptic"
    ]
  },
  {
    "objectID": "API Reference/subsystems/haptic.html#access-to-the-data",
    "href": "API Reference/subsystems/haptic.html#access-to-the-data",
    "title": "Haptic",
    "section": "Access to the data",
    "text": "Access to the data\nThese code snippets and charts are just an example of how the data flow looks like. To know more, please visit data structures page.\n\nAccess to haptic player multipliers\nTsHapticPlayer.get_master_multipliers()[0].value\n\n\n\n\n\nflowchart TD\nA[TsHapticParamMultiplier] --&gt; B[type]\nA --&gt; C[value]\n\n\n\n\n\n\n\n\nAccess to haptic touch parameters\nTsHapticPlayer.create_touch_parameters(10, 0.5, 0.2)[0].value\n\n\n\n\n\nflowchart TD\nA[TsHapticParam] --&gt; B[type]\nA --&gt; C[value]",
    "crumbs": [
      "API Reference",
      "Subsystems",
      "Haptic"
    ]
  },
  {
    "objectID": "API Reference/subsystems/mocap.html#quick-access",
    "href": "API Reference/subsystems/mocap.html#quick-access",
    "title": "Mocap",
    "section": "Quick access",
    "text": "Quick access\n\nMain concept\nExamples\nUsecase\nMocap data structures",
    "crumbs": [
      "API Reference",
      "Subsystems",
      "Mocap"
    ]
  },
  {
    "objectID": "API Reference/subsystems/mocap.html#intro",
    "href": "API Reference/subsystems/mocap.html#intro",
    "title": "Mocap",
    "section": "Intro",
    "text": "Intro\nBiometry subsystem provides functions to access Mocap functionality.\n\nNote:\nSince TsMocap is a member of the device class, it cannot be used independently without an active Teslasuit device.",
    "crumbs": [
      "API Reference",
      "Subsystems",
      "Mocap"
    ]
  },
  {
    "objectID": "API Reference/subsystems/mocap.html#class-tsmocap",
    "href": "API Reference/subsystems/mocap.html#class-tsmocap",
    "title": "Mocap",
    "section": "Class TsMocap",
    "text": "Class TsMocap\nProvides an interface for interacting with the Teslasuit motion capture (mocap) subsystem.\nThis class allows for streaming motion capture data, retrieving raw sensor data, skeleton data for individual bones, and calibration.\n\nClass methods:\n\nstart_streaming(self)\nStart mocap streaming for a provided device handle.\nThis method subscribes to the raw data and skeleton data update callbacks and starts the streaming process.\n\nstop_streaming(self)\nStop mocap streaming for a provided device handle.\nThis method unsubscribes from the raw data and skeleton data update callbacks and stops the streaming process.\n\ncalibrate_skeleton(self)\nCalibrate mocap skeleton model.\nThis method triggers the calibration process for the skeleton model to ensure accurate motion capture data.\n\nget_raw_data_on_ready(self)\nWait until raw mocap data is ready and retrieve it.\nThis method blocks until raw data is available or streaming is stopped.\nReturns:\n\ndict: A dictionary containing raw sensor data for all bones in format of TsMocapSensor structure.\n\n\nget_skeleton_data_on_ready(self)\nWait until skeleton mocap data is ready and retrieve it.\nThis method blocks until skeleton data is available or streaming is stopped.\nReturns:\n\ndict: A dictionary containing skeleton data for all bones in format of TsMocapBone structure.\n\n\nget_biomechanical_angles_on_ready(self)\nWait until biomechanical angles data is ready and retrieve it.\nThis method blocks until biomechanical angles data is available or streaming is stopped.\nReturns:\n\ndict: A dictionary containing biomechanical angles for all bones in format 'TsBiomechanicalIndex': angle value.",
    "crumbs": [
      "API Reference",
      "Subsystems",
      "Mocap"
    ]
  },
  {
    "objectID": "API Reference/subsystems/mocap.html#access-to-the-data",
    "href": "API Reference/subsystems/mocap.html#access-to-the-data",
    "title": "Mocap",
    "section": "Access to the data",
    "text": "Access to the data\nThese code snippets and charts are just an example of how is the data flow looks like. to know more, please visit data structures page.\n\nAccess to raw sensor data\nTsMocap.get_raw_data_on_ready()[TsBone2dIndex.LeftUpperArm].gyro.x\n\n\n\n\n\nflowchart TD\nA[TsMocapSensor] --&gt; B[gyro]\nB --&gt; C[x]\nB --&gt; D[y]\nB --&gt; E[z]\n\n\n\n\n\n\n\n\nAccess to skeleton data\nTsMocap.get_skeleton_data_on_ready()[TsBone2dIndex.LeftUpperArm].position.x\n\n\n\n\n\nflowchart TD\nA[TsMocapBone] --&gt; B[position]\nB --&gt; C[x]\nB --&gt; D[y]\nB --&gt; E[z]\n\n\n\n\n\n\n\n\nAccess to biomechanical angles\nTsMocap.get_biomechanical_angles_on_ready()[TsBiomechanicalIndex.LeftElbowFlexion]\n\n\n\n\n\nflowchart TD\nA[TsBiomechanicalIndex] --&gt; B[angle_value]",
    "crumbs": [
      "API Reference",
      "Subsystems",
      "Mocap"
    ]
  },
  {
    "objectID": "API Reference/core/device.html#quick-access",
    "href": "API Reference/core/device.html#quick-access",
    "title": "Device",
    "section": "Quick access",
    "text": "Quick access\n\nMain concept\nExamples\nUsecase",
    "crumbs": [
      "API Reference",
      "Core",
      "Device"
    ]
  },
  {
    "objectID": "API Reference/core/device.html#intro",
    "href": "API Reference/core/device.html#intro",
    "title": "Device",
    "section": "Intro",
    "text": "Intro\nThe Device module provides functions for connecting to TESLASUIT devices, subscribing to connections and disconnections of TESLASUIT devices, retrieving device information, and controlling the device.\n\nNote:\nSince TsDevice is the main entry point for interacting with a Teslasuit device, it must be instantiated before accessing any subsystems.",
    "crumbs": [
      "API Reference",
      "Core",
      "Device"
    ]
  },
  {
    "objectID": "API Reference/core/device.html#class-tsdevice",
    "href": "API Reference/core/device.html#class-tsdevice",
    "title": "Device",
    "section": "Class TsDevice",
    "text": "Class TsDevice\nHandles the connection, control, and information retrieval for a Teslasuit device. This class also provides access to various subsystems such as motion capture, haptics, and biometry.\n\nAttributes:\n\ndevice_uuid: UUID of the device.\nmocap: TsMocap class that provides access to the motion capture subsystem.\n\nemg: TsEmg class that provides access to the EMG subsystem.\n\nppg: TsPpg class that provides access to the PPG subsystem.\n\ncurrent_feedback: TsCurrentFeedback class that provides access to the current feedback subsystem.\n\nmagnetic_encoder: TsMagneticEncoder class that provides access to the magnetic encoder subsystem.\n\nhaptic: TsHapticPlayer class that provides access to the haptic subsystem.\n\nbia: TsBia class that provides access to the BIA subsystem.\n\n\n\nClass methods:\n\nget_device_ssid(self)\nRetrieves the SSID of the device.\nReturns:\n\nlist: SSID of the device.\n\n\nget_device_serial(self)\nRetrieves the serial number of the device.\nReturns:\n\nstr: Serial number of the device.\n\n\nget_product_type(self)\nRetrieves the product type of the device.\nReturns:\n\nTsDeviceType: Product type of the device.\n\n\nget_mapping(self)\nRetrieves the mapping according to the device type and version.\nReturns:\n\nTsMapping2D: Mapping of the device.\n\n\n\nSubsystems:\nThe TsDevice class provides access to the following subsystems:\n\nMotion Capture (TsMocap)\n\nEMG (TsEmg)\n\nPPG (TsPpg)\n\nCurrent Feedback (TsCurrentFeedback)\n\nMagnetic Encoder (TsMagneticEncoder)\n\nHaptics (TsHapticPlayer)\n\nBIA (TsBia)\n\nNotes Each subsystem requires an active connection to a Teslasuit device. Refer to the respective subsystem documentation for more details.",
    "crumbs": [
      "API Reference",
      "Core",
      "Device"
    ]
  },
  {
    "objectID": "API Reference/core/mapper.html#quick-access",
    "href": "API Reference/core/mapper.html#quick-access",
    "title": "Mapper",
    "section": "Quick access",
    "text": "Quick access\n\nMain concept\nExamples\nUsecase",
    "crumbs": [
      "API Reference",
      "Core",
      "Mapper"
    ]
  },
  {
    "objectID": "API Reference/core/mapper.html#intro",
    "href": "API Reference/core/mapper.html#intro",
    "title": "Mapper",
    "section": "Intro",
    "text": "Intro\nThe Mapper subsystem provides functionality to handle 2D mapping of device elements, including layouts, bones, and their associated data.\n\nNote:\nSince TsMapper interacts with device mappings, it cannot be used independently without an active Teslasuit device.",
    "crumbs": [
      "API Reference",
      "Core",
      "Mapper"
    ]
  },
  {
    "objectID": "API Reference/core/mapper.html#class-tsmapper",
    "href": "API Reference/core/mapper.html#class-tsmapper",
    "title": "Mapper",
    "section": "Class TsMapper",
    "text": "Class TsMapper\nMapping represents a set of device’s elements mapped on 2d space. Elements are described by the 2D Polygon - an array of points. Elements are bound to bones, a full set of bones is included in a layout, multiple layouts with the same element types are contained in an array, an array of layouts with same type are packed by TsLayout2dType and TsLayout2dElementType. Mappings might have different versions. Mapping can be requested by a mapping version or by a device handler because each device has a bound mapping version by default.\n\nClass methods:\n\nget_mapping_by_device(self, device)\nGet the default mapping handler for a device.\nArgs:\n\ndevice class (TsDevice): Device handle.\n\nReturns:\n\nTsMapping2d: Mapping handler.\n\n\nget_mapping_by_version(self, version)\nGet the mapping handler by the mapping version.\nArgs:\n\nversion (TsMapping2dVersion): Mapping version.\n\nReturns:\n\nTsMapping2d: Mapping handler.\n\n\nget_number_of_layouts(self, mapping)\nGet the number of layouts in the mapping.\nArgs:\n\nmapping (TsMapping2d): Mapping handler.\n\nReturns:\n\nint: Number of layouts.\n\n\nget_layouts(self, mapping)\nGet all layouts in the mapping.\nArgs:\n\nmapping (TsMapping2d): Mapping handler.\n\nReturns:\n\nlist: List of layouts.\n\n\nget_layout_index(self, layout)\nGet the index of a layout.\nArgs:\n\nlayout (TsLayout): Layout handle.\n\nReturns:\n\nint: Layout index.\n\n\nget_layout_type(self, layout)\nGet the type of a layout.\nArgs:\n\nlayout (TsLayout): Layout handle.\n\nReturns:\n\nint: Layout type.\n\n\nget_layout_element_type(self, layout)\nGet the element type of a layout.\nArgs:\n\nlayout (TsLayout): Layout handle.\n\nReturns:\n\nint: Layout element type.\n\n\nget_number_of_bones(self, layout)\nGet the number of bones in a layout.\nArgs:\n\nlayout (TsLayout): Layout handle.\n\nReturns:\n\nint: Number of bones.\n\n\nget_layout_bones(self, layout)\nGet all bones in a layout.\nArgs:\n\nlayout (TsLayout): Layout handle.\n\nReturns:\n\nlist: List of bones.\n\n\nget_bone_index(self, bone_handle)\nGet the index of a bone.\nArgs:\n\nbone_handle (TsBone): Bone handle.\n\nReturns:\n\nint: Bone index.\n\n\nget_bone_side(self, bone_handle)\nGet the side of a bone.\nArgs:\n\nbone_handle (TsBone): Bone handle.\n\nReturns:\n\nint: Bone side.\n\n\nget_bone_number_of_contents(self, bone_handle)\nGet the number of contents in a bone.\nArgs:\n\nbone_handle (TsBone): Bone handle.\n\nReturns:\n\nint: Number of contents.\n\n\nget_bone_contents(self, bone_handle)\nGet all contents of a bone.\nArgs:\n\nbone_handle (TsBone): Bone handle.\n\nReturns:\n\nlist: List of bone contents.\n\n\nget_bone_number_of_points(self, bone_handle)\nGet the number of points in a bone content.\nArgs:\n\nbone_handle (TsBone): Bone handle.\n\nReturns:\n\nint: Number of points.\n\n\nget_bone_points(self, bone_handle)\nGet the points representing the shape of a bone content in 2D space.\nArgs:\n\nbone_handle (TsBone): Bone handle.\n\nReturns:\n\nlist: List of points.\n\n\nget_haptic_electric_channel_layout(self, mapping)\nGet the electric channel layout for haptic feedback.\nArgs:\n\nmapping (TsMapping2d): Mapping handler.\n\nReturns:\n\nTsLayout: Electric channel layout handle.\n\n\n\nMapping Utils:\n\nget_layout_by_type(self, mapping, layout_type, layout_element_type)\nGet a layout by its type and element type.\nArgs:\n\nmapping (TsMapping2d): Mapping handler.\n\nlayout_type (int): Layout type.\n\nlayout_element_type (int): Layout element type.\n\nReturns:\n\nTsLayout: Layout handle.\n\n\nget_haptic_electric_channel_layout(self, mapping)\nGet the electric channel layout for haptic feedback.\nArgs:\n\nmapping (TsMapping2d): Mapping handler.\n\nReturns:\n\nTsLayout: Electric channel layout handle.",
    "crumbs": [
      "API Reference",
      "Core",
      "Mapper"
    ]
  },
  {
    "objectID": "API Reference/core/loader.html#quick-access",
    "href": "API Reference/core/loader.html#quick-access",
    "title": "Loader",
    "section": "Quick access",
    "text": "Quick access\n\nMain concept\nExamples\nUsecase"
  },
  {
    "objectID": "API Reference/core/loader.html#intro",
    "href": "API Reference/core/loader.html#intro",
    "title": "Loader",
    "section": "Intro",
    "text": "Intro\nThe Loader subsystem provides functionality to load the Teslasuit C API library dynamically."
  },
  {
    "objectID": "API Reference/core/loader.html#class-tsloader",
    "href": "API Reference/core/loader.html#class-tsloader",
    "title": "Loader",
    "section": "Class TsLoader",
    "text": "Class TsLoader\nHandles the loading of the Teslasuit C API library dynamically. This class ensures the library is loaded correctly and provides access to the library object.\n\nInitialization Parameters:\n\nlib_path (str, optional): Path to the Teslasuit API library. If not provided, the environment variable TESLASUIT_API_LIB_PATH is used.\n\n\n\nClass methods:\n\nload(self)\nLoads the Teslasuit C API library and returns the library object.\nReturns:\n\nctypes.CDLL or ctypes.WinDLL: The loaded library object.\nNone: If the library cannot be loaded.\nNote: If the library path is not provided or invalid, the system attempts to find the library using the default library name (teslasuit_api).\n\nNotes Ensure the library path is valid and accessible."
  },
  {
    "objectID": "API Reference/core/asset_manager.html#quick-access",
    "href": "API Reference/core/asset_manager.html#quick-access",
    "title": "Asset manager",
    "section": "Quick access",
    "text": "Quick access\n\nMain concept\nExamples\nUsecase",
    "crumbs": [
      "API Reference",
      "Core",
      "Asset manager"
    ]
  },
  {
    "objectID": "API Reference/core/asset_manager.html#intro",
    "href": "API Reference/core/asset_manager.html#intro",
    "title": "Asset manager",
    "section": "Intro",
    "text": "Intro\nThe Asset Manager subsystem provides functions to manage Teslasuit assets, such as loading, retrieving, and unloading assets.\n\nNote:\nSince TsAssetManager is a member of the SDK, it cannot be used independently without an active Teslasuit device.",
    "crumbs": [
      "API Reference",
      "Core",
      "Asset manager"
    ]
  },
  {
    "objectID": "API Reference/core/asset_manager.html#class-tsassetmanager",
    "href": "API Reference/core/asset_manager.html#class-tsassetmanager",
    "title": "Asset manager",
    "section": "Class TsAssetManager",
    "text": "Class TsAssetManager\nHandles TESLASUIT asset management, including loading assets from paths or binary data, retrieving asset types, and unloading assets.\n\nClass methods:\n\nload_asset_from_path(self, path)\nLoads an asset from a specified file path.\nArgs:\n\npath (str): Path to the asset.\n\nReturns:\n\nTsAssetHandle: Handle to the loaded asset.\n\n\nload_asset_from_data(self, data, size)\nLoads an asset from binary data.\nArgs:\n\ndata (bytes): Binary data of the asset.\n\nsize (int): Size of the binary data.\n\nReturns:\n\nTsAssetHandle: Handle to the loaded asset.\n\n\nget_asset_type(self, asset_handle)\nRetrieves the type of a loaded asset.\nArgs:\n\nasset_handle (TsAssetHandle): Handle to the asset.\n\nReturns:\n\nTsAssetType: Type of the asset.\n\n\nunload_asset(self, asset_handle)\nUnloads a previously loaded asset.\nArgs:\n\nasset_handle (TsAssetHandle): Handle to the asset.",
    "crumbs": [
      "API Reference",
      "Core",
      "Asset manager"
    ]
  },
  {
    "objectID": "API Reference/core/device_manager.html#quick-access",
    "href": "API Reference/core/device_manager.html#quick-access",
    "title": "Device manager",
    "section": "Quick access",
    "text": "Quick access\n\nMain concept\nExamples\nUsecase",
    "crumbs": [
      "API Reference",
      "Core",
      "Device manager"
    ]
  },
  {
    "objectID": "API Reference/core/device_manager.html#intro",
    "href": "API Reference/core/device_manager.html#intro",
    "title": "Device manager",
    "section": "Intro",
    "text": "Intro\nThe TsDeviceManager class is responsible for managing the connection and disconnection of TESLASUIT devices. It provides access to connected devices and their properties, enabling seamless interaction with the TESLASUIT ecosystem.",
    "crumbs": [
      "API Reference",
      "Core",
      "Device manager"
    ]
  },
  {
    "objectID": "API Reference/core/device_manager.html#class-tsdevicemanager",
    "href": "API Reference/core/device_manager.html#class-tsdevicemanager",
    "title": "Device manager",
    "section": "Class TsDeviceManager",
    "text": "Class TsDeviceManager\nHandles the connection and disconnection of Teslasuit devices. Provides access to connected devices and their properties.\n\nClass attributes:\n\ndevices: list\nA list of connected devices. Each device is an instance of the TsDevice class. The devices attribute maintains a list of all currently connected TESLASUIT devices. Each device in the list is represented as an instance of the TsDevice class, which provides access to device-specific functionality.\n\n\nClass methods:\n\nwait_for_device_to_connect(self, number_of_devices_to_wait=1)\nWaits for a specified number of devices to connect. This method blocks execution until the specified number of devices are connected. It periodically checks the connection status and prints a message while waiting.\nArgs:\n\nnumber_of_devices_to_wait (int): Number of devices to wait for. Defaults to 1.\n\n\nget_or_wait_last_device_attached(self)\nReturns the last connected device or waits for a device to connect if none are available. If no devices are currently connected, this method waits for a device to connect using the wait_for_device_to_connect method. Once a device is connected, it returns the most recently attached device.\nReturns:\n\nTsDevice: The last device connected.\n\n\n\nNotes:\n\nThe TsDeviceManager class automatically subscribes to device connection and disconnection events. Devices are added to or removed from the devices list dynamically.\nEnsure that the Teslasuit SDK is properly initialized before using this class to avoid errors.",
    "crumbs": [
      "API Reference",
      "Core",
      "Device manager"
    ]
  },
  {
    "objectID": "API Reference/core/index.html#introduction",
    "href": "API Reference/core/index.html#introduction",
    "title": "Overview",
    "section": "Introduction",
    "text": "Introduction\nThe Teslasuit API provides a comprehensive set of tools for interacting with Teslasuit devices. This documentation covers the core components of the API, including:\n\ndevice management\nmapping\nasset handling\nsubsystem access.",
    "crumbs": [
      "API Reference",
      "Core",
      "Overview"
    ]
  },
  {
    "objectID": "API Reference/core/index.html#prerequisites",
    "href": "API Reference/core/index.html#prerequisites",
    "title": "Overview",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nTeslasuit API Library\nEnsure the Teslasuit API library (libteslasuit_api.dylib) is available and correctly loaded.\nTeslasuit API Library Path Ensure the Teslasuit API library path is correctly set in the environment variable TESLASUIT_API_LIB_PATHor provided explicitly.\nConnected Teslasuit Device\nA Teslasuit device must be connected to access its features.\nPython Environment\nPython 3.8+ is required to use the Teslasuit SDK.",
    "crumbs": [
      "API Reference",
      "Core",
      "Overview"
    ]
  },
  {
    "objectID": "API Reference/core/index.html#core-components",
    "href": "API Reference/core/index.html#core-components",
    "title": "Overview",
    "section": "Core Components",
    "text": "Core Components\n\nTS API\nThe central interface for initializing and managing the Teslasuit API. It provides access to core functionalities such as device management, asset management, and mapping subsystems.\n\n\nDevice Manager\nHandles the connection and disconnection of Teslasuit devices. It provides access to connected devices and their properties, enabling seamless interaction with the Teslasuit ecosystem.\n\n\nDevice\nRepresents a Teslasuit device and provides access to its subsystems, such as motion capture, haptics, and biometry. It also allows retrieval of device-specific information.\n\n\nMapper\nProvides functionality for handling 2D mapping of device elements, including layouts, bones, and associated data. It supports operations like retrieving mappings and layouts.\n\n\nLoader\nHandles the dynamic loading of the Teslasuit C API library. It ensures the library is correctly loaded and accessible for API operations.\n\n\nAsset Manager\nManages Teslasuit assets, including loading, retrieving, and unloading assets. It supports operations with assets such as haptic effects and animations.\n\n\nData Structures\nDefines the data structures and enumerations used across the Teslasuit SDK, including mappings, layouts, bones, and subsystem-specific configurations.",
    "crumbs": [
      "API Reference",
      "Core",
      "Overview"
    ]
  },
  {
    "objectID": "API Reference/core/index.html#inheritance-scheme",
    "href": "API Reference/core/index.html#inheritance-scheme",
    "title": "Overview",
    "section": "Inheritance scheme",
    "text": "Inheritance scheme\n\n\n\n\n\nflowchart TD\n    A([TsApi]) --&gt; |Handles mapping the device| B[[TsMapper]]\n    A --&gt; |Provides access to connected device| C[[TsDeviceManager]]\n    A --&gt; |Loads the Teslasuit C API library| D[[TsLoader]]\n    A --&gt; |Manages Teslasuit assets| E[[TsAssetManager]]\n\n    C --&gt; N[[TsDevice]]\n    N --&gt; F(Access to subsystems)\n    F --&gt; G[[PPG]]\n    F --&gt; H[[Mocap]]\n    F --&gt; I[[Haptic]]\n    F --&gt; J[[Current feedback]]\n    F --&gt; K[[BIA]]\n    F --&gt; L[[EMG]]\n    F --&gt; M[[Force feedback]]",
    "crumbs": [
      "API Reference",
      "Core",
      "Overview"
    ]
  },
  {
    "objectID": "API Reference/core/index.html#notes",
    "href": "API Reference/core/index.html#notes",
    "title": "Overview",
    "section": "Notes",
    "text": "Notes\n\nEnsure the Teslasuit API is initialized before accessing any of its components.\nRefer to the respective component pages for detailed usage and examples.",
    "crumbs": [
      "API Reference",
      "Core",
      "Overview"
    ]
  },
  {
    "objectID": "API Reference/core/ts_api.html#quick-access",
    "href": "API Reference/core/ts_api.html#quick-access",
    "title": "TS API",
    "section": "Quick access",
    "text": "Quick access\n\nMain concept\nExamples\nUsecase",
    "crumbs": [
      "API Reference",
      "Core",
      "TS API"
    ]
  },
  {
    "objectID": "API Reference/core/ts_api.html#intro",
    "href": "API Reference/core/ts_api.html#intro",
    "title": "TS API",
    "section": "Intro",
    "text": "Intro\nThe TsApi class serves as the central interface for interacting with the Teslasuit API. It provides access to core functionalities, including device management, asset management, and mapping subsystems. This class is essential for initializing and managing the Teslasuit API and its associated components.",
    "crumbs": [
      "API Reference",
      "Core",
      "TS API"
    ]
  },
  {
    "objectID": "API Reference/core/ts_api.html#class-tsapi",
    "href": "API Reference/core/ts_api.html#class-tsapi",
    "title": "TS API",
    "section": "Class TsApi",
    "text": "Class TsApi\nThe TsApi class is an aggregate class that initializes the Teslasuit API and provides access to its core components, such as the device manager, mapper, and asset manager.\n\nClass methods:\n\nget_device_manager(self)\nReturns the TsDeviceManager instance, which provides access to connected Teslasuit devices.\nReturns:\n\nTsDeviceManager: The device manager instance.",
    "crumbs": [
      "API Reference",
      "Core",
      "TS API"
    ]
  },
  {
    "objectID": "API Reference/core/ts_api.html#usage-example",
    "href": "API Reference/core/ts_api.html#usage-example",
    "title": "TS API",
    "section": "Usage Example",
    "text": "Usage Example\nfrom teslasuit_sdk.ts_api import TsApi\n\n# Initialize the API\napi = TsApi(lib_path=\"/path/to/libteslasuit_api.dylib\")\n\n# Access the device manager\ndevice_manager = api.get_device_manager()\n\n# Perform operations with the device manager\n# ...",
    "crumbs": [
      "API Reference",
      "Core",
      "TS API"
    ]
  },
  {
    "objectID": "API Reference/core/ts_api.html#notes",
    "href": "API Reference/core/ts_api.html#notes",
    "title": "TS API",
    "section": "Notes",
    "text": "Notes\n\nThe TsApi class must be initialized before accessing any Teslasuit functionalities.",
    "crumbs": [
      "API Reference",
      "Core",
      "TS API"
    ]
  },
  {
    "objectID": "API Reference/core/data_structures.html",
    "href": "API Reference/core/data_structures.html",
    "title": "Data structures",
    "section": "",
    "text": "This is the page where you can find explanation of data structures used in Teslasuit SDK.",
    "crumbs": [
      "API Reference",
      "Core",
      "Data structures"
    ]
  },
  {
    "objectID": "API Reference/core/data_structures.html#intro",
    "href": "API Reference/core/data_structures.html#intro",
    "title": "Data structures",
    "section": "",
    "text": "This is the page where you can find explanation of data structures used in Teslasuit SDK.",
    "crumbs": [
      "API Reference",
      "Core",
      "Data structures"
    ]
  },
  {
    "objectID": "API Reference/core/data_structures.html#ppg-photoplethismography",
    "href": "API Reference/core/data_structures.html#ppg-photoplethismography",
    "title": "Data structures",
    "section": "PPG (Photoplethismography)",
    "text": "PPG (Photoplethismography)\n\nTsHrv(Structure):\nRepresents Heart Rate Variability (HRV) metrics.\nThis structure stores various HRV parameters, which are used to analyze fluctuations in heart rate over time. These metrics help assess autonomic nervous system activity and overall heart health.\nAttributes:\n\nmean_rr (float): Mean RR interval (time between successive heartbeats) in milliseconds.\nsdnn (float): Standard deviation of NN (normal-to-normal) intervals, indicating overall HRV.\nsdsd (float): Standard deviation of successive RR interval differences.\nrmssd (float): Root Mean Square of Successive Differences between RR intervals, reflecting short-term HRV.\nsd1 (float): Poincaré plot standard deviation perpendicular to the line of identity (short-term HRV component).\nsd2 (float): Poincaré plot standard deviation along the line of identity(long-term HRV component).\nhlf (float): High-frequency component of HRV, associated with parasympathetic nervous activity.\n\n\n\n\nTsPpgRawData(Structure):\nRepresents raw PPG (Photoplethysmography) data from multiple sensor nodes.\nThis structure holds raw PPG data collected from multiple sensor nodes, each of which contains infrared, red, blue, and green sensor values, along with timestamps.\nAttributes:\n\nnumber_of_nodes (int): The number of sensor nodes providing PPG data.\nnodes (POINTER(TsPpgRawNodeData)): Pointer to an array of node data structures.\n\n\n\n\nTsPpgData(Structure):\nRepresents processed PPG (Photoplethysmography) data from multiple sensor nodes.\nThis structure stores processed PPG data collected from multiple sensor nodes. Each node contains PPG-related metrics, including heart rate validation.\nAttributes:\n\nnumber_of_nodes (int): The number of sensor nodes providing PPG data.\nnodes (POINTER(TsPpgNodeData)): Pointer to an array of processed node data structures.\n\n\n\n\nTsPpgNodeData(Structure):\nRepresents processed PPG (Photoplethysmography) data for a single sensor node. This structure stores heart rate, blood oxygen level, and validity flags for a specific PPG sensor node, along with a timestamp indicating when the data was recorded. Attributes:\n\nheart_rate (int): Heart rate calculated in BPM.\nis_heart_rate_valid (bool): Is calculated heart rate valid.\ntimestamp (int): Time point that set when the last raw PPG data sample was processed.",
    "crumbs": [
      "API Reference",
      "Core",
      "Data structures"
    ]
  },
  {
    "objectID": "API Reference/core/data_structures.html#bia-bioelectrical-impedance-analysis",
    "href": "API Reference/core/data_structures.html#bia-bioelectrical-impedance-analysis",
    "title": "Data structures",
    "section": "BIA (Bioelectrical Impedance Analysis)",
    "text": "BIA (Bioelectrical Impedance Analysis)\n\nTsBiaConfig(Structure):\nRepresents the configuration for BIA (Bioelectrical Impedance Analysis) data streaming.\nAttributes:\n\nchannels (list): List of channel indexes to stream.\nnumber_of_channels (int): Number of channels.\nstart_frequency (int): Starting frequency for the BIA data streaming.\nfrequency_step (int): Frequency step size.\nnumber_of_steps (int): Number of frequency steps.\n\n\n\n\nTsComplexNumber(Structure):\nRepresents a complex number.\nAttributes:\n\nreal_value (int): Real part of the complex number.\nim_value (int): Imaginary part of the complex number.\n\n\n\n\nTsBiaFrequencyData(Structure):\nRepresents frequency data for a BIA channel.\nAttributes:\n\nfrequency (int): Frequency value.\ncomplex_number (TsComplexNumber): Complex number associated with the frequency.\n\n\n\n\nTsBiaChannelData(Structure):\nRepresents data for a single BIA channel.\nAttributes:\n\nchannel_index (int): Index of the channel.\nnumber_of_frequencies (int): Number of frequencies in the channel.\nfrequencies (list): List of TsBiaFrequencyData objects.\n\n\n\n\nTsBiaChannels(Structure):\nRepresents data for all BIA channels.\nAttributes:\n\nnumber_of_channels (int): Number of channels.\nchannels (list): List of TsBiaChannelData objects.",
    "crumbs": [
      "API Reference",
      "Core",
      "Data structures"
    ]
  },
  {
    "objectID": "API Reference/core/data_structures.html#mocap-motion-capture",
    "href": "API Reference/core/data_structures.html#mocap-motion-capture",
    "title": "Data structures",
    "section": "Mocap (Motion Capture)",
    "text": "Mocap (Motion Capture)\n\nTsVec2f(Structure):\nRepresents a 2D vector with float coordinates.\nAttributes:\n\nx (float): X coordinate.\ny (float): Y coordinate.\n\n\n\n\nTsVec3f(Structure):\nRepresents a 3D vector with float coordinates.\nAttributes:\n\nx (float): X coordinate.\ny (float): Y coordinate.\nz (float): Z coordinate.\n\n\n\n\nTsQuat(Structure):\nRepresents a quaternion for 3D rotation.\nAttributes:\n\nw (float): Rotation component.\nx (float): X coordinate.\ny (float): Y coordinate.\nz (float): Z coordinate.\n\n\n\n\nTsMocapBone(Structure):\nRepresents skeleton bone data.\nAttributes:\n\nposition (TsVec3f): Position of the bone.\nrotation (TsQuat): Rotation of the bone.\n\n\n\n\nTsMocapSensor(Structure):\nRepresents raw IMU sensor data.\nAttributes:\n\nq6 (TsQuat): 6-axis Quaternion data (without magnetometer).\nq9 (TsQuat): 9-axis Quaternion data (q6 including magnetometer).\naccel (TsVec3f): Accelerometer data.\ngyro (TsVec3f): Gyroscope data.\nmagn (TsVec3f): Magnetometer data.\nlinear_accel (TsVec3f): Linear acceleration data.\ntimestamp (uint64): Timestamp of the data.\n\n\n\n\nTsBone(Structure):\nRepresents a bone data in the mapping.\nAttributes:\n\nid (int): Bone ID.\n\nbone_index (int): Bone index.\n\nbone_side (int): Bone side.\n\nchannels (int): Bone channels.\n\n\n\n\nTsLayout(Structure):\nRepresents a layout data in the mapping.\nAttributes:\n\nid (int): Layout ID.\n\nlayout_type (int): Layout type.\n\nelement_type (int): Element type.\n\nlayout_index (int): Layout index.\n\nbone (POINTER(TsBone)): Pointer to a bone.\n\n\n\n\nTsMappingData(Structure):\nRepresents a set of device’s elements mapped on 2D space.\nAttributes:\n\nmapping_handle (void*): Mapping handle.\n\nlayouts (POINTER(TsLayout)): Pointer to an array of layouts.\n\n\n\n\nTsMapping2dVersion(Enum):\nEnumeration of mapping versions.\nValues:\n\nUndefined = 0,\nMapping_4_5_4 = 1,\nMapping_4_5_5 = 2,\nMapping_4_6_0 = 3,\nMappingLeftGlove_1_0_0 = 4,\nMappingRightGlove_1_0_0 = 5,\nMapping_4_5_4_Legacy = 6,\nMapping_4_5_5_Legacy = 7,\nMapping_5_0_0 = 8,\nMappingLeftGlove_1_2_0 = 9,\nMappingRightGlove_1_2_0 = 10,\nMapping_5_0_1 = 11,\nMapping_5_0_2 = 12,\nMapping_5_0_3 = 13,\nMapping_4_7_0 = 14,\nMappingLeftGlove_1_3_0 = 15,\nMappingRightGlove_1_3_0 = 16,\nMapping_4_X_Medical = 17,\nMapping_4_5_6 = 18\n\n\n\n\nTsLayout2dType(Enum):\nEnumeration of layout types.\nValues:\n\nUndefined: Undefined layout type.\n\nElectric: Electric layout.\n\nTemperature: Temperature layout.\n\nVibration: Vibration layout.\n\nEmg: EMG layout.\n\nEcg: ECG layout.\n\n\n\n\nTsLayout2dElementType(Enum):\nEnumeration of layout element types.\nValues:\n\nUndefined: Undefined element type.\n\nCell: Cell element.\n\nChannel: Channel element.\n\n\n\n\nTsBone2dIndex(IntEnum):\nEnumeration of bone indices in the mapping.\nValues:\n\nHips = 0,\nLeftUpperLeg = 1,\nRightUpperLeg = 2,\nLeftLowerLeg = 3,\nRightLowerLeg = 4,\nLeftFoot = 5,\nRightFoot = 6,\nSpine = 7,\nChest = 8,\nUpperChest = 9,\nNeck = 10,\nHead = 11,\nLeftShoulder = 12,\nRightShoulder = 13,\nLeftUpperArm = 14,\nRightUpperArm = 15,\nLeftLowerArm = 16,\nRightLowerArm = 17,\nLeftHand = 18,\nRightHand = 19,\nLeftThumbProximal = 20,\nLeftThumbIntermediate = 21,\nLeftThumbDistal = 22,\nLeftIndexProximal = 23,\nLeftIndexIntermediate = 24,\nLeftIndexDistal = 25,\nLeftMiddleProximal = 26,\nLeftMiddleIntermediate = 27,\nLeftMiddleDistal = 28,\nLeftRingProximal = 29,\nLeftRingIntermediate = 30,\nLeftRingDistal = 31,\nLeftLittleProximal = 32,\nLeftLittleIntermediate = 33,\nLeftLittleDistal = 34,\nRightThumbProximal = 35,\nRightThumbIntermediate = 36,\nRightThumbDistal = 37,\nRightIndexProximal = 38,\nRightIndexIntermediate = 39,\nRightIndexDistal = 40,\nRightMiddleProximal = 41,\nRightMiddleIntermediate = 42,\nRightMiddleDistal = 43,\nRightRingProximal = 44,\nRightRingIntermediate = 45,\nRightRingDistal = 46,\nRightLittleProximal = 47,\nRightLittleIntermediate = 48,\nRightLittleDistal = 49\n\n\n\n\nTsBone2dSide(Enum):\nEnumeration of bone sides.\nValues:\n\nUndefined: Undefined side.\n\nFront: Front side.\n\nBack: Back side.\n\n\n\n\nTsBiomechanicalIndex(Enum):\nEnumeration of biomechanical indices.\nValues:\n\nPelvisTilt: Pelvis tilt.\n\nPelvisList: Pelvis list.\n\nPelvisRotation: Pelvis rotation.\n\nHipFlexExtR: Right hip flexion/extension.\n\nHipAddAbdR: Right hip adduction/abduction.\n\nKneeFlexExtR: Right knee flexion/extension.\n\nAnkleFlexExtR: Right ankle flexion/extension.\n\nElbowFlexExtR: Right elbow flexion/extension.\n\nWristFlexExtR: Right wrist flexion/extension.\n\nShoulderAddAbdR: Right shoulder adduction/abduction.\n\nShoulderFlexExtR: Right shoulder flexion/extension.",
    "crumbs": [
      "API Reference",
      "Core",
      "Data structures"
    ]
  },
  {
    "objectID": "API Reference/core/data_structures.html#emg",
    "href": "API Reference/core/data_structures.html#emg",
    "title": "Data structures",
    "section": "EMG",
    "text": "EMG\n\nTsEmgOptions(Structure):\nRepresents EMG filter options.\nAttributes:\n\nlower_bandwidth (int): Filter’s lower bandwidth.\n\nupper_bandwidth (int): Filter’s upper bandwidth.\n\nsampling_frequency (int): Sampling frequency.\n\nsample_size (int): Sample size.\n\n\n\n\nTsEmgChannelData(Structure):\nRepresents EMG channel data.\nAttributes:\n\nchannel_index (int): Index of the channel.\n\nnumber_of_samples (int): Number of samples in the channel.\n\nsamples (list): List of samples.\n\n\n\n\nTsEmgNodeData(Structure):\nRepresents EMG node data.\nAttributes:\n\nnode_index (int): Index of the node.\n\nnumber_of_channels (int): Number of channels in the node.\n\nchannels (list): List of TsEmgChannelData objects.\n\nnumber_of_timestamps (int): Number of timestamps.\n\ntimestamps (list): List of timestamps.\n\n\n\n\nTsEmgData(Structure):\nRepresents EMG data.\nAttributes:\n\nnumber_of_nodes (int): Number of nodes.\n\nnodes (list): List of TsEmgNodeData objects.\n\noptions ([TsEmgOptions](#tsemgoptions)): EMG options.",
    "crumbs": [
      "API Reference",
      "Core",
      "Data structures"
    ]
  },
  {
    "objectID": "API Reference/core/data_structures.html#haptic",
    "href": "API Reference/core/data_structures.html#haptic",
    "title": "Data structures",
    "section": "Haptic",
    "text": "Haptic\n\nTsHapticParam(Structure):\nRepresents a haptic parameter.\nAttributes:\n\ntype (TsHapticParamType): Type of the parameter (e.g., Period, Amplitude, PulseWidth).\n\nvalue (float): Value of the parameter.\n\n\n\n\nTsHapticParamMultiplier(Structure):\nRepresents a multiplier for haptic parameters.\nAttributes:\n\ntype (TsHapticParamType): Type of the parameter (e.g., Period, Amplitude, PulseWidth).\n\nvalue (float): Multiplier value (between 0 and 1).\n\n\n\n\nTsHapticParamType(Enum):\nEnumeration of haptic parameter types.\nValues:\n\nUndefined: Undefined parameter type.\n\nPeriod: Period parameter.\n\nAmplitude: Amplitude parameter.\n\nPulseWidth: Pulse width parameter.\n\nTemperature: Temperature parameter.",
    "crumbs": [
      "API Reference",
      "Core",
      "Data structures"
    ]
  },
  {
    "objectID": "API Reference/core/data_structures.html#magnetic-encoder",
    "href": "API Reference/core/data_structures.html#magnetic-encoder",
    "title": "Data structures",
    "section": "Magnetic Encoder",
    "text": "Magnetic Encoder\n\nTsForceFeedbackConfig(Structure):\nRepresents the configuration for servomotor magnetic encoder.\nAttributes:\n\nbone_index (int): Index of the bone.\n\nangle (float): Angle for the magnetic encoder.\n\nhardness_percent (int): Hardness percentage from 0 to 100.\n\nlock_direction (TsMagneticEncoderLockDirection): Direction of the lock.\n\n\n\n\nTsMagneticEncoderLockDirection(Enum):\nEnumeration of magnetic encoder lock directions.\nValues:\n\nUp: Lock movement upwards.\n\nDown: Lock movement downwards.\n\nBoth: Lock movement in both directions.\n\n\n\n\nTsFingerMEPosition(Structure):\nRepresents the position of a finger.\nAttributes:\n\nflexion_angle (float): Flexion angle of the finger.\n\nabduction_angle (float): Abduction angle of the finger.\n\n\n\n\nTsGloveMEPosition(Structure):\nRepresents the magnetic encoder position structures for the fingers.\nAttributes:\n\nside (TsDeviceSide): Side of the glove (left or right).\n\nfingers (dict): Dictionary of bone indexes and their corresponding TsFingerMEPosition.",
    "crumbs": [
      "API Reference",
      "Core",
      "Data structures"
    ]
  },
  {
    "objectID": "API Reference/core/data_structures.html#device",
    "href": "API Reference/core/data_structures.html#device",
    "title": "Data structures",
    "section": "Device",
    "text": "Device\n\nTsDevice(Structure):\nRepresents a Teslasuit device.\nAttributes:\n\nuuid (bytes): A 16-byte UUID that uniquely identifies the device.\n\n\n\n\nTsVersion(Structure):\nRepresents the version of the Teslasuit C API.\nAttributes:\n\nmajor (int): Major version number.\n\nminor (int): Minor version number.\n\npatch (int): Patch version number.\n\nbuild (int): Build version number.\n\n\n\n\nTsDeviceType(Enum):\nEnumeration of Teslasuit device types.\nValues:\n\nUndefined: Undefined device type.\n\nSuit: Teslasuit suit device type.\n\nGlove: Teslasuit glove device type.\n\n\n\n\nTsDeviceSide(Enum):\nEnumeration of Teslasuit glove device sides.\nValues:\n\nUndefined: Undefined device side.\n\nRight: Right glove device side.\n\nLeft: Left glove device side.\n\n\n\n\nTsDeviceEventPolicy(Enum):\nEnumeration of policies for handling Teslasuit device events.\nValues:\n\nEnumerate: Enumerate all devices.\n\nAttach: Attach a device.\n\nDetach: Detach a device.\n\n\n\n\nTsDeviceEvent(Enum):\nEnumeration of events related to Teslasuit devices.\nValues:\n\nDeviceAttached: Device attached event.\n\nDeviceDetached: Device detached event.",
    "crumbs": [
      "API Reference",
      "Core",
      "Data structures"
    ]
  },
  {
    "objectID": "API Reference/core/data_structures.html#asset-manager",
    "href": "API Reference/core/data_structures.html#asset-manager",
    "title": "Data structures",
    "section": "Asset Manager",
    "text": "Asset Manager\n\nTsAssetType(Enum):\nEnumeration of Teslasuit asset types.\nValues:\n\nUndefined: Undefined asset type.\n\nSpline: Spline asset.\n\nHapticEffect: Haptic effect asset.\n\nMaterial: Material asset.\n\nTouchSequence: Touch sequence asset.\n\nPresetAnimation: Preset animation asset.\n\nSceneAnimation: Scene animation asset.",
    "crumbs": [
      "API Reference",
      "Core",
      "Data structures"
    ]
  },
  {
    "objectID": "API Reference/core/data_structures.html#current-feedback",
    "href": "API Reference/core/data_structures.html#current-feedback",
    "title": "Data structures",
    "section": "Current Feedback",
    "text": "Current Feedback\n\nTsCurrentFeedbackChannelData(Structure):\nRepresents a current feedback channel data.\nAttributes:\n\nchannel_index (int): Index of the channel.\nvalue (int): Value of the channel.\n\n\n\n\nTsCurrentFeedbackNodeData(Structure):\nRepresents a current feedback node data.\nAttributes:\n\nnode_index (int): Index of the node.\nnumber_of_channels (int): Number of channels in the node.\nchannels_data (list): List of TsCurrentFeedbackChannelData objects.\n\n\n\n\nTsCurrentFeedbackNodes(Structure):\nRepresents a collection of current feedback nodes.\nAttributes:\n\nnumber_of_nodes (int): Number of nodes.\nnodes (list): List of TsCurrentFeedbackNodeData objects.",
    "crumbs": [
      "API Reference",
      "Core",
      "Data structures"
    ]
  },
  {
    "objectID": "API Reference/subsystems/bia.html#quick-access",
    "href": "API Reference/subsystems/bia.html#quick-access",
    "title": "BIA (experimental)",
    "section": "Quick access",
    "text": "Quick access\n\nMain concept\nExamples\nBIA data structures",
    "crumbs": [
      "API Reference",
      "Subsystems",
      "BIA (experimental)"
    ]
  },
  {
    "objectID": "API Reference/subsystems/bia.html#intro",
    "href": "API Reference/subsystems/bia.html#intro",
    "title": "BIA (experimental)",
    "section": "Intro",
    "text": "Intro\nThe BIA (Bioelectrical Impedance Analysis) subsystem provides functions to access BIA functionality.\n\nNote:\nSince TsBia is a member of the device class, it cannot be used independently without an active Teslasuit device.",
    "crumbs": [
      "API Reference",
      "Subsystems",
      "BIA (experimental)"
    ]
  },
  {
    "objectID": "API Reference/subsystems/bia.html#class-tsbia",
    "href": "API Reference/subsystems/bia.html#class-tsbia",
    "title": "BIA (experimental)",
    "section": "Class TsBia",
    "text": "Class TsBia\nHandles BIA (Bioelectrical Impedance Analysis) data processing and streaming.\nThis class manages the interaction with BIA sensors, including data streaming configuration, starting/stopping streaming, and retrieving BIA data.\n\nClass methods:\n\nstart_streaming(self)\nStart the streaming of BIA data.\n\nstop_streaming(self)\nStop the streaming of BIA data.\n\nget_data_on_ready(self)\nBlocks execution until BIA data is ready and returns the latest data.\nReturns:\n\nTsBiaChannels (struct): The latest BIA data.\n\n\nset_streaming_config(self, channels, start_frequency=10000, number_of_steps=10, frequency_step=10000)\nSet the streaming configuration for BIA data.\nArgs:\n\nchannels (list): List of channel indexes to stream.\n\nstart_frequency (int): Starting frequency for the BIA data.\n\nnumber_of_steps (int): Number of frequency steps.\n\nfrequency_step (int): Frequency step size.",
    "crumbs": [
      "API Reference",
      "Subsystems",
      "BIA (experimental)"
    ]
  },
  {
    "objectID": "API Reference/subsystems/bia.html#access-to-the-data",
    "href": "API Reference/subsystems/bia.html#access-to-the-data",
    "title": "BIA (experimental)",
    "section": "Access to the data",
    "text": "Access to the data\nThese code snippets and charts are just an example of how is the data flow looks like. to know more, please visit data structures page.\n\nAccess to BIA channel data\nTsBia.get_data_on_ready().channels[0].frequencies[0].complex_number.real_value\n\n\n\n\n\nflowchart TD\nA[TsBiaChannels] --&gt; B[TsBiaChannelData]\nB --&gt; C[TsBiaFrequencyData]\nC --&gt; D[TsComplexNumber]\nD --&gt; E[real_value]\nD --&gt; F[im_value]",
    "crumbs": [
      "API Reference",
      "Subsystems",
      "BIA (experimental)"
    ]
  },
  {
    "objectID": "API Reference/subsystems/current_feedback.html#quick-access",
    "href": "API Reference/subsystems/current_feedback.html#quick-access",
    "title": "Current Feedback (experimental)",
    "section": "Quick access",
    "text": "Quick access\n\nMain concept\nExamples\nCurrent feedback data structures",
    "crumbs": [
      "API Reference",
      "Subsystems",
      "Current Feedback (experimental)"
    ]
  },
  {
    "objectID": "API Reference/subsystems/current_feedback.html#intro",
    "href": "API Reference/subsystems/current_feedback.html#intro",
    "title": "Current Feedback (experimental)",
    "section": "Intro",
    "text": "Intro\nThe Current Feedback subsystem provides functions to access and stream current feedback data from Teslasuit devices.\n\nNote:\nSince TsCurrentFeedback is a member of the device class, it cannot be used independently without an active Teslasuit device.",
    "crumbs": [
      "API Reference",
      "Subsystems",
      "Current Feedback (experimental)"
    ]
  },
  {
    "objectID": "API Reference/subsystems/current_feedback.html#class-tscurrentfeedback",
    "href": "API Reference/subsystems/current_feedback.html#class-tscurrentfeedback",
    "title": "Current Feedback (experimental)",
    "section": "Class TsCurrentFeedback",
    "text": "Class TsCurrentFeedback\nHandles current feedback data processing and streaming.\nThis class manages the interaction with current feedback nodes, including data streaming and retrieval.\n\nClass methods:\n\nstart_streaming(self)\nStart the streaming of current feedback data.\n\nstop_streaming(self)\nStop the streaming of current feedback data.\n\nget_data_on_ready(self)\nBlocks execution until current feedback data is ready and returns the latest data.\nReturns:\n\nTsCurrentFeedbackNodes (struct): The latest current feedback data.",
    "crumbs": [
      "API Reference",
      "Subsystems",
      "Current Feedback (experimental)"
    ]
  },
  {
    "objectID": "API Reference/subsystems/current_feedback.html#access-to-the-data",
    "href": "API Reference/subsystems/current_feedback.html#access-to-the-data",
    "title": "Current Feedback (experimental)",
    "section": "Access to the data",
    "text": "Access to the data\nThese code snippets and charts are just an example of how is the data flow looks like. to know more, please visit data structures page.\n\nAccess to current feedback channel data\nTsCurrentFeedback.get_data_on_ready().nodes[0].channels_data[0].value\n\n\n\n\n\nflowchart TD\nA[TsCurrentFeedbackNodes] --&gt; B[TsCurrentFeedbackNodeData]\nB --&gt; C[TsCurrentFeedbackChannelData]\nC --&gt; D[value]",
    "crumbs": [
      "API Reference",
      "Subsystems",
      "Current Feedback (experimental)"
    ]
  },
  {
    "objectID": "API Reference/subsystems/ppg.html#quick-access",
    "href": "API Reference/subsystems/ppg.html#quick-access",
    "title": "PPG",
    "section": "Quick access",
    "text": "Quick access\n\nMain concept\nExamples\nUsecase\nPPG Data structures",
    "crumbs": [
      "API Reference",
      "Subsystems",
      "PPG"
    ]
  },
  {
    "objectID": "API Reference/subsystems/ppg.html#intro",
    "href": "API Reference/subsystems/ppg.html#intro",
    "title": "PPG",
    "section": "Intro",
    "text": "Intro\nBiometry subsystem provides functions to access PPG functionality.\n\nNote:\nSince TsPPG is a member of the device class, it cannot be used independently without an active Teslasuit device.",
    "crumbs": [
      "API Reference",
      "Subsystems",
      "PPG"
    ]
  },
  {
    "objectID": "API Reference/subsystems/ppg.html#class-tsppg",
    "href": "API Reference/subsystems/ppg.html#class-tsppg",
    "title": "PPG",
    "section": "Class TsPpg",
    "text": "Class TsPpg\nHandles PPG (Photoplethysmography) sensor data processing and streaming. This class manages the interaction with a PPG sensor, including raw and processed data streaming, calibration, and retrieving heart rate variability (HRV) and raw PPG data.\n\nClass methods:\n\nstart_raw_streaming(self)\nStart the streaming of a PPG raw data\n\nstop_raw_streaming(self)\nStop the streaming of a PPG raw data\n\nget_hrv_data_on_ready(self)\nBlocks execution until HRV data is ready and returns the latest HRV data.\nReturns:\n\nTsHrv (struct) The latest HRV data.\n\n\nget_raw_data_on_ready(self)\nBlocks execution until raw PPG data is ready and returns the latest raw data.\nReturns:\n\nTsPpgRawData (struct): The latest raw PPG data.\n\n\nget_hrv(self)\nRetrieves the latest HRV data.\nReturns:\n\nTsHrv (struct): The latest HRV data.\n\n\nget_data_raw(self)\nRetrieves the latest raw PPG data.\nReturns:\n\nTsPpgRawData (struct): The latest raw PPG data.\n\n\nget_data(self)\nRetrieves the latest processed PPG data.\nReturns:\n\nTsPpgData: The latest processed PPG data.\n\nNB! TsPpgData struct doesn’t provide any parameters such as “heart_rate”. The access is given through the TsPpgNodeData struct. Please see the example.\n\ncalibrate(self)\nCalibrates PPG processor. The calibration procedure is capturing interval of the raw data during 3 seconds. The captured interval will be used in calculation of all ppg parameters. By default, calibration procedure starts on starting PPG processor. In case on bad start, the calibration procedure might be restarted using this function.",
    "crumbs": [
      "API Reference",
      "Subsystems",
      "PPG"
    ]
  },
  {
    "objectID": "API Reference/subsystems/ppg.html#access-to-the-data",
    "href": "API Reference/subsystems/ppg.html#access-to-the-data",
    "title": "PPG",
    "section": "Access to the data",
    "text": "Access to the data\nThese code snippets and charts are just an example of how is the data flow looks like. to know more, please visit data structures page.\n\nAccess to raw data\nTsPpg.get_raw_data_on_ready().nodes[0].ir_data\n\n\n\n\n\nflowchart TD\nA[TsPpgRawData] --&gt; B[TsPpgRawNodeData]\n\n\n\n\n\n\n\n\nAccess to HRV data\nTsPpg.get_hrv_data_on_ready().mean_rr\n\n\nAccess to heart rate data\nTsPpg.get_data().nodes[0].heart_rate\n\n\n\n\n\nflowchart TD\nA[TsPpgData] --&gt; B[TsPpgNodeData]",
    "crumbs": [
      "API Reference",
      "Subsystems",
      "PPG"
    ]
  },
  {
    "objectID": "API Reference/subsystems/force_feedback.html#quick-access",
    "href": "API Reference/subsystems/force_feedback.html#quick-access",
    "title": "Force feedback (Teslaglove)",
    "section": "Quick access",
    "text": "Quick access\n\nMain concept\nExamples\nMagnetic encoder data structures",
    "crumbs": [
      "API Reference",
      "Subsystems",
      "Force feedback (Teslaglove)"
    ]
  },
  {
    "objectID": "API Reference/subsystems/force_feedback.html#intro",
    "href": "API Reference/subsystems/force_feedback.html#intro",
    "title": "Force feedback (Teslaglove)",
    "section": "Intro",
    "text": "Intro\nThe Magnetic Encoder subsystem provides functions to control servomotors for haptic feedback and movement restriction.\n\nNote:\nsince TsMagneticEncoder is a member of the device class and cannot be used independently without an active Teslasuit device.",
    "crumbs": [
      "API Reference",
      "Subsystems",
      "Force feedback (Teslaglove)"
    ]
  },
  {
    "objectID": "API Reference/subsystems/force_feedback.html#class-tsmagneticencoder",
    "href": "API Reference/subsystems/force_feedback.html#class-tsmagneticencoder",
    "title": "Force feedback (Teslaglove)",
    "section": "Class TsMagneticEncoder",
    "text": "Class TsMagneticEncoder\nHandles servomotor magnetic encoder control, including locking directions and configuring feedback parameters.\n\nClass methods:\n\nget_positions(self)\nGet the current positions of the fingers.\nReturns:\n\ndict: A dictionary of bone indexes and their corresponding TsFingerMEPosition.\n\n\nstart_me_streaming(self)\nStarts magnetic encoder data streaming. This method subscribes to the data update callback and starts streaming.\n\nstop_me_streaming(self)\nStops magnetic encoder data streaming. This method stops the streaming and unsubscribes from the data update callback.\n\nts_magnetic_encoder_enable(self, me_configs)\nEnable magnetic encoder for the specified bone indexes.\nArgs:\n\nme_configs (list): A list of TsForceFeedbackConfig objects.\n\n\nts_magnetic_encoder_disable(self, bone_indexes)\nDisable magnetic encoder for the specified bone indexes.\nArgs:\n\nbone_indexes (list): A list of bone indexes to disable magnetic encoder for.\n\n\nget_default_me_controls_struct(self)\nGet the default magnetic encoder controls structure.\nReturns:\n\nTsForceFeedbackConfig: Default magnetic encoder configuration.\n\n\nget_default_ff_controls_struct(self)\nGet the default force feedback controls structure for the magnetic encoder.\nReturns:\n\nTsForceFeedbackConfig: A TsForceFeedbackConfig structure.\n\n\nget_bone_indexes(self)\nGet the bone indexes for the magnetic encoder.\nReturns:\n\nlist: A list of bone indexes.",
    "crumbs": [
      "API Reference",
      "Subsystems",
      "Force feedback (Teslaglove)"
    ]
  },
  {
    "objectID": "API Reference/subsystems/force_feedback.html#utilities",
    "href": "API Reference/subsystems/force_feedback.html#utilities",
    "title": "Force feedback (Teslaglove)",
    "section": "Utilities",
    "text": "Utilities\n\nUtility functions:\n\nget_position_struct_for_bones(bone_indexes)\nCreate a dictionary of TsFingerMEPosition for the given bone indexes.\nArgs:\n\nbone_indexes (list): List of bone indexes.\n\nReturns:\n\ndict: A dictionary of bone indexes and their corresponding TsFingerMEPosition.\n\n\nget_left_default_position_struct()\nCreate a default position struct for the left hand.\nReturns:\n\ndict: A dictionary of bone indexes and their corresponding TsFingerMEPosition.\n\n\nget_right_default_position_struct()\nCreate a default position struct for the right hand.\nReturns:\n\ndict: A dictionary of bone indexes and their corresponding TsFingerMEPosition.\n\n\nmirror_bone_index(bone_index)\nMirror the bone index for the opposite hand.\nArgs:\n\nbone_index: Bone index to be mirrored.\n\nReturns:\n\nint: Mirrored bone index.\n\n\nget_me_controls_struct_for_bones(bone_indexes)\nCreate a TsForceFeedbackConfig structure for the given bone indexes.\nArgs:\n\nbone_indexes (list): List of bone indexes.\n\nReturns:\n\nTsForceFeedbackConfig: Magnetic encoder configuration structure.\n\n\nget_left_default_me_controls_struct()\nCreate a default magnetic encoder controls struct for the left hand.\nReturns:\n\nTsForceFeedbackConfig: Default magnetic encoder configuration.\n\n\nget_right_default_me_controls_struct()\nCreate a default magnetic encoder controls struct for the right hand.\nReturns:\n\nTsForceFeedbackConfig: Default magnetic encoder configuration.",
    "crumbs": [
      "API Reference",
      "Subsystems",
      "Force feedback (Teslaglove)"
    ]
  },
  {
    "objectID": "API Reference/subsystems/force_feedback.html#access-to-the-data",
    "href": "API Reference/subsystems/force_feedback.html#access-to-the-data",
    "title": "Force feedback (Teslaglove)",
    "section": "Access to the data",
    "text": "Access to the data\nThese code snippets and charts are just an example of how is the data flow looks like. to know more, please visit data structures page.\n\nAccess to finger positions\nTsMagneticEncoder.get_positions().fingers[TsBone2dIndex.LeftThumbProximal].flexion_angle\n\n\n\n\n\nflowchart TD\nA[TsFingerMEPosition] --&gt; B[flexion_angle]\nA --&gt; C[abduction_angle]\n\n\n\n\n\n\n\n\nAccess to force feedback configuration\nTsMagneticEncoder.get_default_ff_controls_struct().bone_index\n\n\n\n\n\nflowchart TD\nA[TsForceFeedbackConfig] --&gt; B[bone_index]\nA --&gt; C[angle]\nA --&gt; D[hardness_percent]\nA --&gt; E[lock_direction]",
    "crumbs": [
      "API Reference",
      "Subsystems",
      "Force feedback (Teslaglove)"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction",
    "section": "",
    "text": "The Teslasuit SDK is a developer toolkit for integrating the Teslasuit — a full-body haptic suit with motion capture and biometric sensors — into immersive applications. With this SDK, developers can control the suit’s haptic feedback system, stream and record motion data, and monitor biometric signals in real time.\nThe Teslasuit SDK Python API provides a high-level interface for integrating Teslasuit systems into Python-based applications. It enables developers, researchers, and engineers to access the full range of Teslasuit’s haptic, motion capture, and biometric capabilities through an efficient and extensible API.\n\n\n\nThe API documentation is organized into the following sections:\n\nGetting Started – Fast setup for quick first steps\nMain Concepts – Theory and architecture of Teslasuit systems\n\nAPI Reference\n\nCore – Initialization, connection, session control\n\nSubsystems – Haptics, Mocap, Biometry, Mapping, etc.\n\n\nExamples – Step-by-step usage scripts\n\nUse Cases – Practical applications and integration flows\n\n\n\n\n\n\n\nThe Haptics module allows you to control the suit’s network of electrical stimulators to create realistic tactile feedback or stimulate major muscle groups to elicit contractions. Developers can configure custom stimulation patterns, adjust intensity levels, and trigger feedback events in sync with application logic.\nFor example, you might simulate the feeling of impact or rainfall on the user’s body, or provide a complex stimulation pattern across multiple muscle groups in the lower extremities, synchronized with the gait cycle.\n➡️ Create your first haptic touch.\n🔍 Learn more about the suit’s EMS system and best practices for designing haptic feedback here.\n\n\n\n\nThe Motion Capture module provides access to the suit’s built-in IMU-based inertial tracking system. The SDK streams detailed motion and biomechanical data in real time, using a skeletal model to deliver full-body pose tracking.\nFor example, you can animate a game character using real-time body motion, record physical activity for replay or analysis, or dynamically adjust stimulation based on biomechanical feedback.\n➡️ Start your first motion capture stream.\n🔍 Learn more about Teslasuit’s Mocap system, coordinate systems, and best practices here.\n\n\n\n\nThe Biometry module provides real-time biometric readings from the suit’s sensors to monitor the user’s physical state. With the Python API, developers can access data such as heart rate and heart rate variability (HRV), offering insights into stress, fatigue, or exertion levels.\nFor instance, an adaptive training application can adjust difficulty or feedback based on a user’s physiological response.\n➡️ Measure your heart rate now.\n🔍 Learn more about Teslasuit’s biometric system and HRV metrics here.\n\n\n\n\n\nTo use the Teslasuit SDK Python API, ensure you have:\n\nWindows 10 or later\n\nInstalled Teslasuit Control Center\nPython 3.8 or higher\n\nA connected Teslasuit device\n\n\n\n\n\nFor technical inquiries, feature requests, or troubleshooting assistance, please contact:\n\nHelp Desk\n\nFAQ\n\nDeveloper Forum\n\nEmail support: support@teslasuit.io",
    "crumbs": [
      "Home",
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#documentation-structure",
    "href": "index.html#documentation-structure",
    "title": "Introduction",
    "section": "",
    "text": "The API documentation is organized into the following sections:\n\nGetting Started – Fast setup for quick first steps\nMain Concepts – Theory and architecture of Teslasuit systems\n\nAPI Reference\n\nCore – Initialization, connection, session control\n\nSubsystems – Haptics, Mocap, Biometry, Mapping, etc.\n\n\nExamples – Step-by-step usage scripts\n\nUse Cases – Practical applications and integration flows",
    "crumbs": [
      "Home",
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#main-capabilities",
    "href": "index.html#main-capabilities",
    "title": "Introduction",
    "section": "",
    "text": "The Haptics module allows you to control the suit’s network of electrical stimulators to create realistic tactile feedback or stimulate major muscle groups to elicit contractions. Developers can configure custom stimulation patterns, adjust intensity levels, and trigger feedback events in sync with application logic.\nFor example, you might simulate the feeling of impact or rainfall on the user’s body, or provide a complex stimulation pattern across multiple muscle groups in the lower extremities, synchronized with the gait cycle.\n➡️ Create your first haptic touch.\n🔍 Learn more about the suit’s EMS system and best practices for designing haptic feedback here.\n\n\n\n\nThe Motion Capture module provides access to the suit’s built-in IMU-based inertial tracking system. The SDK streams detailed motion and biomechanical data in real time, using a skeletal model to deliver full-body pose tracking.\nFor example, you can animate a game character using real-time body motion, record physical activity for replay or analysis, or dynamically adjust stimulation based on biomechanical feedback.\n➡️ Start your first motion capture stream.\n🔍 Learn more about Teslasuit’s Mocap system, coordinate systems, and best practices here.\n\n\n\n\nThe Biometry module provides real-time biometric readings from the suit’s sensors to monitor the user’s physical state. With the Python API, developers can access data such as heart rate and heart rate variability (HRV), offering insights into stress, fatigue, or exertion levels.\nFor instance, an adaptive training application can adjust difficulty or feedback based on a user’s physiological response.\n➡️ Measure your heart rate now.\n🔍 Learn more about Teslasuit’s biometric system and HRV metrics here.",
    "crumbs": [
      "Home",
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#requirements",
    "href": "index.html#requirements",
    "title": "Introduction",
    "section": "",
    "text": "To use the Teslasuit SDK Python API, ensure you have:\n\nWindows 10 or later\n\nInstalled Teslasuit Control Center\nPython 3.8 or higher\n\nA connected Teslasuit device",
    "crumbs": [
      "Home",
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#support-and-contact",
    "href": "index.html#support-and-contact",
    "title": "Introduction",
    "section": "",
    "text": "For technical inquiries, feature requests, or troubleshooting assistance, please contact:\n\nHelp Desk\n\nFAQ\n\nDeveloper Forum\n\nEmail support: support@teslasuit.io",
    "crumbs": [
      "Home",
      "Introduction"
    ]
  },
  {
    "objectID": "examples/emg_example.html#quick-access",
    "href": "examples/emg_example.html#quick-access",
    "title": "EMG example (experimental)",
    "section": "Quick access",
    "text": "Quick access\n\nMain concept\nEMG Subsystem\nEMG data structures",
    "crumbs": [
      "Examples",
      "EMG example (experimental)"
    ]
  },
  {
    "objectID": "examples/emg_example.html#intro",
    "href": "examples/emg_example.html#intro",
    "title": "EMG example (experimental)",
    "section": "Intro",
    "text": "Intro\nThis web page provides a comprehensive guide on how to retrieve data from the EMG (Electromyography) sensor of a Teslasuit device. The page is structured to help developers understand the process of initializing the Teslasuit API, connecting to a device, accessing the EMG subsystem, and streaming data.",
    "crumbs": [
      "Examples",
      "EMG example (experimental)"
    ]
  },
  {
    "objectID": "examples/emg_example.html#code-for-emg-data",
    "href": "examples/emg_example.html#code-for-emg-data",
    "title": "EMG example (experimental)",
    "section": "Code for EMG data",
    "text": "Code for EMG data\n1from teslasuit_sdk import ts_api\n\ndef main():\n2    print(\"Initializing Teslasuit API...\")\n    api = ts_api.TsApi()\n\n3    print(\"Waiting for a Teslasuit device to connect...\")\n    device = api.get_device_manager().get_or_wait_last_device_attached()\n\n4    print(\"Accessing the EMG subsystem...\")\n    emg = device.emg\n\n5    print(\"Starting EMG data streaming...\")\n    emg.start_streaming()\n\n    desired_fps = 60\n    period_in_ms = 1. / desired_fps\n    frames_to_stream = 10\n\n    print(\"Streaming EMG data...\")\n6    while frames_to_stream:\n        time.sleep(period_in_ms)\n7        print(\"EMG data:\", emg)\n        frames_to_stream -= 1\n\n    print(\"Stopping EMG data streaming...\")\n8    emg.stop_streaming()\n9    print(\"Finished\")\n\n# Entry point for the script\nif __name__ == \"__main__\":\n10    main()\n\n1\n\nImport the main Teslasuit API module.\n\n2\n\nCreate an instance of the Teslasuit API.\n\n3\n\nWait for a Teslasuit device to be connected and get it.\n\n4\n\nAccess the EMG subsystem from the device.\n\n5\n\nStart streaming EMG data from the suit.\n\n6\n\nStream EMG data for a specified number of frames.\n\n7\n\nPrint the EMG data to the console.\n\n8\n\nStop the EMG data streaming.\n\n9\n\nIndicate that the process is finished.\n\n10\n\nStart the program using the main function.",
    "crumbs": [
      "Examples",
      "EMG example (experimental)"
    ]
  },
  {
    "objectID": "examples/emg_example.html#expected-output",
    "href": "examples/emg_example.html#expected-output",
    "title": "EMG example (experimental)",
    "section": "Expected output",
    "text": "Expected output\n1Initializing Teslasuit API...\n2Waiting for a Teslasuit device to connect...\n3Accessing the EMG subsystem...\n4Starting EMG data streaming...\n5Streaming EMG data...\n6EMG data: &lt;data&gt;\n7Stopping EMG data streaming...\n8Finished\n\n1\n\nThe API is initialized via api = ts_api.TsApi().\n\n2\n\nThe program waits for a Teslasuit device to connect using api.get_device_manager().get_or_wait_last_device_attached().\n\n3\n\nThe EMG subsystem of the connected device is accessed via device.emg.\n\n4\n\nEMG data streaming is initiated with emg.start_streaming().\n\n5\n\nThe program streams EMG data for a specified number of frames.\n\n6\n\nEMG data is printed to the console.\n\n7\n\nEMG data streaming is stopped using emg.stop_streaming().\n\n8\n\nThe process is completed.",
    "crumbs": [
      "Examples",
      "EMG example (experimental)"
    ]
  },
  {
    "objectID": "examples/mocap_example.html#quick-access",
    "href": "examples/mocap_example.html#quick-access",
    "title": "Mocap example",
    "section": "Quick access",
    "text": "Quick access\n\nMain concept\nMocap Subsystem\nMocap data structures",
    "crumbs": [
      "Examples",
      "Mocap example"
    ]
  },
  {
    "objectID": "examples/mocap_example.html#intro",
    "href": "examples/mocap_example.html#intro",
    "title": "Mocap example",
    "section": "Intro",
    "text": "Intro\nThis web page provides a comprehensive guide on how to retrieve data from the IMU (Inertial Measurement Unit) sensors of a Teslasuit device. The page is structured to help developers understand the process of initializing the Teslasuit API, connecting to a device, accessing the Mocap subsystem, and streaming data such as biomechanical angles and quaternions.",
    "crumbs": [
      "Examples",
      "Mocap example"
    ]
  },
  {
    "objectID": "examples/mocap_example.html#code-for-mocap-data",
    "href": "examples/mocap_example.html#code-for-mocap-data",
    "title": "Mocap example",
    "section": "Code for Mocap data",
    "text": "Code for Mocap data\n1from teslasuit_sdk import ts_api\n2import teslasuit_sdk.subsystems.ts_mocap\n3from teslasuit_sdk.ts_mapper import (TsBone2dIndex, TsBiomechanicalIndex)\n\ndef main():\n4    is_streaming = False\n    try:\n5        print(\"Initializing Teslasuit API...\")\n        api = ts_api.TsApi()\n\n6        print(\"Waiting for a Teslasuit device to connect...\")\n        device = api.get_device_manager().get_or_wait_last_device_attached()\n\n7        print(\"Accessing the Mocap subsystem...\")\n        mocap = device.mocap\n\n8        print(\"Starting Mocap data streaming...\")\n        mocap.start_streaming()\n        is_streaming = True\n\n        frames = 100\n9        while frames &gt; 0:\n10            data = mocap.get_raw_data_on_ready()\n            print(\"Bone data:\", data[TsBone2dIndex.RightUpperArm])\n11            biomech_data = mocap.get_biomechanical_angles_on_ready()\n            print(\"Biomech Pelvis Tilt: \", biomech_data[TsBiomechanicalIndex.PelvisTilt])\n12            frames -= 1\n\n13        print(\"Finished\")\n\n14    except (KeyboardInterrupt, SystemExit):\n        print('\\n! Received keyboard interrupt, quitting mocap streaming\\n')\n\n15    if is_streaming:\n        mocap.stop_streaming()\n        print(\"Mocap streaming was stopped\")\n\nif __name__ == '__main__':\n16    main()\n\n1\n\nImport the main Teslasuit API module.\n\n2\n\nImport the Mocap subsystem from the SDK.\n\n3\n\nImport the necessary mapper indices for bone and biomechanical data.\n\n4\n\nInitialize a flag to track streaming status.\n\n5\n\nCreate an instance of the Teslasuit API.\n\n6\n\nWait for a Teslasuit device to be connected and get it.\n\n7\n\nAccess the Mocap subsystem from the device.\n\n8\n\nStart streaming Mocap data from the suit.\n\n9\n\nEnter a loop to process a fixed number of frames.\n\n10\n\nRetrieve and print raw bone data for the right upper arm.\n\n11\n\nRetrieve and print biomechanical pelvis tilt data.\n\n12\n\nDecrement the frame counter.\n\n13\n\nPrint a message when streaming is finished.\n\n14\n\nHandle keyboard interrupts gracefully.\n\n15\n\nStop Mocap streaming if it was started.\n\n16\n\nStart the program using the main function.",
    "crumbs": [
      "Examples",
      "Mocap example"
    ]
  },
  {
    "objectID": "examples/mocap_example.html#expected-output",
    "href": "examples/mocap_example.html#expected-output",
    "title": "Mocap example",
    "section": "Expected output",
    "text": "Expected output\n1Initializing Teslasuit API...\n2Waiting for a Teslasuit device to connect...\n3Accessing the Mocap subsystem...\n4Starting Mocap data streaming...\n5Bone data: [0.5, 0.2, 0.1]\n6Biomech Pelvis Tilt: 15.0\n7...\n8Finished\n9Mocap streaming was stopped\n\n1\n\nAPI is initialized via api = ts_api.TsApi().\n\n2\n\nThe program waits for a Teslasuit device to connect using api.get_device_manager().get_or_wait_last_device_attached().\n\n3\n\nThe Mocap subsystem of the connected device is accessed via device.mocap.\n\n4\n\nMocap data streaming is initiated with mocap.start_streaming().\n\n5\n\nRaw bone data for the right upper arm is printed using mocap.get_raw_data_on_ready().\n\n6\n\nBiomechanical pelvis tilt data is printed using mocap.get_biomechanical_angles_on_ready().\n\n7\n\nThe loop continues for the specified number of frames.\n\n8\n\nA message is printed when streaming is finished.\n\n9\n\nMocap streaming is stopped, and a confirmation message is printed.",
    "crumbs": [
      "Examples",
      "Mocap example"
    ]
  },
  {
    "objectID": "examples/ppg_example.html#quick-access",
    "href": "examples/ppg_example.html#quick-access",
    "title": "PPG example",
    "section": "Quick access",
    "text": "Quick access\n\nMain concept\nPPG Subsystem\nUsecase\nPPG data structures",
    "crumbs": [
      "Examples",
      "PPG example"
    ]
  },
  {
    "objectID": "examples/ppg_example.html#intro",
    "href": "examples/ppg_example.html#intro",
    "title": "PPG example",
    "section": "Intro",
    "text": "Intro\nThis web page provides a comprehensive guide on how to retrieve data from the PPG (Photoplethysmography) sensor of a Teslasuit device. The page is structured to help developers understand the process of initializing the Teslasuit API, connecting to a device, accessing the PPG subsystem, and streaming data such as heart rate and HRV (Heart Rate Variability).",
    "crumbs": [
      "Examples",
      "PPG example"
    ]
  },
  {
    "objectID": "examples/ppg_example.html#code-for-hrv-data",
    "href": "examples/ppg_example.html#code-for-hrv-data",
    "title": "PPG example",
    "section": "Code for HRV data",
    "text": "Code for HRV data\n\n1from teslasuit_sdk import ts_api\n2import teslasuit_sdk.subsystems.ts_ppg\n\ndef main():\n3    print(\"Initializing Teslasuit API...\")\n    api = ts_api.TsApi()\n\n4    print(\"Waiting for a Teslasuit device to connect...\")\n    device = api.get_device_manager().get_or_wait_last_device_attached()\n\n5    print(\"Accessing the PPG subsystem...\")\n    ppg = device.ppg\n\n6    print(\"Starting raw PPG data streaming...\")\n    ppg.start_raw_streaming()\n\n    print(\"Waiting for HRV data (Mean R-R)...\")\n    while True:\n7        hrv_data = ppg.get_hrv_data_on_ready()\n8        print(\"Mean R-R Interval:\", hrv_data.mean_rr)\n\n# Entry point for the script\nif __name__ == \"__main__\":\n9    main()\n\n1\n\nImport the main Teslasuit API module.\n\n2\n\nImport the PPG subsystem from the SDK.\n\n3\n\nCreate an instance of the Teslasuit API.\n\n4\n\nWait for a Teslasuit device to be connected and get it.\n\n5\n\nAccess the PPG subsystem from the device.\n\n6\n\nStart streaming raw PPG data from the suit.\n\n7\n\nWait for HRV data to become available.\n\n8\n\nPrint the mean R-R interval from HRV data.\n\n9\n\nStart the program using the main function.",
    "crumbs": [
      "Examples",
      "PPG example"
    ]
  },
  {
    "objectID": "examples/ppg_example.html#expected-output",
    "href": "examples/ppg_example.html#expected-output",
    "title": "PPG example",
    "section": "Expected output",
    "text": "Expected output\n\n1Initializing Teslasuit API...\n2Waiting for a Teslasuit device to connect...\n3Accessing the PPG subsystem...\n4Starting raw PPG data streaming...\n5Waiting for HRV data (Mean R-R)...\n6Mean R-R Interval: 750\n\n1\n\nApi is initialized via api = ts_api.TsApi()\n\n2\n\nThe program waits for a Teslasuit device to connect using api.get_device_manager().get_or_wait_last_device_attached().\n\n3\n\nThe PPG subsystem of the connected device is accessed via device.ppg.\n\n4\n\nRaw PPG data streaming is initiated with ppg.start_raw_streaming().\n\n5\n\nThe program enters a loop to wait for HRV data, specifically the Mean R-R interval, using ppg.get_hrv_data_on_ready().\n\n6\n\nThe Mean R-R interval is printed to the console as it becomes available.\n\n\n ⚠️ Safety First! In order to get valid HRV data, you have to wait for at least 30 seconds before getting actual data.**",
    "crumbs": [
      "Examples",
      "PPG example"
    ]
  },
  {
    "objectID": "examples/ppg_example.html#code-for-heart-rate-data",
    "href": "examples/ppg_example.html#code-for-heart-rate-data",
    "title": "PPG example",
    "section": "Code for Heart rate data",
    "text": "Code for Heart rate data\n\n1from teslasuit_sdk import ts_api\n2import teslasuit_sdk.subsystems.ts_ppg\n\ndef main():\n3    print(\"Initializing Teslasuit API...\")\n    api = ts_api.TsApi()\n\n4    print(\"Waiting for a Teslasuit device to connect...\")\n    device = api.get_device_manager().get_or_wait_last_device_attached()\n\n5    print(\"Accessing the PPG subsystem...\")\n    ppg = device.ppg\n\n6    print(\"Starting raw PPG data streaming...\")\n    ppg.start_raw_streaming()\n\n    # Wait for and print Heart Rate data from the PPG node\n    print(\"Waiting for Heart Rate data...\")\n    while True:\n7        node_data = ppg.get_data()\n8        print(\"Heart Rate:\", node_data.nodes[0].heart_rate)\n\n# Entry point for the script\nif __name__ == \"__main__\":\n9    main()\n\n1\n\nImport the main Teslasuit API module.\n\n2\n\nImport the PPG subsystem from the SDK.\n\n3\n\nCreate an instance of the Teslasuit API.\n\n4\n\nWait for a Teslasuit device to be connected and get it.\n\n5\n\nAccess the PPG subsystem from the device.\n\n6\n\nStart streaming raw PPG data from the suit.\n\n7\n\nGet PPG data from the node.\n\n8\n\nPrint the current heart rate from the first node.\n\n9\n\nStart the program using the main function.",
    "crumbs": [
      "Examples",
      "PPG example"
    ]
  },
  {
    "objectID": "examples/ppg_example.html#expected-output-1",
    "href": "examples/ppg_example.html#expected-output-1",
    "title": "PPG example",
    "section": "Expected output",
    "text": "Expected output\n\n1Initializing Teslasuit API...\n2Waiting for a Teslasuit device to connect...\n3Accessing the PPG subsystem...\n4Starting raw PPG data streaming...\n5Waiting for Heart Rate data...\n6Heart Rate: 72\n\n1\n\nApi is initialized via api = ts_api.TsApi()\n\n2\n\nThe program waits for a Teslasuit device to connect using api.get_device_manager().get_or_wait_last_device_attached().\n\n3\n\nThe PPG subsystem of the connected device is accessed via device.ppg.\n\n4\n\nRaw PPG data streaming is initiated with ppg.start_raw_streaming().\n\n5\n\nThe program enters another loop to wait for heart rate data from the first PPG node using ppg.get_data().\n\n6\n\nThe heart rate value is printed to the console as it becomes available using node_data.nodes[0].heart_rate()",
    "crumbs": [
      "Examples",
      "PPG example"
    ]
  },
  {
    "objectID": "examples/haptic_example.html#quick-access",
    "href": "examples/haptic_example.html#quick-access",
    "title": "Haptic example",
    "section": "Quick access",
    "text": "Quick access\n\nMain concept\nHaptic Subsystem\nHaptic data structures",
    "crumbs": [
      "Examples",
      "Haptic example"
    ]
  },
  {
    "objectID": "examples/haptic_example.html#intro",
    "href": "examples/haptic_example.html#intro",
    "title": "Haptic example",
    "section": "Intro",
    "text": "Intro\nThis web page provides a comprehensive guide on how to create and play haptic feedback on a Teslasuit device. The page is structured to help developers understand the process of initializing the Teslasuit API, connecting to a device, accessing the Haptic subsystem, and playing haptic touches.",
    "crumbs": [
      "Examples",
      "Haptic example"
    ]
  },
  {
    "objectID": "examples/haptic_example.html#code-for-haptic-touch",
    "href": "examples/haptic_example.html#code-for-haptic-touch",
    "title": "Haptic example",
    "section": "Code for Haptic Touch",
    "text": "Code for Haptic Touch\nimport time\nimport _setup_sys_path\n\n1from teslasuit_sdk import ts_api\n2import teslasuit_sdk.subsystems.ts_haptic\n3from teslasuit_sdk.ts_mapper import TsBone2dIndex\n\n4TOUCH_DURATION_MS = 3000\n\ndef main():\n    try:\n5        print(\"Initialize API\")\n        api = ts_api.TsApi()\n\n6        device = api.get_device_manager().get_or_wait_last_device_attached()\n7        player = device.haptic\n8        mapper = api.mapper\n\n9        print(\"Setup channels to play and touch parameters\")\n        layout = mapper.get_haptic_electric_channel_layout(device.get_mapping())\n10        bones = mapper.get_layout_bones(layout)\n11        channels = mapper.get_bone_contents(bones[TsBone2dIndex.RightUpperArm.value])\n12        params = player.create_touch_parameters(100, 40, 150)\n\n13        print(\"Create touch and play\")\n        playable_id = player.create_touch(params, channels, TOUCH_DURATION_MS)\n14        player.play_playable(playable_id)\n\n15        print(\"Wait until playback finished...\")\n        time.sleep(TOUCH_DURATION_MS / 1000)\n16        print(\"Finished\")\n\n17    except (KeyboardInterrupt, SystemExit):\n        print('\\n! Received keyboard interrupt, quitting haptic touch play\\n')\n\n\nif __name__ == '__main__':\n18    main()\n\n1\n\nImport the main Teslasuit API module.\n\n2\n\nImport the Haptic subsystem from the SDK.\n\n3\n\nImport the TsBone2dIndex for mapping bones.\n\n4\n\nDefine the duration of the haptic touch in milliseconds.\n\n5\n\nInitialize the Teslasuit API.\n\n6\n\nWait for a Teslasuit device to connect and get it.\n\n7\n\nAccess the Haptic subsystem from the device.\n\n8\n\nAccess the mapper for haptic channel mapping.\n\n9\n\nRetrieve the haptic channel layout for the device.\n\n10\n\nGet the bones from the layout.\n\n11\n\nRetrieve the haptic channels for the right upper arm.\n\n12\n\nCreate touch parameters with period, amplitude, and pulse width.\n\n13\n\nCreate a haptic touch and play it.\n\n14\n\nPlay the created haptic touch.\n\n15\n\nWait for the playback to finish.\n\n16\n\nPrint “Finished” after playback ends.\n\n17\n\nHandle keyboard interrupts gracefully.\n\n18\n\nStart the program using the main function.",
    "crumbs": [
      "Examples",
      "Haptic example"
    ]
  },
  {
    "objectID": "examples/haptic_example.html#expected-output",
    "href": "examples/haptic_example.html#expected-output",
    "title": "Haptic example",
    "section": "Expected output",
    "text": "Expected output\n1Initialize API\n2Setup channels to play and touch parameters\n3Create touch and play\n4Wait until playback finished...\n5Finished\n\n1\n\nThe API is initialized via api = ts_api.TsApi().\n\n2\n\nChannels and touch parameters are set up using the mapper and haptic subsystem.\n\n3\n\nA haptic touch is created and played using player.create_touch() and player.play_playable().\n\n4\n\nThe program waits for the playback to finish using time.sleep().\n\n5\n\nThe program prints “Finished” after the playback ends.\n\n\n ⚠️ Safety First! Ensure the Teslasuit device is connected and properly calibrated before running the script.**",
    "crumbs": [
      "Examples",
      "Haptic example"
    ]
  },
  {
    "objectID": "Main concepts/emg_concept.html#quick-access",
    "href": "Main concepts/emg_concept.html#quick-access",
    "title": "EMG (experimental)",
    "section": "Quick access",
    "text": "Quick access\n\nEMG Subsystem\nExamples\nEMG Data structures",
    "crumbs": [
      "Main concepts",
      "EMG (experimental)"
    ]
  },
  {
    "objectID": "Main concepts/emg_concept.html#what-is-emg",
    "href": "Main concepts/emg_concept.html#what-is-emg",
    "title": "EMG (experimental)",
    "section": "What is EMG?",
    "text": "What is EMG?\nElectromyography (EMG) is a technique for evaluating and recording the electrical activity produced by skeletal muscles. EMG sensors detect electrical signals generated by muscle fibers during contraction and relaxation. This data is widely used in medical diagnostics, rehabilitation, biomechanics, and human-computer interaction to assess muscle function, fatigue, and neuromuscular health.\nEMG is a key technology in wearable devices, enabling real-time monitoring of muscle activity. Its applications range from gesture recognition and prosthetics control to sports science and rehabilitation.",
    "crumbs": [
      "Main concepts",
      "EMG (experimental)"
    ]
  },
  {
    "objectID": "Main concepts/emg_concept.html#emg-in-teslasuit",
    "href": "Main concepts/emg_concept.html#emg-in-teslasuit",
    "title": "EMG (experimental)",
    "section": "EMG in Teslasuit",
    "text": "EMG in Teslasuit\nThe Teslasuit integrates EMG technology as part of its biometry subsystem, enabling advanced muscle activity monitoring. The EMG subsystem in the Teslasuit is designed to provide real-time data on muscle activation, raw EMG signals, and configurable filtering options. This data can be used for various applications, including gesture recognition, fatigue monitoring, and biofeedback.\nThe Teslasuit’s EMG functionality is accessible through the TsEmg class, which provides methods for streaming raw data, setting filter options, and retrieving processed EMG data. The EMG subsystem is tightly integrated with the Teslasuit API, allowing developers to seamlessly incorporate EMG data into their applications.",
    "crumbs": [
      "Main concepts",
      "EMG (experimental)"
    ]
  },
  {
    "objectID": "Main concepts/emg_concept.html#key-features-of-the-teslasuit-emg-subsystem",
    "href": "Main concepts/emg_concept.html#key-features-of-the-teslasuit-emg-subsystem",
    "title": "EMG (experimental)",
    "section": "Key Features of the Teslasuit EMG Subsystem",
    "text": "Key Features of the Teslasuit EMG Subsystem\n\nRaw Data Streaming: The Teslasuit EMG subsystem allows developers to stream raw EMG data in real time for custom signal processing and analysis.\nConfigurable Filtering: The subsystem provides options to set filter parameters such as bandwidth, sampling frequency, and sample size for optimal signal quality.\nMulti-Node and Multi-Channel Support: The EMG subsystem supports multiple sensor nodes and channels, enabling comprehensive muscle activity monitoring across different body areas.\nTimestamps and Synchronization: Each EMG data sample is timestamped, allowing for precise synchronization with other sensor data.",
    "crumbs": [
      "Main concepts",
      "EMG (experimental)"
    ]
  },
  {
    "objectID": "Main concepts/emg_concept.html#how-the-teslasuit-api-implements-emg",
    "href": "Main concepts/emg_concept.html#how-the-teslasuit-api-implements-emg",
    "title": "EMG (experimental)",
    "section": "How the Teslasuit API Implements EMG",
    "text": "How the Teslasuit API Implements EMG\nThe Teslasuit API provides a structured approach to accessing and utilizing EMG data. Below are the key steps involved:\n\nInitialization: The Teslasuit API must be initialized before accessing the EMG subsystem. This ensures that the API is ready to communicate with the Teslasuit device.\nDevice Connection: A Teslasuit device must be connected to access its EMG subsystem. The API provides methods to wait for and retrieve connected devices.\nSubsystem Access: The EMG subsystem is accessed through the emg property of the connected device. This property returns an instance of the TsEmg class.\nData Streaming and Retrieval: The TsEmg class provides methods to start/stop streaming and retrieve EMG data with the desired configuration.",
    "crumbs": [
      "Main concepts",
      "EMG (experimental)"
    ]
  },
  {
    "objectID": "Main concepts/emg_concept.html#description-of-emg-data",
    "href": "Main concepts/emg_concept.html#description-of-emg-data",
    "title": "EMG (experimental)",
    "section": "Description of EMG Data",
    "text": "Description of EMG Data\nBelow is a detailed description of the EMG data and data structures used in the Teslasuit API for the EMG subsystem.\n\nEMG Options\n\nWhat are EMG Options?\nEMG options define the filtering and sampling parameters for EMG data acquisition. The main options include:\n\nLower Bandwidth: The lower cutoff frequency for the EMG signal filter.\nUpper Bandwidth: The upper cutoff frequency for the EMG signal filter.\nSampling Frequency: The rate at which EMG samples are collected.\nSample Size: The number of samples per data packet.\n\n\n\nWhy EMG Options Matter\nBy configuring these options, developers can optimize EMG signal quality for different applications, reduce noise, and tailor data acquisition to specific muscle activity patterns.\n\n\nEMG Options in Teslasuit\nTeslasuit exposes EMG options through the TsEmgOptions structure. These options can be set using the set_options() method of the TsEmg class.\n\n\n\nEMG Data Structures\n\nTsEmgChannelData: Represents EMG data for a single channel, including channel index, number of samples, and the sample values.\nTsEmgNodeData: Represents EMG data for a single node, including node index, channels, and timestamps.\nTsEmgData: Represents the complete EMG data set, including all nodes, channels, and options.",
    "crumbs": [
      "Main concepts",
      "EMG (experimental)"
    ]
  },
  {
    "objectID": "Main concepts/emg_concept.html#applications-of-emg-in-teslasuit",
    "href": "Main concepts/emg_concept.html#applications-of-emg-in-teslasuit",
    "title": "EMG (experimental)",
    "section": "Applications of EMG in Teslasuit",
    "text": "Applications of EMG in Teslasuit\nThe EMG subsystem in the Teslasuit has a wide range of applications, including:\n\nGesture Recognition: Detect and classify hand or body gestures based on muscle activity patterns.\nRehabilitation: Monitor muscle activation and fatigue during therapy and recovery exercises.\nSports Science: Analyze muscle performance, coordination, and fatigue in athletes.\nHuman-Computer Interaction: Enable intuitive control of devices and virtual environments using muscle signals.",
    "crumbs": [
      "Main concepts",
      "EMG (experimental)"
    ]
  },
  {
    "objectID": "Main concepts/emg_concept.html#dependencies-in-data-structures-and-accessing-data",
    "href": "Main concepts/emg_concept.html#dependencies-in-data-structures-and-accessing-data",
    "title": "EMG (experimental)",
    "section": "Dependencies in Data Structures and Accessing Data",
    "text": "Dependencies in Data Structures and Accessing Data\nThe Teslasuit EMG subsystem relies on a hierarchy of data structures to manage and process EMG data. Below is a detailed description of the dependencies between these structures and a block scheme illustrating how data is accessed.\n\nData Structure Dependencies\n\nTsEmgOptions:\n\nRepresents EMG filter and sampling options.\n\nTsEmgChannelData:\n\nRepresents EMG data for a single channel (samples, channel index).\n\nTsEmgNodeData:\n\nRepresents EMG data for a single node (channels, timestamps).\n\nTsEmgData:\n\nRepresents the complete EMG data set (nodes, options).\n\n\n\n\nBlock Scheme for Accessing Data\nBelow is a simplified block scheme illustrating the flow of data from options and nodes to channel samples:\n\n\n\n\n\nflowchart TD\n    A([TsEmgData]) --&gt; B[[TsEmgNodeData]]\n    B --&gt; C[[TsEmgChannelData]]\n    C --&gt; D((samples))\n    A --&gt; E[[TsEmgOptions]]\n    E --&gt; F((lower_bandwidth))\n    E --&gt; G((upper_bandwidth))\n    E --&gt; H((sampling_frequency))\n    E --&gt; I((sample_size))",
    "crumbs": [
      "Main concepts",
      "EMG (experimental)"
    ]
  },
  {
    "objectID": "Main concepts/emg_concept.html#example-code",
    "href": "Main concepts/emg_concept.html#example-code",
    "title": "EMG (experimental)",
    "section": "Example Code",
    "text": "Example Code\nFor detailed examples of how to use the EMG subsystem in the Teslasuit API, refer to the EMG Examples page. These examples demonstrate how to initialize the API, connect to a device, and retrieve EMG data.",
    "crumbs": [
      "Main concepts",
      "EMG (experimental)"
    ]
  },
  {
    "objectID": "Main concepts/emg_concept.html#conclusion",
    "href": "Main concepts/emg_concept.html#conclusion",
    "title": "EMG (experimental)",
    "section": "Conclusion",
    "text": "Conclusion\nThe EMG subsystem in the Teslasuit represents a powerful tool for real-time muscle activity monitoring. By leveraging the Teslasuit API, developers can integrate EMG data into a wide range of applications, from gesture recognition to rehabilitation and sports science.",
    "crumbs": [
      "Main concepts",
      "EMG (experimental)"
    ]
  },
  {
    "objectID": "Main concepts/current_feedback_concept.html#quick-access",
    "href": "Main concepts/current_feedback_concept.html#quick-access",
    "title": "Current feedback (experimental)",
    "section": "Quick access",
    "text": "Quick access\n\nCurrent feedback Subsystem\nExamples\nCurrent feedback Data structures",
    "crumbs": [
      "Main concepts",
      "Current feedback (experimental)"
    ]
  },
  {
    "objectID": "Main concepts/current_feedback_concept.html#what-is-current-feedback",
    "href": "Main concepts/current_feedback_concept.html#what-is-current-feedback",
    "title": "Current feedback (experimental)",
    "section": "What is Current Feedback?",
    "text": "What is Current Feedback?\nCurrent feedback refers to the real-time measurement and monitoring of electrical current delivered to electrodes in wearable devices. In the context of Teslasuit, current feedback enables precise tracking of the actual current supplied to haptic, stimulation, or sensor channels, ensuring safety, device integrity, and accurate feedback for closed-loop control.\nCurrent feedback is essential for verifying that the intended electrical stimulation is being delivered as expected. It helps detect anomalies, prevent overcurrent conditions, and provide diagnostic information for both developers and end users.",
    "crumbs": [
      "Main concepts",
      "Current feedback (experimental)"
    ]
  },
  {
    "objectID": "Main concepts/current_feedback_concept.html#current-feedback-in-teslasuit",
    "href": "Main concepts/current_feedback_concept.html#current-feedback-in-teslasuit",
    "title": "Current feedback (experimental)",
    "section": "Current Feedback in Teslasuit",
    "text": "Current Feedback in Teslasuit\nThe Teslasuit integrates current feedback technology as part of its hardware monitoring and safety subsystem. The current feedback subsystem provides real-time data on the current values for each node and channel in the suit. This allows developers to monitor electrical delivery, validate stimulation protocols, and implement safety checks in their applications.\nThe Teslasuit’s current feedback functionality is accessible through the TsCurrentFeedback class, which provides methods for starting and stopping data streaming, as well as retrieving current feedback data for all nodes and channels. The subsystem is tightly integrated with the Teslasuit API, enabling seamless access to current measurements during operation.",
    "crumbs": [
      "Main concepts",
      "Current feedback (experimental)"
    ]
  },
  {
    "objectID": "Main concepts/current_feedback_concept.html#key-features-of-the-teslasuit-current-feedback-subsystem",
    "href": "Main concepts/current_feedback_concept.html#key-features-of-the-teslasuit-current-feedback-subsystem",
    "title": "Current feedback (experimental)",
    "section": "Key Features of the Teslasuit Current Feedback Subsystem",
    "text": "Key Features of the Teslasuit Current Feedback Subsystem\n\nReal-Time Data Streaming: Stream current feedback data from all nodes and channels in real time.\nMulti-Node, Multi-Channel Support: Monitor current values across multiple hardware nodes and channels simultaneously.\nSafety and Diagnostics: Use current feedback to detect abnormal conditions, verify stimulation delivery, and ensure device safety.\nIntegration with Other Subsystems: Combine current feedback data with haptic, EMG, or other sensor data for advanced closed-loop applications.",
    "crumbs": [
      "Main concepts",
      "Current feedback (experimental)"
    ]
  },
  {
    "objectID": "Main concepts/current_feedback_concept.html#how-the-teslasuit-api-implements-current-feedback",
    "href": "Main concepts/current_feedback_concept.html#how-the-teslasuit-api-implements-current-feedback",
    "title": "Current feedback (experimental)",
    "section": "How the Teslasuit API Implements Current Feedback",
    "text": "How the Teslasuit API Implements Current Feedback\nThe Teslasuit API provides a structured approach to accessing and utilizing current feedback data. Below are the key steps involved:\n\nInitialization: The Teslasuit API must be initialized before accessing the current feedback subsystem.\nDevice Connection: A Teslasuit device must be connected to access its current feedback subsystem.\nSubsystem Access: The current feedback subsystem is accessed through the current_feedback property of the connected device, returning an instance of the TsCurrentFeedback class.\nData Streaming and Retrieval: The TsCurrentFeedback class provides methods to start/stop streaming and retrieve current feedback data.",
    "crumbs": [
      "Main concepts",
      "Current feedback (experimental)"
    ]
  },
  {
    "objectID": "Main concepts/current_feedback_concept.html#description-of-current-feedback-data",
    "href": "Main concepts/current_feedback_concept.html#description-of-current-feedback-data",
    "title": "Current feedback (experimental)",
    "section": "Description of Current Feedback Data",
    "text": "Description of Current Feedback Data\nBelow is a detailed description of the current feedback data and data structures used in the Teslasuit API for the current feedback subsystem.\n\nCurrent Feedback Data Structures\n\nTsCurrentFeedbackChannelData: Represents current feedback data for a single channel, including channel index and measured value.\nTsCurrentFeedbackNodeData: Represents current feedback data for a single node, including node index and a list of channel data.\nTsCurrentFeedbackNodes: Represents the collection of all current feedback nodes and their associated channel data.\n\n\nWhy Current Feedback Data Matters\nCurrent feedback data allows developers and researchers to:\n\nVerify that electrical stimulation or actuation is being delivered as intended.\nDetect hardware faults, overcurrent, or undercurrent conditions.\nImplement closed-loop control algorithms that adjust stimulation based on real-time measurements.\nEnsure user safety and device reliability.\n\n\n\nCurrent Feedback Parameters in Teslasuit\nTeslasuit exposes current feedback parameters through the TsCurrentFeedbackNodes and related structures. These can be accessed using the TsCurrentFeedback class methods.",
    "crumbs": [
      "Main concepts",
      "Current feedback (experimental)"
    ]
  },
  {
    "objectID": "Main concepts/current_feedback_concept.html#applications-of-current-feedback-in-teslasuit",
    "href": "Main concepts/current_feedback_concept.html#applications-of-current-feedback-in-teslasuit",
    "title": "Current feedback (experimental)",
    "section": "Applications of Current Feedback in Teslasuit",
    "text": "Applications of Current Feedback in Teslasuit\nThe current feedback subsystem in the Teslasuit has a wide range of applications, including:\n\nSafety Monitoring: Detect and respond to abnormal current delivery in real time.\nDiagnostics and Maintenance: Identify hardware issues or degradation over time.\nClosed-Loop Control: Adjust stimulation or actuation parameters based on measured current.\nResearch and Development: Analyze current delivery patterns for optimization and validation.",
    "crumbs": [
      "Main concepts",
      "Current feedback (experimental)"
    ]
  },
  {
    "objectID": "Main concepts/current_feedback_concept.html#dependencies-in-data-structures-and-accessing-data",
    "href": "Main concepts/current_feedback_concept.html#dependencies-in-data-structures-and-accessing-data",
    "title": "Current feedback (experimental)",
    "section": "Dependencies in Data Structures and Accessing Data",
    "text": "Dependencies in Data Structures and Accessing Data\nThe Teslasuit current feedback subsystem relies on a hierarchy of data structures to manage and process current feedback data. Below is a detailed description of the dependencies between these structures and a block scheme illustrating how data is accessed.\n\nData Structure Dependencies\n\nTsCurrentFeedbackNodes:\n\nRepresents all current feedback nodes.\n\nTsCurrentFeedbackNodeData:\n\nRepresents data for a single node, including channel data.\n\nTsCurrentFeedbackChannelData:\n\nRepresents data for a single channel, including the measured value.\n\n\n\n\nBlock Scheme for Accessing Data\nBelow is a simplified block scheme illustrating the flow of data from nodes to channel values:\n\n\n\n\n\nflowchart TD\n    A([TsCurrentFeedbackNodes]) --&gt; B[[TsCurrentFeedbackNodeData]]\n    B --&gt; C[[TsCurrentFeedbackChannelData]]\n    C --&gt; D((value))",
    "crumbs": [
      "Main concepts",
      "Current feedback (experimental)"
    ]
  },
  {
    "objectID": "Main concepts/current_feedback_concept.html#example-code",
    "href": "Main concepts/current_feedback_concept.html#example-code",
    "title": "Current feedback (experimental)",
    "section": "Example Code",
    "text": "Example Code\nFor detailed examples of how to use the current feedback subsystem in the Teslasuit API, refer to the Current Feedback Examples page. These examples demonstrate how to initialize the API, connect to a device, and retrieve current feedback data.",
    "crumbs": [
      "Main concepts",
      "Current feedback (experimental)"
    ]
  },
  {
    "objectID": "Main concepts/current_feedback_concept.html#conclusion",
    "href": "Main concepts/current_feedback_concept.html#conclusion",
    "title": "Current feedback (experimental)",
    "section": "Conclusion",
    "text": "Conclusion\nThe current feedback subsystem in the Teslasuit provides a robust and flexible platform for real-time monitoring of electrical current delivery. By leveraging the Teslasuit API, developers can ensure safety, optimize stimulation protocols, and enable advanced closed-loop applications.",
    "crumbs": [
      "Main concepts",
      "Current feedback (experimental)"
    ]
  },
  {
    "objectID": "Main concepts/bia_concept.html#quick-access",
    "href": "Main concepts/bia_concept.html#quick-access",
    "title": "BIA (experimental)",
    "section": "Quick access",
    "text": "Quick access\n\nBIA Subsystem\nExamples\nBIA Data structures",
    "crumbs": [
      "Main concepts",
      "BIA (experimental)"
    ]
  },
  {
    "objectID": "Main concepts/bia_concept.html#what-is-bia",
    "href": "Main concepts/bia_concept.html#what-is-bia",
    "title": "BIA (experimental)",
    "section": "What is BIA?",
    "text": "What is BIA?\nBioelectrical Impedance Analysis (BIA) is a non-invasive technique used to measure the electrical impedance of body tissues. By applying a small alternating current and measuring the resulting voltage, BIA provides information about body composition, such as total body water, fat-free mass, and fat mass. The impedance varies with tissue type and hydration, making BIA a valuable tool in health, fitness, and medical diagnostics.\nBIA is widely used in wearable devices and clinical settings for body composition analysis, hydration monitoring, and physiological research. Its applications range from sports science and wellness tracking to clinical assessment of fluid balance and nutrition.",
    "crumbs": [
      "Main concepts",
      "BIA (experimental)"
    ]
  },
  {
    "objectID": "Main concepts/bia_concept.html#bia-in-teslasuit",
    "href": "Main concepts/bia_concept.html#bia-in-teslasuit",
    "title": "BIA (experimental)",
    "section": "BIA in Teslasuit",
    "text": "BIA in Teslasuit\nThe Teslasuit integrates BIA technology as part of its biometry subsystem, enabling advanced physiological monitoring capabilities. The BIA subsystem in the Teslasuit is designed to provide real-time data on tissue impedance across multiple channels and frequencies. This data can be used for applications such as hydration monitoring, body composition analysis, and research into physiological responses.\nThe Teslasuit’s BIA functionality is accessible through the TsBia class, which provides methods for configuring streaming, starting and stopping data acquisition, and retrieving BIA data. The BIA subsystem is tightly integrated with the Teslasuit API, allowing developers to seamlessly incorporate BIA data into their applications.",
    "crumbs": [
      "Main concepts",
      "BIA (experimental)"
    ]
  },
  {
    "objectID": "Main concepts/bia_concept.html#key-features-of-the-teslasuit-bia-subsystem",
    "href": "Main concepts/bia_concept.html#key-features-of-the-teslasuit-bia-subsystem",
    "title": "BIA (experimental)",
    "section": "Key Features of the Teslasuit BIA Subsystem",
    "text": "Key Features of the Teslasuit BIA Subsystem\n\nMulti-Channel Support: The Teslasuit BIA subsystem allows developers to stream impedance data from multiple channels (electrode pairs) simultaneously.\nMulti-Frequency Analysis: The subsystem supports impedance measurements across a range of frequencies, enabling detailed tissue characterization.\nComplex Impedance Data: BIA data includes both real and imaginary components, providing insight into resistive and reactive properties of tissues.\nConfigurable Streaming: Developers can configure which channels and frequencies to stream, optimizing data collection for specific applications.",
    "crumbs": [
      "Main concepts",
      "BIA (experimental)"
    ]
  },
  {
    "objectID": "Main concepts/bia_concept.html#how-the-teslasuit-api-implements-bia",
    "href": "Main concepts/bia_concept.html#how-the-teslasuit-api-implements-bia",
    "title": "BIA (experimental)",
    "section": "How the Teslasuit API Implements BIA",
    "text": "How the Teslasuit API Implements BIA\nThe Teslasuit API provides a structured approach to accessing and utilizing BIA data. Below are the key steps involved:\n\nInitialization: The Teslasuit API must be initialized before accessing the BIA subsystem. This ensures that the API is ready to communicate with the Teslasuit device.\nDevice Connection: A Teslasuit device must be connected to access its BIA subsystem. The API provides methods to wait for and retrieve connected devices.\nSubsystem Access: The BIA subsystem is accessed through the bia property of the connected device. This property returns an instance of the TsBia class.\nData Streaming and Retrieval: The TsBia class provides methods to configure streaming, start/stop data acquisition, and retrieve BIA data.",
    "crumbs": [
      "Main concepts",
      "BIA (experimental)"
    ]
  },
  {
    "objectID": "Main concepts/bia_concept.html#description-of-bia-data",
    "href": "Main concepts/bia_concept.html#description-of-bia-data",
    "title": "BIA (experimental)",
    "section": "Description of BIA Data",
    "text": "Description of BIA Data\nBelow is a detailed description of the BIA data and data structures used in the Teslasuit API for the BIA subsystem.\n\nBIA Data Structures\n\nTsBiaConfig: Represents the configuration for BIA data streaming, including channels, frequency range, and step size.\nTsComplexNumber: Represents a complex number with real and imaginary parts, used for impedance data.\nTsBiaFrequencyData: Represents impedance data for a specific frequency, including the frequency value and associated complex impedance.\nTsBiaChannelData: Represents data for a single BIA channel, including channel index and a list of frequency data.\nTsBiaChannels: Represents all BIA channel data collected in a streaming session.\n\n\n\nBIA Parameters and Explanation\n\nChannels: Electrode pairs or sensor locations from which impedance is measured. Multiple channels allow for spatial mapping of tissue properties.\nFrequency: The frequency of the applied current. Different frequencies probe different tissue characteristics (e.g., cell membranes, extracellular fluid).\nComplex Impedance: Each measurement consists of a real part (resistance) and an imaginary part (reactance), providing a complete picture of tissue electrical properties.\n\n\nWhy BIA Parameters Matter\nBy analyzing impedance across multiple channels and frequencies, developers and researchers can gain insights into body composition, hydration status, and physiological changes. The real and imaginary components help distinguish between different tissue types and fluid compartments.\n\n\nBIA Parameters in Teslasuit\nTeslasuit exposes BIA parameters through the TsBiaConfig and related data structures. These parameters can be set and retrieved using the TsBia class methods.",
    "crumbs": [
      "Main concepts",
      "BIA (experimental)"
    ]
  },
  {
    "objectID": "Main concepts/bia_concept.html#applications-of-bia-in-teslasuit",
    "href": "Main concepts/bia_concept.html#applications-of-bia-in-teslasuit",
    "title": "BIA (experimental)",
    "section": "Applications of BIA in Teslasuit",
    "text": "Applications of BIA in Teslasuit\nThe BIA subsystem in the Teslasuit has a wide range of applications, including:\n\nBody Composition Analysis: Estimate fat-free mass, fat mass, and total body water.\nHydration Monitoring: Track changes in body water content for wellness and performance.\nClinical Assessment: Support diagnosis and monitoring of fluid balance in medical settings.\nSports Science: Monitor physiological changes during training, recovery, and competition.\nResearch: Enable advanced studies of tissue properties and physiological responses.",
    "crumbs": [
      "Main concepts",
      "BIA (experimental)"
    ]
  },
  {
    "objectID": "Main concepts/bia_concept.html#dependencies-in-data-structures-and-accessing-data",
    "href": "Main concepts/bia_concept.html#dependencies-in-data-structures-and-accessing-data",
    "title": "BIA (experimental)",
    "section": "Dependencies in Data Structures and Accessing Data",
    "text": "Dependencies in Data Structures and Accessing Data\nThe Teslasuit BIA subsystem relies on a hierarchy of data structures to manage and process impedance data. Below is a detailed description of the dependencies between these structures and a block scheme illustrating how data is accessed.\n\nData Structure Dependencies\n\nTsBiaChannels:\n\nRepresents all BIA channel data.\n\nTsBiaChannelData:\n\nRepresents data for a single channel, including frequency data.\n\nTsBiaFrequencyData:\n\nRepresents impedance data for a specific frequency.\n\nTsComplexNumber:\n\nRepresents the real and imaginary parts of impedance.\n\n\n\n\nBlock Scheme for Accessing Data\nBelow is a simplified block scheme illustrating the flow of data from channels to frequency-specific impedance values:\n\n\n\n\n\nflowchart TD\n    A([TsBiaChannels]) --&gt; B[[TsBiaChannelData]]\n    B --&gt; C[[TsBiaFrequencyData]]\n    C --&gt; D[[TsComplexNumber]]\n    D --&gt; E((real_value))\n    D --&gt; F((im_value))",
    "crumbs": [
      "Main concepts",
      "BIA (experimental)"
    ]
  },
  {
    "objectID": "Main concepts/bia_concept.html#example-code",
    "href": "Main concepts/bia_concept.html#example-code",
    "title": "BIA (experimental)",
    "section": "Example Code",
    "text": "Example Code\nFor detailed examples of how to use the BIA subsystem in the Teslasuit API, refer to the BIA Examples page. These examples demonstrate how to initialize the API, connect to a device, configure streaming, and retrieve BIA data.",
    "crumbs": [
      "Main concepts",
      "BIA (experimental)"
    ]
  },
  {
    "objectID": "Main concepts/bia_concept.html#conclusion",
    "href": "Main concepts/bia_concept.html#conclusion",
    "title": "BIA (experimental)",
    "section": "Conclusion",
    "text": "Conclusion\nThe BIA subsystem in the Teslasuit represents a powerful tool for real-time physiological and body composition monitoring. By leveraging the Teslasuit API, developers can integrate BIA data into a wide range of applications, from wellness and sports science to clinical research.",
    "crumbs": [
      "Main concepts",
      "BIA (experimental)"
    ]
  },
  {
    "objectID": "Main concepts/force_feedback_concept.html#quick-access",
    "href": "Main concepts/force_feedback_concept.html#quick-access",
    "title": "Force Feedback (Teslaglove)",
    "section": "Quick access",
    "text": "Quick access\n\nForce Feedback Subsystem\nExamples\nMagnetic Encoder Data structures",
    "crumbs": [
      "Main concepts",
      "Force Feedback (Teslaglove)"
    ]
  },
  {
    "objectID": "Main concepts/force_feedback_concept.html#what-is-force-feedback",
    "href": "Main concepts/force_feedback_concept.html#what-is-force-feedback",
    "title": "Force Feedback (Teslaglove)",
    "section": "What is Force Feedback?",
    "text": "What is Force Feedback?\nForce feedback is a technology that provides physical sensations to the user by applying force or resistance through motors. In wearable devices like Teslaglove, force feedback is typically implemented using servomotors or similar mechanisms to restrict or guide movement, simulate resistance, or provide tactile cues.\nForce feedback enhances immersion and realism in virtual and augmented reality, training, and simulation by allowing users to physically feel virtual objects, boundaries, or forces. It is widely used in robotics, gaming, rehabilitation, and haptics research.",
    "crumbs": [
      "Main concepts",
      "Force Feedback (Teslaglove)"
    ]
  },
  {
    "objectID": "Main concepts/force_feedback_concept.html#force-feedback-in-teslaglove",
    "href": "Main concepts/force_feedback_concept.html#force-feedback-in-teslaglove",
    "title": "Force Feedback (Teslaglove)",
    "section": "Force Feedback in Teslaglove",
    "text": "Force Feedback in Teslaglove\nTeslaglove integrates force feedback technology using magnetic encoders and servomotors to deliver programmable resistance and movement restriction to the fingers. The force feedback subsystem allows developers to configure the angle, hardness, and lock direction for each finger joint, enabling a wide range of interaction scenarios.\nThe force feedback functionality is accessible through the TsMagneticEncoder class, which provides methods for enabling/disabling force feedback, configuring parameters, and streaming finger position data. The subsystem is tightly integrated with the Teslasuit API, allowing seamless control and feedback in real time.",
    "crumbs": [
      "Main concepts",
      "Force Feedback (Teslaglove)"
    ]
  },
  {
    "objectID": "Main concepts/force_feedback_concept.html#key-features-of-the-teslaglove-force-feedback-subsystem",
    "href": "Main concepts/force_feedback_concept.html#key-features-of-the-teslaglove-force-feedback-subsystem",
    "title": "Force Feedback (Teslaglove)",
    "section": "Key Features of the Teslaglove Force Feedback Subsystem",
    "text": "Key Features of the Teslaglove Force Feedback Subsystem\n\nProgrammable Resistance: Developers can set the angle and hardness (resistance) for each finger joint, simulating the feel of virtual objects or barriers.\nLock Direction Control: The subsystem supports locking movement in specific directions (up, down, or both), enabling complex interaction patterns.\nReal-Time Position Streaming: The API provides access to real-time finger position data for precise feedback and control.\nFlexible Configuration: Multiple fingers and joints can be controlled independently, allowing for highly customizable force feedback experiences.",
    "crumbs": [
      "Main concepts",
      "Force Feedback (Teslaglove)"
    ]
  },
  {
    "objectID": "Main concepts/force_feedback_concept.html#how-the-teslasuit-api-implements-force-feedback",
    "href": "Main concepts/force_feedback_concept.html#how-the-teslasuit-api-implements-force-feedback",
    "title": "Force Feedback (Teslaglove)",
    "section": "How the Teslasuit API Implements Force Feedback",
    "text": "How the Teslasuit API Implements Force Feedback\nThe Teslasuit API provides a structured approach to accessing and utilizing force feedback. Below are the key steps involved:\n\nInitialization: The Teslasuit API must be initialized before accessing the force feedback subsystem.\nDevice Connection: A Teslaglove device must be connected to access its magnetic encoder subsystem.\nSubsystem Access: The force feedback subsystem is accessed through the magnetic_encoder property of the connected device, returning an instance of the TsMagneticEncoder class.\nConfiguration and Control: The TsMagneticEncoder class provides methods to enable/disable force feedback, set parameters, and stream finger positions.",
    "crumbs": [
      "Main concepts",
      "Force Feedback (Teslaglove)"
    ]
  },
  {
    "objectID": "Main concepts/force_feedback_concept.html#description-of-force-feedback-data",
    "href": "Main concepts/force_feedback_concept.html#description-of-force-feedback-data",
    "title": "Force Feedback (Teslaglove)",
    "section": "Description of Force Feedback Data",
    "text": "Description of Force Feedback Data\nBelow is a detailed description of the force feedback data and data structures used in the Teslasuit API for the Teslaglove force feedback subsystem.\n\nForce Feedback Parameters\n\nWhat are Force Feedback Parameters?\nForce feedback parameters define how the servomotors restrict or guide finger movement. The main parameters include:\n\nBone Index: Specifies which finger joint the feedback is applied to.\nAngle: The target angle for the joint, in degrees.\nHardness Percent: The resistance level, from 0 (no resistance) to 100 (maximum resistance).\nLock Direction: The direction(s) in which movement is restricted (up, down, or both).\n\n\n\nWhy Force Feedback Parameters Matter\nBy adjusting these parameters, developers can simulate the feel of grasping objects, encountering barriers, or experiencing dynamic resistance. This enables realistic and interactive virtual experiences, as well as applications in rehabilitation and training.\n\n\nForce Feedback Parameters in Teslaglove\nTeslaglove exposes force feedback parameters through the TsForceFeedbackConfig structure. These parameters are passed to the magnetic encoder subsystem to configure force feedback for each finger joint.\n\n\n\nFinger Position Data\n\nTsFingerMEPosition: Represents the flexion and abduction angles of a finger.\nTsGloveMEPosition: Represents the positions of all fingers on a glove.\n\n\n\nLock Direction\n\nTsMagneticEncoderLockDirection: Enum specifying lock direction (Up, Down, or Both).",
    "crumbs": [
      "Main concepts",
      "Force Feedback (Teslaglove)"
    ]
  },
  {
    "objectID": "Main concepts/force_feedback_concept.html#applications-of-force-feedback-in-teslaglove",
    "href": "Main concepts/force_feedback_concept.html#applications-of-force-feedback-in-teslaglove",
    "title": "Force Feedback (Teslaglove)",
    "section": "Applications of Force Feedback in Teslaglove",
    "text": "Applications of Force Feedback in Teslaglove\nThe force feedback subsystem in the Teslaglove has a wide range of applications, including:\n\nImmersive VR/AR: Simulate the feel of virtual objects, textures, and boundaries for enhanced immersion.\nTraining and Simulation: Provide realistic resistance and guidance for skill acquisition and muscle memory.\nRehabilitation: Deliver programmable resistance for therapy and recovery exercises.\nGaming: Enhance gameplay with tactile cues and physical interaction.",
    "crumbs": [
      "Main concepts",
      "Force Feedback (Teslaglove)"
    ]
  },
  {
    "objectID": "Main concepts/force_feedback_concept.html#dependencies-in-data-structures-and-accessing-data",
    "href": "Main concepts/force_feedback_concept.html#dependencies-in-data-structures-and-accessing-data",
    "title": "Force Feedback (Teslaglove)",
    "section": "Dependencies in Data Structures and Accessing Data",
    "text": "Dependencies in Data Structures and Accessing Data\nThe Teslaglove force feedback subsystem relies on a hierarchy of data structures to manage and process force feedback effects. Below is a description of the dependencies between these structures and a block scheme illustrating how data is accessed.\n\nData Structure Dependencies\n\nTsForceFeedbackConfig:\n\nRepresents the configuration for force feedback (bone index, angle, hardness, lock direction).\n\nTsFingerMEPosition:\n\nRepresents the position (flexion and abduction angles) of a finger.\n\nTsGloveMEPosition:\n\nRepresents the positions of all fingers on a glove.\n\n\n\n\nBlock Scheme for Accessing Data\nBelow is a simplified block scheme illustrating the flow of data from configuration to feedback and position monitoring:\n\n\n\n\n\nflowchart TD\n    A([TsMagneticEncoder]) --&gt; B[[TsForceFeedbackConfig]]\n    A --&gt; C[[TsGloveMEPosition]]\n    C --&gt; D[[TsFingerMEPosition]]\n    D --&gt; E((flexion_angle))\n    D --&gt; F((abduction_angle))\n    B --&gt; G((bone_index))\n    B --&gt; H((angle))\n    B --&gt; I((hardness_percent))\n    B --&gt; J((lock_direction))",
    "crumbs": [
      "Main concepts",
      "Force Feedback (Teslaglove)"
    ]
  },
  {
    "objectID": "Main concepts/force_feedback_concept.html#example-code",
    "href": "Main concepts/force_feedback_concept.html#example-code",
    "title": "Force Feedback (Teslaglove)",
    "section": "Example Code",
    "text": "Example Code\nFor detailed examples of how to use the force feedback subsystem in the Teslasuit API, refer to the Force Feedback Examples page. These examples demonstrate how to initialize the API, connect to a device, and configure force feedback.",
    "crumbs": [
      "Main concepts",
      "Force Feedback (Teslaglove)"
    ]
  },
  {
    "objectID": "Main concepts/force_feedback_concept.html#conclusion",
    "href": "Main concepts/force_feedback_concept.html#conclusion",
    "title": "Force Feedback (Teslaglove)",
    "section": "Conclusion",
    "text": "Conclusion\nThe force feedback subsystem in the Teslaglove provides a powerful and flexible platform for delivering programmable resistance and tactile feedback. By leveraging the Teslasuit API, developers can create immersive, interactive, and responsive experiences across a wide range of applications.",
    "crumbs": [
      "Main concepts",
      "Force Feedback (Teslaglove)"
    ]
  },
  {
    "objectID": "usecases/ppg_visualiser.html#quick-access",
    "href": "usecases/ppg_visualiser.html#quick-access",
    "title": "Real-time heart rate visualiser",
    "section": "Quick access",
    "text": "Quick access\n\nMain concept\nExamples\nPPG Subsystem\nPPG Data structures\n\n\n\n\n\n\n\nTo start we need\n\n\n\n\n\nTo start working with the Teslasuit PPG sensor, you need to ensure the following prerequisites are met:\n\nTeslasuit Device\n\nEnsure you have access to a Teslasuit device with of version 4.7 or higher.\n\nTeslasuit SDK\n\nInstall the Teslasuit SDK.\n\nFollow the installation guide to set up the SDK on your system.\n\nPython Environment\n\nInstall Python 3.8 or higher.\nEnsure that Python SDK is added to your . If it’s not run script from this section\n\nConnection Setup\n\nEnsure the Teslasuit device is powered on and connected to your computer via WiFi.\nVerify the connection using the Teslasuit Control Center application.\n\nDevelopment Environment\n\nUse an IDE or text editor that supports Python development, such as VS Code or PyCharm.\n\nPermissions\n\nEnsure you have the necessary permissions to access the Teslasuit device and its subsystems.\n\nOn some systems, you may need to run the script with elevated privileges.\n\n\nOnce these prerequisites are met, you can proceed to initialize the Teslasuit API and start working with the PPG subsystem as demonstrated in the code section below.",
    "crumbs": [
      "Usecases",
      "Real-time heart rate visualiser"
    ]
  },
  {
    "objectID": "usecases/ppg_visualiser.html#visualising-heart-rate-data",
    "href": "usecases/ppg_visualiser.html#visualising-heart-rate-data",
    "title": "Real-time heart rate visualiser",
    "section": "Visualising heart rate data",
    "text": "Visualising heart rate data\nimport matplotlib.pyplot as plt\n1from teslasuit_sdk import ts_api\n2import teslasuit_sdk.subsystems.ts_ppg\n\n\ndef main():\n3    print(\"Initializing Teslasuit API...\")\n    api = ts_api.TsApi()\n\n4    print(\"Waiting for a Teslasuit device to connect...\")\n    device = api.get_device_manager().get_or_wait_last_device_attached()\n\n5    print(\"Accessing the PPG subsystem...\")\n    ppg = device.ppg\n\n6    print(\"Starting raw PPG data streaming...\")\n    ppg.start_raw_streaming()\n\n    # Initialize plot\n7    plt.ion()\n    fig, ax = plt.subplots()\n    x_data, y_data = [], []\n    line, = ax.plot(x_data, y_data, label=\"Heart Rate (bpm)\")\n    ax.set_xlabel(\"Timestamp (s)\")\n    ax.set_ylabel(\"Heart Rate (bpm)\")\n    ax.set_title(\"Real-Time Heart Rate Data\")\n    ax.legend()\n\n8    print(\"Waiting for Heart Rate data...\")\n\n    try:\n        while True:\n            # Get processed PPG data\n9            node_data = ppg.get_data()\n            heart_rate = node_data.nodes[0].heart_rate\n            timestamp = node_data.nodes[0].timestamp\n\n            # Update data\n10            x_data.append(timestamp)\n            y_data.append(heart_rate)\n\n            # Update plot\n11            line.set_xdata(x_data)\n            line.set_ydata(y_data)\n            ax.relim()\n            ax.autoscale_view()\n            plt.draw()\n            plt.pause(0.01)\n\n12    except KeyboardInterrupt:\n        print(\"Stopping real-time plotting...\")\n    finally:\n13        ppg.stop_raw_streaming()\n        plt.ioff()\n        plt.show()\n\nif __name__ == \"__main__\":\n14    main()\n\n1\n\nImport the main Teslasuit API module: Import the required Teslasuit SDK modules.\n\n2\n\nImport the PPG subsystem: Import the PPG subsystem from the SDK.\n\n3\n\nInitialize the Teslasuit API: Create an instance of the Teslasuit API.\n\n4\n\nWait for a Teslasuit device to connect: Wait for a Teslasuit device to be connected and get it.\n\n5\n\nAccess the PPG subsystem: Access the PPG subsystem from the connected device.\n\n6\n\nStart raw PPG data streaming: Start streaming raw PPG data from the suit.\n\n7\n\nInitialize the real-time plot: Set up the matplotlib plot for real-time visualization of heart rate data.\n\n8\n\nStart waiting for heart rate data: Begin the loop to process and visualize heart rate data.\n\n9\n\nRetrieve heart rate data: Get processed PPG data and extract the heart rate and timestamp.\n\n10\n\nUpdate data arrays: Append the timestamp and heart rate to the respective data arrays.\n\n11\n\nUpdate the plot: Update the plot with the new data and refresh the visualization.\n\n12\n\nHandle keyboard interrupt: Gracefully stop the program when interrupted (e.g., via Ctrl+C).\n\n13\n\nStop raw PPG data streaming: Stop the PPG data stream and close the plot.\n\n14\n\nRun the main function: Start the program using the main function.\n\n\n\n\n\n\n\n\nPotential problems and solutions\n\n\n\n\n\n\nDevice Connection Issues\n\nProblem: The Teslasuit device may not connect or be detected by the API.\n\nSolution: Ensure the device is powered on and within range. Verify that the Teslasuit drivers and SDK are correctly installed. Check for any connection errors in the logs.\n\nPPG Subsystem Not Accessible\n\nProblem: The PPG subsystem might not be available or initialized properly.\n\nSolution: Confirm that the connected Teslasuit device supports the PPG subsystem. Restart the device and reinitialize the API if necessary. Double-check that the Teslasuit version is 4.7 or higher, as earlier versions may not support the PPG functionality.\n\nSDK Initialization Issues\n\nProblem: The SDK cannot be initialized, or the library is not found.\n\nSolution: Verify that the Teslasuit SDK is installed correctly. Refer to the installation guide for instructions. Ensure the environment of the working project is properly set up. Refer to the this section for details.\n\nData Streaming Delays\n\nProblem: There may be delays in receiving HRV or heart rate data.\n\nSolution: Delays could be caused by the algorithm behind HRV calculation. Usually it requires at least 30 second of raw data to calculate HRV.",
    "crumbs": [
      "Usecases",
      "Real-time heart rate visualiser"
    ]
  }
]